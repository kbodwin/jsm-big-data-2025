{
  "hash": "6ecf4f3067a1cf7cef4f28e436ce2390",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hands-on practice: Analysis with PUMS Data\"\neditor: source\n---\n\n\n\n\n## Exercise 1: Reading Partitioned PUMS Data\n\n::: panel-tabset\n### Problems\n\n* Load the PUMS person data as an arrow dataset\n* What are the dimensions of the dataset? Number of rows? Number of columns?\n* Examine the dataset:\n  * What columns does the dataset have?\n  * What are the column types?\n\n### Hints\n\nYou can use `arrow::open_dataset(...)` to open a dataset. Treat the dataset like it's a data frame, can you use the same functions that you are already familiar with?\n\n### Solution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(arrow)\nlibrary(dplyr)\n\n# Open the PUMS dataset\npums_ds <- open_dataset(\"~/PUMS/data/person\")\n\n# dimensions\nnrow(pums_ds)\nncol(pums_ds)\n\n# Examine the dataset\npums_ds\n\n# Examine schema\nschema(pums_ds)\n```\n:::\n\n\n\n:::\n\n## Exercise 2: Basic Filtering and Aggregation\n\n::: panel-tabset\n### Problems\n\n* What was the population of Tennessee in 2018?\n* What was the population of Tennessee over the last five years of available data?\n\n### Hint\n\nTry using familiar dplyr verbs: `filter()`, `summarize()`, et c.\n\n### Solution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(arrow)\nlibrary(dplyr)\n\n# Open the PUMS dataset\npums_ds <- open_dataset(\"~/PUMS/data/person\")\n\npums_ds |>\n  filter(year == 2018, location == \"tn\") |>\n  summarize(\n    n = n(),\n    population = sum(PWGTP)\n  ) |>\n  collect()\n\npums_ds |>\n  filter(location == \"tn\") |>\n  group_by(year) |>\n  summarize(\n    n = n(),\n    population = sum(PWGTP)\n  ) |>\n  arrange(-year) |>\n  slice_head(n = 5) |>\n  collect()\n```\n:::\n\n\n\n:::\n\n## Exercise 3: Using DuckDB with PUMS Data\n\n::: panel-tabset\n### Problems\n\nFor each state, compute the minimum commute time and the maximum commute time. Return it in a long data frame (hint, you'll need to use `tidyr::pivot_longer` here) with the columns: `location`, `commute_metric` (values: `max_commute`, `min_commute`), `time`. \n\nFor motivation: if you were trying to plot using `ggplot2` and wanted both the minimums and the maximums to show up on the same plot.\n\n### Hint\nArrow's query engine doesn't support `tidyr::pivot_longer`. So you'll need to use `to_duckdb()` and then use duckdb from there.\n\n### Solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(arrow)\nlibrary(duckdb)\nlibrary(tidyr)\n\n# Open the PUMS dataset\npums_ds <- open_dataset(\"~/PUMS/data/person\")\n\npums_ds |>\n  group_by(location) |>\n  summarize(\n    max_commute = max(JWMNP, na.rm = TRUE),\n    min_commute = min(JWMNP, na.rm = TRUE)\n  ) |>\n  to_duckdb() |> \n  pivot_longer(!location, names_to = \"commute_metric\", values_to = \"time\") |>\n  arrange(location) |>\n  collect()\n```\n:::\n\n\n\n:::\n\n## Challenge: Formulate Your Own Analysis\n\n- **Choose a research question:**\n  - How has commute time changed over the years?\n  - What's the relationship between education and income?\n  - How does housing cost burden vary by state?\n  - Your own question...\n\n- **Implement the analysis using:**\n  - Arrow Dataset operations\n  - DuckDB SQL queries\n  - Data visualization\n\n- **Compare performance between approaches**\n\n\n## The PUMS Dataset\n\n[detailed dataset description](https://scaling-arrow-pums.s3.us-east-1.amazonaws.com/readme.html)\n\n- **Public Use Microdata Sample**\n  - US Census Bureau data\n  - Individual person and household records\n  - Anonymized demographic information\n  - Income, education, housing, commute, et c.\n\n- **Dataset characteristics:**\n  - Multiple years (2005-2022, sans 2020)\n  - All US states and territories\n  - 53 Million rows (person), 25 Million rows (household)\n  - 200+ variables",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}