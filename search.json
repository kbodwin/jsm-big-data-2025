[
  {
    "objectID": "materials/activities/04-practice-workflow.html#your-turn",
    "href": "materials/activities/04-practice-workflow.html#your-turn",
    "title": "Practice a Smooth Workflow",
    "section": "Your Turn",
    "text": "Your Turn\nThe following pipeline is disorganized, syntactically inconsistent, and of course, slow.\nRewrite it using your new skills to be clean, readable, and efficient.\nThen use your favorite benchmarking or speed testing approach from unit 1 to demonstrate that the new pipeline is indeed faster.\n\nstates &lt;- c(\"ak\", \"al\", \"ar\", \"az\", \"wa\", \"wi\", \"wv\", \"wy\")\n\ndat &lt;- data.frame()\n\nfor (state in states) {\n  my_files &lt;- list.files(glue(\"./materials/data/raw_csvs/person/2021/{state}/\"), full.names = TRUE)\n  \n  for (file in my_files) {\n    \n    temp &lt;- read_csv(file) |&gt;\n      mutate_all(as.character)\n    \n    dat &lt;- dat |&gt;\n      bind_rows(temp)\n    \n  }\n}\n\n\ndat[year == 2021][, .(avg_age = mean(AGEP)), by = ST][order(-avg_age)]\n\n\n\ndat |&gt;\n  group_by(location) |&gt;\n  summarize(\n    max_commute = max(JWMNP, na.rm = TRUE),\n    min_commute = min(JWMNP, na.rm = TRUE)\n  ) |&gt; \n  pivot_longer(!location, names_to = \"commute_metric\", values_to = \"time\") |&gt;\n  arrange(location)"
  },
  {
    "objectID": "materials/activities/01-practice-slowdowns.html",
    "href": "materials/activities/01-practice-slowdowns.html",
    "title": "Find the slowdowns",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(glue)\nlibrary(tictoc)"
  },
  {
    "objectID": "materials/activities/01-practice-slowdowns.html#setup",
    "href": "materials/activities/01-practice-slowdowns.html#setup",
    "title": "Find the slowdowns",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(glue)\nlibrary(tictoc)"
  },
  {
    "objectID": "materials/activities/01-practice-slowdowns.html#your-turn",
    "href": "materials/activities/01-practice-slowdowns.html#your-turn",
    "title": "Find the slowdowns",
    "section": "Your Turn",
    "text": "Your Turn\nWe will find the slowdowns in the following process:\n\nstates &lt;- c(\"ak\", \"al\", \"ar\", \"az\", \"wa\", \"wi\", \"wv\", \"wy\")\n\ndat &lt;- data.frame()\n\nfor (state in states) {\n  my_files &lt;- list.files(glue(\"../data/raw_csvs/person/2021/{state}/\"), full.names = TRUE)\n  \n  for (file in my_files) {\n    \n    temp &lt;- read_csv(file) |&gt;\n      mutate_all(as.character)\n    \n    dat &lt;- dat |&gt;\n      bind_rows(temp)\n    \n  }\n}\n\nRows: 6411 Columns: 287\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (25): RT, SERIALNO, SPORDER, PUMA, ST, JWTRNS, SCHG, SCHL, ANC1P, ANC2P...\ndbl (262): DIVISION, REGION, ADJINC, PWGTP, AGEP, CIT, CITWP, COW, DDRS, DEA...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 49647 Columns: 287\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (25): RT, SERIALNO, SPORDER, PUMA, ST, JWTRNS, SCHG, SCHL, ANC1P, ANC2P...\ndbl (262): DIVISION, REGION, ADJINC, PWGTP, AGEP, CIT, CITWP, COW, DDRS, DEA...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 30050 Columns: 287\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (25): RT, SERIALNO, SPORDER, PUMA, ST, JWTRNS, SCHG, SCHL, ANC1P, ANC2P...\ndbl (262): DIVISION, REGION, ADJINC, PWGTP, AGEP, CIT, CITWP, COW, DDRS, DEA...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 73025 Columns: 287\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (25): RT, SERIALNO, SPORDER, PUMA, ST, JWTRNS, SCHG, SCHL, ANC1P, ANC2P...\ndbl (262): DIVISION, REGION, ADJINC, PWGTP, AGEP, CIT, CITWP, COW, DDRS, DEA...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 78528 Columns: 287\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (23): RT, SERIALNO, SPORDER, JWTRNS, SCHG, SCHL, ANC1P, ANC2P, HISP, IN...\ndbl (264): DIVISION, PUMA, REGION, ST, ADJINC, PWGTP, AGEP, CIT, CITWP, COW,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 60281 Columns: 287\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (24): RT, SERIALNO, SPORDER, PUMA, JWTRNS, SCHG, SCHL, ANC1P, ANC2P, HI...\ndbl (263): DIVISION, REGION, ST, ADJINC, PWGTP, AGEP, CIT, CITWP, COW, DDRS,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 17428 Columns: 287\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (24): RT, SERIALNO, SPORDER, PUMA, JWTRNS, SCHG, SCHL, ANC1P, ANC2P, HI...\ndbl (263): DIVISION, REGION, ST, ADJINC, PWGTP, AGEP, CIT, CITWP, COW, DDRS,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 5861 Columns: 287\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (24): RT, SERIALNO, SPORDER, PUMA, JWTRNS, SCHG, SCHL, ANC1P, ANC2P, HI...\ndbl (263): DIVISION, REGION, ST, ADJINC, PWGTP, AGEP, CIT, CITWP, COW, DDRS,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ndat |&gt;\n  mutate(\n    age_groups = case_when(\n      AGEP &lt; 18 ~ \"Under 18\",\n      AGEP &lt; 65 ~ \"18-64\",\n      TRUE ~ \"65+\"\n    )\n  ) |&gt;\n  group_by(REGION, CIT, SEX, ST, age_groups) |&gt;\n  summarize(\n    count = n()\n  ) |&gt;\n  pivot_wider(names_from = age_groups,\n              values_from = count) |&gt;\n  filter(REGION == 3) \n\n`summarise()` has grouped output by 'REGION', 'CIT', 'SEX', 'ST'. You can\noverride using the `.groups` argument.\n\n\n\n  \n\n\n\n\nStep One: Find the problem chunk(s)\nUse tictoc() to figure out which of the two steps is slowest.\nUse system.time() to figure out which part of the data read is slowest.\n\n\nStep Two: Profile the processes\nUse profviz() to see where the slowdowns occur in the analysis pipeline.\n\n\nStep Three: Benchmark a solution\nTry rearranging your analysis pipeline to be more efficient. Compare this solution to the original."
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#you-have-data-that",
    "href": "materials/slides/01-slowdowns-solutions.html#you-have-data-that",
    "title": "Finding slowdowns and solutions.",
    "section": "You have data that…",
    "text": "You have data that…\n\nYou want to analyze: summarize, visualize, model, etc.\nCan be downloaded somewhere on your local machine.\nCan be read fully into R…\n\n\n… but maybe very slowly…\n\n\n… and maybe only if it’s a parquet file."
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#what-if-its-bigger-than-that",
    "href": "materials/slides/01-slowdowns-solutions.html#what-if-its-bigger-than-that",
    "title": "Finding slowdowns and solutions.",
    "section": "What if it’s bigger than that?",
    "text": "What if it’s bigger than that?\n\nIt’s probably in a cloud database. (e.g. AWS)\nDo the individual files/tables fit on disk?\nCan you query subsets of the data and fit those on disk?"
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#key-terms",
    "href": "materials/slides/01-slowdowns-solutions.html#key-terms",
    "title": "Finding slowdowns and solutions.",
    "section": "Key Terms",
    "text": "Key Terms\n\nData is on disk if it is stored on your computer\nData is in-memory if you load it into RAM, e.g. loading into R.\nA csv file is a file type for storing data as comma separated text.\nA parquet file is a file type for storing data as column information."
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#key-packages",
    "href": "materials/slides/01-slowdowns-solutions.html#key-packages",
    "title": "Finding slowdowns and solutions.",
    "section": "Key Packages",
    "text": "Key Packages\n\ndata.table optimizes calculations in R on data frames, via algorithmic cleverness and C implementation.\nduckdb creates a SQL database locally and lets you use R Code to execute SQL operations.\narrow provides ways to read and write parquet files and to move data around between data.table, duckdb, and other formats."
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#helper-packages",
    "href": "materials/slides/01-slowdowns-solutions.html#helper-packages",
    "title": "Finding slowdowns and solutions.",
    "section": "Helper Packages",
    "text": "Helper Packages\n\nFriends of data.table:\n\ndtplyr, tidyfast for dplyr syntax\nmlr3 for machine learning\n\nFriends of duckdb:\n\nduckplyr for for dplyr syntax\nodbc, for connection to cloud databases\n\nOther speed/efficiency helpers:\n\npolars in python"
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#my-data-reads-in-slowly.",
    "href": "materials/slides/01-slowdowns-solutions.html#my-data-reads-in-slowly.",
    "title": "Finding slowdowns and solutions.",
    "section": "1. My data reads in slowly.",
    "text": "1. My data reads in slowly.\nA. Use data.table::fread() instead.\nB. Write it to a parquet version; use arrow::read_parquet().\nC. Put it in a duckdb; use queries to avoid reading the whole dataset at once."
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#one-of-my-pipelines-is-a-little-slow-and-i-do-it-many-times",
    "href": "materials/slides/01-slowdowns-solutions.html#one-of-my-pipelines-is-a-little-slow-and-i-do-it-many-times",
    "title": "Finding slowdowns and solutions.",
    "section": "2. One of my pipelines is a little slow, and I do it many times",
    "text": "2. One of my pipelines is a little slow, and I do it many times\nA. Are you using vectorized functions (or could you)?\nB. Use data.table - do the small speed gains add up?\nC. Can you move some subsetting steps to duckdb?"
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#one-of-my-pipelines-is-very-slow.",
    "href": "materials/slides/01-slowdowns-solutions.html#one-of-my-pipelines-is-very-slow.",
    "title": "Finding slowdowns and solutions.",
    "section": "3. One of my pipelines is very slow.",
    "text": "3. One of my pipelines is very slow.\nA. Can you re-order the pipeline?\nB. Are you doing a split-apply-combine over many groups? data.table!\nC. Are you doing a subsetting process? data.table or duckdb!\nD. Is it just a lot of data? duckdb and calculate in partitions."
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#setup",
    "href": "materials/slides/01-slowdowns-solutions.html#setup",
    "title": "Finding slowdowns and solutions.",
    "section": "Setup",
    "text": "Setup\n\ndat &lt;- read_csv(\"../data/raw_csvs/person/2021/az/psam_p04.csv\")"
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#the-tictoc-package",
    "href": "materials/slides/01-slowdowns-solutions.html#the-tictoc-package",
    "title": "Finding slowdowns and solutions.",
    "section": "The tictoc() package",
    "text": "The tictoc() package\n\ntic()\n\n  dat |&gt;\n    pivot_longer(PWGTP1:PWGTP80,\n               names_to = \"Weight_Num\",\n               values_to = \"Weight_Amount\") |&gt;\n    group_by(ST) |&gt;\n    mutate(\n      max_weight = max(Weight_Amount)\n    )\n\n# A tibble: 5,842,000 × 210\n# Groups:   ST [1]\n   RT    SERIALNO   DIVISION SPORDER PUMA  REGION ST    ADJINC PWGTP  AGEP   CIT\n   &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 P     2021GQ000…        8 01      00800      4 04    1.03e6    35    36     1\n 2 P     2021GQ000…        8 01      00800      4 04    1.03e6    35    36     1\n 3 P     2021GQ000…        8 01      00800      4 04    1.03e6    35    36     1\n 4 P     2021GQ000…        8 01      00800      4 04    1.03e6    35    36     1\n 5 P     2021GQ000…        8 01      00800      4 04    1.03e6    35    36     1\n 6 P     2021GQ000…        8 01      00800      4 04    1.03e6    35    36     1\n 7 P     2021GQ000…        8 01      00800      4 04    1.03e6    35    36     1\n 8 P     2021GQ000…        8 01      00800      4 04    1.03e6    35    36     1\n 9 P     2021GQ000…        8 01      00800      4 04    1.03e6    35    36     1\n10 P     2021GQ000…        8 01      00800      4 04    1.03e6    35    36     1\n# ℹ 5,841,990 more rows\n# ℹ 199 more variables: CITWP &lt;dbl&gt;, COW &lt;dbl&gt;, DDRS &lt;dbl&gt;, DEAR &lt;dbl&gt;,\n#   DEYE &lt;dbl&gt;, DOUT &lt;dbl&gt;, DPHY &lt;dbl&gt;, DRAT &lt;dbl&gt;, DRATX &lt;dbl&gt;, DREM &lt;dbl&gt;,\n#   ENG &lt;dbl&gt;, FER &lt;dbl&gt;, GCL &lt;dbl&gt;, GCM &lt;dbl&gt;, GCR &lt;dbl&gt;, HIMRKS &lt;dbl&gt;,\n#   HINS1 &lt;dbl&gt;, HINS2 &lt;dbl&gt;, HINS3 &lt;dbl&gt;, HINS4 &lt;dbl&gt;, HINS5 &lt;dbl&gt;,\n#   HINS6 &lt;dbl&gt;, HINS7 &lt;dbl&gt;, INTP &lt;dbl&gt;, JWMNP &lt;dbl&gt;, JWRIP &lt;dbl&gt;,\n#   JWTRNS &lt;chr&gt;, LANX &lt;dbl&gt;, MAR &lt;dbl&gt;, MARHD &lt;dbl&gt;, MARHM &lt;dbl&gt;, …\n\ntoc()\n\n3.124 sec elapsed"
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#function-wrappers-optional",
    "href": "materials/slides/01-slowdowns-solutions.html#function-wrappers-optional",
    "title": "Finding slowdowns and solutions.",
    "section": "Function wrappers (optional)",
    "text": "Function wrappers (optional)\n\nold_pipeline &lt;-  function() {\n  dat |&gt;\n    pivot_longer(PWGTP1:PWGTP80,\n               names_to = \"Weight_Num\",\n               values_to = \"Weight_Amount\") |&gt;\n    group_by(CIT) |&gt;\n    mutate(\n      max_weight = max(Weight_Amount)\n    )\n}\n\nlibrary(dtplyr)\n\nnew_pipeline &lt;- function() {\n  dat |&gt;\n    rowwise() |&gt;\n    summarize(\n      max_weight = max(PWGTP1:PWGTP80),\n      CIT = CIT\n    ) |&gt;\n    group_by(CIT) |&gt;\n    summarize(\n      max_weight = max(max_weight)\n    )\n}"
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#microbenchmark-for-multiple-runs",
    "href": "materials/slides/01-slowdowns-solutions.html#microbenchmark-for-multiple-runs",
    "title": "Finding slowdowns and solutions.",
    "section": "Microbenchmark for multiple runs",
    "text": "Microbenchmark for multiple runs\n\nmicrobenchmark::microbenchmark(\n  old_version = old_pipeline(),\n  new_version = new_pipeline(),\n  times = 5\n)\n\nUnit: milliseconds\n        expr       min        lq      mean    median        uq       max neval\n old_version 1612.0746 1673.3494 1820.7446 1823.9169 1984.6106 2009.7713     5\n new_version  191.5454  250.3799  329.5858  387.5821  408.1263  410.2953     5"
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#bench-package-for-memory-comparisons",
    "href": "materials/slides/01-slowdowns-solutions.html#bench-package-for-memory-comparisons",
    "title": "Finding slowdowns and solutions.",
    "section": "bench package for memory comparisons…",
    "text": "bench package for memory comparisons…\n\nbench::mark(\n  old_version = old_pipeline(),\n  new_version = new_pipeline(),\n  check = FALSE,\n  max_iterations = 3\n)\n\n# A tibble: 2 × 6\n  expression       min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt;  &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 old_version    2.09s    2.09s     0.478    9.45GB    0.956\n2 new_version 191.34ms  199.4ms     4.51    15.24MB   28.6"
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#and-testing-scaling-with-size",
    "href": "materials/slides/01-slowdowns-solutions.html#and-testing-scaling-with-size",
    "title": "Finding slowdowns and solutions.",
    "section": "… and testing scaling with size",
    "text": "… and testing scaling with size\n\nresults &lt;- bench::press(\n  duplications = c(1, 2),\n  {\n    dat_big &lt;- bind_rows(replicate(duplications, dat, simplify = FALSE))\n    bench::mark(\n      old_version = old_pipeline(),\n      new_version = new_pipeline(),\n      check = FALSE,\n      max_iterations = 3\n    )\n  }\n)\n\nresults\n\n# A tibble: 4 × 7\n  expression  duplications      min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt;         &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 old_version            1    2.04s    2.04s     0.490    9.45GB    0.490\n2 new_version            1 194.53ms  251.4ms     3.47    15.24MB   20.8  \n3 old_version            2    1.96s    1.96s     0.509    9.45GB    1.02 \n4 new_version            2 248.67ms 262.87ms     3.80    15.24MB   20.9"
  },
  {
    "objectID": "materials/slides/01-slowdowns-solutions.html#summary",
    "href": "materials/slides/01-slowdowns-solutions.html#summary",
    "title": "Finding slowdowns and solutions.",
    "section": "Summary",
    "text": "Summary\n\nUse tictoc() or proc.time() to get a feel for runtimes of larger chunks.\nUse profiling to narrow down where in a chunk the slowdowns are.\nUse benchmarking to compare your old version to a proposed solution.\nUse benchmark testing to see how your speed ups scale with data size."
  },
  {
    "objectID": "materials/slides/02-datatable.html#why-data.table",
    "href": "materials/slides/02-datatable.html#why-data.table",
    "title": "data.table",
    "section": "Why data.table?",
    "text": "Why data.table?\n\n\nConcise syntax: fast to type, fast to read – “Me think, why waste time say lot word when few word do trick.”\n\n\n\n\nFast speed: optimized C code under the hood – “I am faster than 80 percent of all snakes.”\n\n\n\n\nMemory efficient: modify by reference – “Whenever I’m about to do something, I think, “would an idiot do that?” And if they would, I do not do that thing.”"
  },
  {
    "objectID": "materials/slides/02-datatable.html#why-data.table-1",
    "href": "materials/slides/02-datatable.html#why-data.table-1",
    "title": "data.table",
    "section": "Why data.table?",
    "text": "Why data.table?\n\n\nCareful API lifecycle management: stable, backward compatible – “I’m not superstitious, but I am a little stitious.”\n\n\n\n\nCommunity: active development and support – “Would I rather be feared or loved? Easy. Both. I want people to be afraid of how much they love me.”\n\n\n\n\nFeature rich: comprehensive data manipulation toolkit – “Bears, beets, Battlestar Galactica.”"
  },
  {
    "objectID": "materials/slides/02-datatable.html#loading-pums-data",
    "href": "materials/slides/02-datatable.html#loading-pums-data",
    "title": "data.table",
    "section": "Loading PUMS Data",
    "text": "Loading PUMS Data\nPreview to next section with Jonathan about arrow:\n\nlibrary(data.table)\nlibrary(dplyr)\nlibrary(arrow)\n\n# Preview into next section: Load multiple states and years using arrow\npums &lt;- open_dataset(here::here(\"data/person\")) |&gt;\n  filter(year &gt;= 2020, location %in% c(\"ca\", \"tx\", \"ny\")) |&gt;\n  collect()\nsetDT(pums)"
  },
  {
    "objectID": "materials/slides/02-datatable.html#loading-pums-data-1",
    "href": "materials/slides/02-datatable.html#loading-pums-data-1",
    "title": "data.table",
    "section": "Loading PUMS Data",
    "text": "Loading PUMS Data\n\npums[, 1:5]\n\n         SPORDER            RT      SERIALNO   PUMA          ST\n           &lt;int&gt;        &lt;fctr&gt;        &lt;char&gt; &lt;char&gt;      &lt;char&gt;\n      1:       1 Person Record 2021HU0896827  00904 New York/NY\n      2:       2 Person Record 2021HU0896827  00904 New York/NY\n      3:       3 Person Record 2021HU0896827  00904 New York/NY\n      4:       4 Person Record 2021HU0896827  00904 New York/NY\n      5:       5 Person Record 2021HU0896827  00904 New York/NY\n     ---                                                       \n1735551:       1 Person Record 2022HU0609672  04611    Texas/TX\n1735552:       2 Person Record 2022HU0609672  04611    Texas/TX\n1735553:       3 Person Record 2022HU0609672  04611    Texas/TX\n1735554:       1 Person Record 2022HU0609675  04302    Texas/TX\n1735555:       2 Person Record 2022HU0609675  04302    Texas/TX\n\nnames(pums)\n\n  [1] \"SPORDER\"   \"RT\"        \"SERIALNO\"  \"PUMA\"      \"ST\"        \"ADJUST\"   \n  [7] \"PWGTP\"     \"AGEP\"      \"CIT\"       \"COW\"       \"DDRS\"      \"DEYE\"     \n [13] \"DOUT\"      \"DPHY\"      \"DREM\"      \"DWRK\"      \"ENG\"       \"FER\"      \n [19] \"GCL\"       \"GCM\"       \"GCR\"       \"INTP\"      \"JWMNP\"     \"JWRIP\"    \n [25] \"JWTR\"      \"LANX\"      \"MAR\"       \"MIG\"       \"MIL\"       \"MILY\"     \n [31] \"MLPA\"      \"MLPB\"      \"MLPC\"      \"MLPD\"      \"MLPE\"      \"MLPF\"     \n [37] \"MLPG\"      \"MLPH\"      \"MLPI\"      \"MLPJ\"      \"MLPK\"      \"NWAB\"     \n [43] \"NWAV\"      \"NWLA\"      \"NWLK\"      \"NWRE\"      \"OIP\"       \"PAP\"      \n [49] \"REL\"       \"RETP\"      \"SCH\"       \"SCHG\"      \"SCHL\"      \"SEMP\"     \n [55] \"SEX\"       \"SSIP\"      \"SSP\"       \"WAGP\"      \"WKHP\"      \"WKL\"      \n [61] \"WKW\"       \"YOEP\"      \"UWRK\"      \"ANC\"       \"ANC1P\"     \"ANC2P\"    \n [67] \"DECADE\"    \"DRIVESP\"   \"DS\"        \"ESP\"       \"ESR\"       \"HISP\"     \n [73] \"INDP\"      \"JWAP\"      \"JWDP\"      \"LANP\"      \"MIGPUMA\"   \"MIGSP\"    \n [79] \"MSP\"       \"NAICSP\"    \"NATIVITY\"  \"OC\"        \"OCCP\"      \"PAOC\"     \n [85] \"PERNP\"     \"PINCP\"     \"POBP\"      \"POVPIP\"    \"POWPUMA\"   \"POWSP\"    \n [91] \"QTRBIR\"    \"RAC1P\"     \"RAC2P\"     \"RAC3P\"     \"RACAIAN\"   \"RACASN\"   \n [97] \"RACBLK\"    \"RACNHPI\"   \"RACNUM\"    \"RACSOR\"    \"RACWHT\"    \"RC\"       \n[103] \"SFN\"       \"SFR\"       \"SOCP\"      \"VPS\"       \"WAOB\"      \"FAGEP\"    \n[109] \"FANCP\"     \"FCITP\"     \"FCOWP\"     \"FDDRSP\"    \"FDEYEP\"    \"FDOUTP\"   \n[115] \"FDPHYP\"    \"FDREMP\"    \"FDWRKP\"    \"FENGP\"     \"FESRP\"     \"FFERP\"    \n[121] \"FGCLP\"     \"FGCMP\"     \"FGCRP\"     \"FHISP\"     \"FINDP\"     \"FINTP\"    \n[127] \"FJWDP\"     \"FJWMNP\"    \"FJWRIP\"    \"FJWTRP\"    \"FLANP\"     \"FLANXP\"   \n[133] \"FMARP\"     \"FMIGP\"     \"FMIGSP\"    \"FMILPP\"    \"FMILSP\"    \"FMILYP\"   \n[139] \"FOCCP\"     \"FOIP\"      \"FPAP\"      \"FPOBP\"     \"FPOWSP\"    \"FRACP\"    \n[145] \"FRELP\"     \"FRETP\"     \"FSCHGP\"    \"FSCHLP\"    \"FSCHP\"     \"FSEMP\"    \n[151] \"FSEXP\"     \"FSSIP\"     \"FSSP\"      \"FWAGP\"     \"FWKHP\"     \"FWKLP\"    \n[157] \"FWKWP\"     \"FYOEP\"     \"PWGTP1\"    \"PWGTP2\"    \"PWGTP3\"    \"PWGTP4\"   \n[163] \"PWGTP5\"    \"PWGTP6\"    \"PWGTP7\"    \"PWGTP8\"    \"PWGTP9\"    \"PWGTP10\"  \n[169] \"PWGTP11\"   \"PWGTP12\"   \"PWGTP13\"   \"PWGTP14\"   \"PWGTP15\"   \"PWGTP16\"  \n[175] \"PWGTP17\"   \"PWGTP18\"   \"PWGTP19\"   \"PWGTP20\"   \"PWGTP21\"   \"PWGTP22\"  \n[181] \"PWGTP23\"   \"PWGTP24\"   \"PWGTP25\"   \"PWGTP26\"   \"PWGTP27\"   \"PWGTP28\"  \n[187] \"PWGTP29\"   \"PWGTP30\"   \"PWGTP31\"   \"PWGTP32\"   \"PWGTP33\"   \"PWGTP34\"  \n[193] \"PWGTP35\"   \"PWGTP36\"   \"PWGTP37\"   \"PWGTP38\"   \"PWGTP39\"   \"PWGTP40\"  \n[199] \"PWGTP41\"   \"PWGTP42\"   \"PWGTP43\"   \"PWGTP44\"   \"PWGTP45\"   \"PWGTP46\"  \n[205] \"PWGTP47\"   \"PWGTP48\"   \"PWGTP49\"   \"PWGTP50\"   \"PWGTP51\"   \"PWGTP52\"  \n[211] \"PWGTP53\"   \"PWGTP54\"   \"PWGTP55\"   \"PWGTP56\"   \"PWGTP57\"   \"PWGTP58\"  \n[217] \"PWGTP59\"   \"PWGTP60\"   \"PWGTP61\"   \"PWGTP62\"   \"PWGTP63\"   \"PWGTP64\"  \n[223] \"PWGTP65\"   \"PWGTP66\"   \"PWGTP67\"   \"PWGTP68\"   \"PWGTP69\"   \"PWGTP70\"  \n[229] \"PWGTP71\"   \"PWGTP72\"   \"PWGTP73\"   \"PWGTP74\"   \"PWGTP75\"   \"PWGTP76\"  \n[235] \"PWGTP77\"   \"PWGTP78\"   \"PWGTP79\"   \"PWGTP80\"   \"NOP\"       \"ADJINC\"   \n[241] \"CITWP\"     \"DEAR\"      \"DRAT\"      \"DRATX\"     \"HINS1\"     \"HINS2\"    \n[247] \"HINS3\"     \"HINS4\"     \"HINS5\"     \"HINS6\"     \"HINS7\"     \"MARHD\"    \n[253] \"MARHM\"     \"MARHT\"     \"MARHW\"     \"MARHYP\"    \"DIS\"       \"HICOV\"    \n[259] \"PRIVCOV\"   \"PUBCOV\"    \"FCITWP\"    \"FDEARP\"    \"FDRATP\"    \"FDRATXP\"  \n[265] \"FHINS1P\"   \"FHINS2P\"   \"FHINS3P\"   \"FHINS4P\"   \"FHINS5P\"   \"FHINS6P\"  \n[271] \"FHINS7P\"   \"FMARHDP\"   \"FMARHMP\"   \"FMARHTP\"   \"FMARHWP\"   \"FMARHYP\"  \n[277] \"WRK\"       \"FOD1P\"     \"FOD2P\"     \"SCIENGP\"   \"SCIENGRLP\" \"FFODP\"    \n[283] \"FHINS3C\"   \"FHINS4C\"   \"FHINS5C\"   \"RELP\"      \"FWRKP\"     \"FDISP\"    \n[289] \"FPERNP\"    \"FPINCP\"    \"FPRIVCOVP\" \"FPUBCOVP\"  \"RACNH\"     \"RACPI\"    \n[295] \"SSPA\"      \"MLPCD\"     \"MLPFG\"     \"FHICOVP\"   \"DIVISION\"  \"REGION\"   \n[301] \"HIMRKS\"    \"JWTRNS\"    \"RELSHIPP\"  \"WKWN\"      \"FHIMRKSP\"  \"FJWTRNSP\" \n[307] \"FRELSHIPP\" \"FWKWNP\"    \"MLPIK\"     \"year\"      \"location\""
  },
  {
    "objectID": "materials/slides/02-datatable.html#concise-syntax",
    "href": "materials/slides/02-datatable.html#concise-syntax",
    "title": "data.table",
    "section": "1. Concise Syntax",
    "text": "1. Concise Syntax\n“why waste time say lot word when few word do trick.”\n\n\n\nIn j we can grab individual variables or a list of them (using the .())"
  },
  {
    "objectID": "materials/slides/02-datatable.html#concise-syntax-1",
    "href": "materials/slides/02-datatable.html#concise-syntax-1",
    "title": "data.table",
    "section": "1. Concise Syntax",
    "text": "1. Concise Syntax\nFast to type, fast to read\n\n# Base R approach\npums_df &lt;- as.data.frame(pums)\nsubset_data &lt;- pums_df[pums$ST == \"California/CA\" & pums$year == 2022, ]\nage_groups &lt;- ifelse(subset_data$AGEP &lt; 18, \"Under 18\",\n                    ifelse(subset_data$AGEP &lt; 65, \"18-64\", \"65+\"))\nbase_result &lt;- aggregate(subset_data$PWGTP, by = list(age_group = age_groups), FUN = sum)\n\n# data.table approach\npums[, age_groups := fcase(AGEP &lt; 18, \"Under 18\", AGEP &lt; 65, \"18-64\", default = \"65+\")]\ndt_result &lt;- pums[\n  year == 2022 & ST == \"California/CA\", \n  .(total_pop = sum(PWGTP)), \n  by = age_groups\n]\n\n\n\n\n\nbase_result\n\n  age_group        x\n1     18-64 24372342\n2       65+  6165865\n3  Under 18  8491135\n\n\n\n\ndt_result\n\n   age_groups total_pop\n       &lt;char&gt;     &lt;int&gt;\n1:      18-64  24372342\n2:        65+   6165865\n3:   Under 18   8491135"
  },
  {
    "objectID": "materials/slides/02-datatable.html#fill-in-the-blank",
    "href": "materials/slides/02-datatable.html#fill-in-the-blank",
    "title": "data.table",
    "section": "Fill in the Blank",
    "text": "Fill in the Blank\nWe want to take the pums data.table and select the SCHL, SEX, ST, and AGEP.\n\ndt_subset &lt;- pums[,\n\n]"
  },
  {
    "objectID": "materials/slides/02-datatable.html#fill-in-the-blank-1",
    "href": "materials/slides/02-datatable.html#fill-in-the-blank-1",
    "title": "data.table",
    "section": "Fill in the Blank",
    "text": "Fill in the Blank\nWe want to take the pums data.table and select the SCHL, SEX, ST, and AGEP.\n\ndt_subset &lt;- pums[,\n  .(SCHL, SEX, ST, AGEP)\n]"
  },
  {
    "objectID": "materials/slides/02-datatable.html#fill-in-the-blank-2",
    "href": "materials/slides/02-datatable.html#fill-in-the-blank-2",
    "title": "data.table",
    "section": "Fill in the Blank",
    "text": "Fill in the Blank\nWe want to subset to those in “ny” based on our location variable, group by age_groups and year, and get the proportion of those in the “Civilian employed, at work” based on the ESR variable.\n\ndt_ny &lt;- pums[\n\n\n\n]"
  },
  {
    "objectID": "materials/slides/02-datatable.html#fill-in-the-blank-3",
    "href": "materials/slides/02-datatable.html#fill-in-the-blank-3",
    "title": "data.table",
    "section": "Fill in the Blank",
    "text": "Fill in the Blank\nWe want to subset to those in “ny” based on our location variable, group by age_groups and year, and get the proportion of those in the “Civilian employed, at work” based on the ESR variable.\n\ndt_ny &lt;- pums[\n  location == \"ny\",\n  .(employed = mean(ESR == \"Civilian employed, at work\", na.rm = TRUE)),\n  by = .(age_groups, year)\n]"
  },
  {
    "objectID": "materials/slides/02-datatable.html#what-will-this-do",
    "href": "materials/slides/02-datatable.html#what-will-this-do",
    "title": "data.table",
    "section": "What will this do?",
    "text": "What will this do?\nHINSx are insurance types WAGP income (wages/salary) last 12 months\n\npums[, ins_type := fcase(\n  HINS1 == TRUE, \"employer\", \n  HINS2 == TRUE, \"direct\", \n  HINS3 == TRUE, \"Medicare\", \n  HINS4 == TRUE, \"Medicaid\",\n  HINS5 == TRUE | HINS6 == TRUE | HINS7 == TRUE, \"other\",\n  default = \"no insurance\")\n]\npums[, .(avg_income = mean(WAGP, na.rm = TRUE)), by = ins_type]"
  },
  {
    "objectID": "materials/slides/02-datatable.html#what-will-this-do-1",
    "href": "materials/slides/02-datatable.html#what-will-this-do-1",
    "title": "data.table",
    "section": "What will this do?",
    "text": "What will this do?\nHINSx are insurance types WAGP income (wages/salary) last 12 months\n\npums[, ins_type := fcase(\n  HINS1 == TRUE, \"employer\", \n  HINS2 == TRUE, \"direct\", \n  HINS3 == TRUE, \"Medicare\", \n  HINS4 == TRUE, \"Medicaid\",\n  HINS5 == TRUE | HINS6 == TRUE | HINS7 == TRUE, \"other\",\n  default = \"no insurance\")\n]\npums[, .(avg_income = mean(WAGP, na.rm = TRUE)), by = ins_type]\n\n       ins_type avg_income\n         &lt;char&gt;      &lt;num&gt;\n1:       direct  20805.087\n2:     employer  57418.563\n3:     Medicare   6044.857\n4:     Medicaid  10794.296\n5: no insurance  18047.548\n6:        other  30429.201"
  },
  {
    "objectID": "materials/slides/02-datatable.html#fast-speed",
    "href": "materials/slides/02-datatable.html#fast-speed",
    "title": "data.table",
    "section": "2. Fast Speed",
    "text": "2. Fast Speed\n“I am faster than 80 percent of all snakes.”\nBenchmarking is difficult\n\n# Benchmarking aggregation operations\nmicrobenchmark::microbenchmark(\n  # data.table\n  pums[, .(total_pop = sum(PWGTP)), by = .(ST, year)],\n  \n  # dplyr\n  pums_df |&gt; \n    group_by(ST, year) |&gt; \n    summarise(total_pop = sum(PWGTP), .groups = \"drop\"),\n\n  times = 10\n)\n\nUnit: milliseconds\n                                                                                  expr\n                                   pums[, .(total_pop = sum(PWGTP)), by = .(ST, year)]\n summarise(group_by(pums_df, ST, year), total_pop = sum(PWGTP),      .groups = \"drop\")\n      min       lq     mean   median       uq      max neval\n 10.65586 10.86816 12.38742 11.24441 12.25334 18.80338    10\n 22.14533 23.10104 26.42951 26.77839 27.52859 35.57590    10"
  },
  {
    "objectID": "materials/slides/02-datatable.html#fast-speed-1",
    "href": "materials/slides/02-datatable.html#fast-speed-1",
    "title": "data.table",
    "section": "2. Fast Speed",
    "text": "2. Fast Speed\n\n# Benchmarking aggregation operations\nmicrobenchmark::microbenchmark(\n  # data.table\n  pums[, .(total_pop = sum(PWGTP)), keyby = .(ST, year)],\n  \n  # dplyr\n  pums_df |&gt; \n    group_by(ST, year) |&gt; \n    summarise(total_pop = sum(PWGTP), .groups = \"drop\") |&gt; \n    arrange(ST, year),\n\n  times = 10\n)\n\nUnit: milliseconds\n                                                                                                     expr\n                                                   pums[, .(total_pop = sum(PWGTP)), keyby = .(ST, year)]\n arrange(summarise(group_by(pums_df, ST, year), total_pop = sum(PWGTP),      .groups = \"drop\"), ST, year)\n      min       lq     mean   median       uq      max neval\n 36.70439 37.05687 37.72736 37.47972 37.99835 40.02199    10\n 20.80701 22.45783 25.46581 24.57036 27.08907 34.81310    10"
  },
  {
    "objectID": "materials/slides/02-datatable.html#memory-efficient",
    "href": "materials/slides/02-datatable.html#memory-efficient",
    "title": "data.table",
    "section": "3. Memory Efficient",
    "text": "3. Memory Efficient\n“Whenever I’m about to do something, I think, “would an idiot do that?” And if they would, I do not do that thing.”\n\nQuick History Lesson on Shallow/Deep Copies\n\n\n# Create a copy (memory inefficient)\npums_nocopy &lt;- pums\n\n# Modify by reference (memory efficient)\npums[, age_decade := floor(AGEP / 10) * 10]\n\n# shows up in pums_nocopy\npums_nocopy[, .(age_decade)]\n\n         age_decade\n              &lt;num&gt;\n      1:         60\n      2:         40\n      3:         30\n      4:         20\n      5:         20\n     ---           \n1735551:         50\n1735552:         60\n1735553:         20\n1735554:         60\n1735555:         60\n\n\n\n\n\n\n\nlobstr::ref(pums)\n\n█ [1:0x10d207e00] &lt;dt[,314]&gt; \n├─SPORDER = [2:0x165f38000] &lt;int&gt; \n├─RT = [3:0x166c78000] &lt;fct&gt; \n├─SERIALNO = [4:0x10d800000] &lt;chr&gt; \n├─PUMA = [5:0x116800000] &lt;chr&gt; \n├─ST = [6:0x118280000] &lt;chr&gt; \n├─ADJUST = [7:0x147300000] &lt;int&gt; \n├─PWGTP = [8:0x3386a8000] &lt;int&gt; \n├─AGEP = [9:0x3393e8000] &lt;int&gt; \n├─CIT = [10:0x33a128000] &lt;fct&gt; \n├─COW = [11:0x33ae68000] &lt;fct&gt; \n├─DDRS = [12:0x140900000] &lt;lgl&gt; \n├─DEYE = [13:0x300018000] &lt;lgl&gt; \n├─DOUT = [14:0x3006b8000] &lt;lgl&gt; \n├─DPHY = [15:0x308008000] &lt;lgl&gt; \n├─DREM = [16:0x178140000] &lt;lgl&gt; \n├─DWRK = [17:0x1787e0000] &lt;lgl&gt; \n├─ENG = [18:0x33bba8000] &lt;fct&gt; \n├─FER = [19:0x120878000] &lt;lgl&gt; \n├─GCL = [20:0x161608000] &lt;lgl&gt; \n├─GCM = [21:0x33c8e8000] &lt;fct&gt; \n├─GCR = [22:0x140fa0000] &lt;lgl&gt; \n├─INTP = [23:0x33d628000] &lt;int&gt; \n├─JWMNP = [24:0x33e368000] &lt;int&gt; \n├─JWRIP = [25:0x11e200000] &lt;chr&gt; \n├─JWTR = [26:0x128000000] &lt;chr&gt; \n├─LANX = [27:0x141640000] &lt;lgl&gt; \n├─MAR = [28:0x33f0a8000] &lt;fct&gt; \n├─MIG = [29:0x141ce0000] &lt;lgl&gt; \n├─MIL = [30:0x340008000] &lt;fct&gt; \n├─MILY = [31:0x340d48000] &lt;fct&gt; \n├─MLPA = [32:0x310008000] &lt;lgl&gt; \n├─MLPB = [33:0x142380000] &lt;lgl&gt; \n├─MLPC = [34:0x142a20000] &lt;lgl&gt; \n├─MLPD = [35:0x318008000] &lt;lgl&gt; \n├─MLPE = [36:0x161ca8000] &lt;lgl&gt; \n├─MLPF = [37:0x162348000] &lt;lgl&gt; \n├─MLPG = [38:0x1629e8000] &lt;lgl&gt; \n├─MLPH = [39:0x1300c8000] &lt;lgl&gt; \n├─MLPI = [40:0x1430c0000] &lt;lgl&gt; \n├─MLPJ = [41:0x3186a8000] &lt;lgl&gt; \n├─MLPK = [42:0x318d48000] &lt;lgl&gt; \n├─NWAB = [43:0x3193e8000] &lt;lgl&gt; \n├─NWAV = [44:0x341a88000] &lt;fct&gt; \n├─NWLA = [45:0x319a88000] &lt;lgl&gt; \n├─NWLK = [46:0x31a128000] &lt;lgl&gt; \n├─NWRE = [47:0x120f18000] &lt;lgl&gt; \n├─OIP = [48:0x3427c8000] &lt;int&gt; \n├─PAP = [49:0x343508000] &lt;int&gt; \n├─REL = [50:0x12c000000] &lt;chr&gt; \n├─RETP = [51:0x303bb8000] &lt;int&gt; \n├─SCH = [52:0x1215b8000] &lt;lgl&gt; \n├─SCHG = [53:0x12da80000] &lt;chr&gt; \n├─SCHL = [54:0x138000000] &lt;chr&gt; \n├─SEMP = [55:0x330410000] &lt;int&gt; \n├─SEX = [56:0x331150000] &lt;fct&gt; \n├─SSIP = [57:0x331e90000] &lt;int&gt; \n├─SSP = [58:0x332bd0000] &lt;int&gt; \n├─WAGP = [59:0x333910000] &lt;int&gt; \n├─WKHP = [60:0x334650000] &lt;int&gt; \n├─WKL = [61:0x335390000] &lt;fct&gt; \n├─WKW = [62:0x3360d0000] &lt;fct&gt; \n├─YOEP = [63:0x13b800000] &lt;chr&gt; \n├─UWRK = [64:0x121c58000] &lt;lgl&gt; \n├─ANC = [65:0x336e10000] &lt;fct&gt; \n├─ANC1P = [66:0x13d280000] &lt;chr&gt; \n├─ANC2P = [67:0x13ed00000] &lt;chr&gt; \n├─DECADE = [68:0x344248000] &lt;fct&gt; \n├─DRIVESP = [69:0x344f88000] &lt;fct&gt; \n├─DS = [70:0x1222f8000] &lt;lgl&gt; \n├─ESP = [71:0x345cc8000] &lt;fct&gt; \n├─ESR = [72:0x346a08000] &lt;fct&gt; \n├─HISP = [73:0x148d40000] &lt;chr&gt; \n├─INDP = [74:0x14dd40000] &lt;chr&gt; \n├─JWAP = [75:0x158000000] &lt;chr&gt; \n├─JWDP = [76:0x15b800000] &lt;chr&gt; \n├─LANP = [77:0x15d280000] &lt;chr&gt; \n├─MIGPUMA = [78:0x156298000] &lt;fct&gt; \n├─MIGSP = [79:0x15ed00000] &lt;chr&gt; \n├─MSP = [80:0x126bd8000] &lt;fct&gt; \n├─NAICSP = [81:0x168d40000] &lt;chr&gt; \n├─NATIVITY = [82:0x127918000] &lt;fct&gt; \n├─OC = [83:0x178e80000] &lt;lgl&gt; \n├─OCCP = [84:0x16a7c0000] &lt;chr&gt; \n├─PAOC = [85:0x3486a8000] &lt;fct&gt; \n├─PERNP = [86:0x3493e8000] &lt;int&gt; \n├─PINCP = [87:0x34a128000] &lt;int&gt; \n├─POBP = [88:0x1711a0000] &lt;chr&gt; \n├─POVPIP = [89:0x34ae68000] &lt;int&gt; \n├─POWPUMA = [90:0x34bba8000] &lt;fct&gt; \n├─POWSP = [91:0x172c20000] &lt;chr&gt; \n├─QTRBIR = [92:0x34c8e8000] &lt;fct&gt; \n├─RAC1P = [93:0x34d628000] &lt;fct&gt; \n├─RAC2P = [94:0x1746a0000] &lt;chr&gt; \n├─RAC3P = [95:0x176120000] &lt;chr&gt; \n├─RACAIAN = [96:0x122998000] &lt;lgl&gt; \n├─RACASN = [97:0x320008000] &lt;lgl&gt; \n├─RACBLK = [98:0x130768000] &lt;lgl&gt; \n├─RACNHPI = [99:0x3206a8000] &lt;lgl&gt; \n├─RACNUM = [100:0x34e368000] &lt;int&gt; \n├─RACSOR = [101:0x163088000] &lt;lgl&gt; \n├─RACWHT = [102:0x3086a8000] &lt;lgl&gt; \n├─RC = [103:0x31a7c8000] &lt;lgl&gt; \n├─SFN = [104:0x34f0a8000] &lt;fct&gt; \n├─SFR = [105:0x350008000] &lt;fct&gt; \n├─SOCP = [106:0x358000000] &lt;chr&gt; \n├─VPS = [107:0x359a80000] &lt;chr&gt; \n├─WAOB = [108:0x350d48000] &lt;fct&gt; \n├─FAGEP = [109:0x150c78000] &lt;lgl&gt; \n├─FANCP = [110:0x143760000] &lt;lgl&gt; \n├─FCITP = [111:0x320d48000] &lt;lgl&gt; \n├─FCOWP = [112:0x300d58000] &lt;lgl&gt; \n├─FDDRSP = [113:0x130e08000] &lt;lgl&gt; \n├─FDEYEP = [114:0x179520000] &lt;lgl&gt; \n├─FDOUTP = [115:0x179bc0000] &lt;lgl&gt; \n├─FDPHYP = [116:0x151318000] &lt;lgl&gt; \n├─FDREMP = [117:0x3106a8000] &lt;lgl&gt; \n├─FDWRKP = [118:0x17a260000] &lt;lgl&gt; \n├─FENGP = [119:0x17a900000] &lt;lgl&gt; \n├─FESRP = [120:0x17afa0000] &lt;lgl&gt; \n├─FFERP = [121:0x123038000] &lt;lgl&gt; \n├─FGCLP = [122:0x1236d8000] &lt;lgl&gt; \n├─FGCMP = [123:0x1519b8000] &lt;lgl&gt; \n├─FGCRP = [124:0x3213e8000] &lt;lgl&gt; \n├─FHISP = [125:0x123d78000] &lt;lgl&gt; \n├─FINDP = [126:0x124418000] &lt;lgl&gt; \n├─FINTP = [127:0x124ab8000] &lt;lgl&gt; \n├─FJWDP = [128:0x163728000] &lt;lgl&gt; \n├─FJWMNP = [129:0x321a88000] &lt;lgl&gt; \n├─FJWRIP = [130:0x310d48000] &lt;lgl&gt; \n├─FJWTRP = [131:0x31ae68000] &lt;lgl&gt; \n├─FLANP = [132:0x31b508000] &lt;lgl&gt; \n├─FLANXP = [133:0x308d48000] &lt;lgl&gt; \n├─FMARP = [134:0x3013f8000] &lt;lgl&gt; \n├─FMIGP = [135:0x301a98000] &lt;lgl&gt; \n├─FMIGSP = [136:0x322128000] &lt;lgl&gt; \n├─FMILPP = [137:0x17b640000] &lt;lgl&gt; \n├─FMILSP = [138:0x17bce0000] &lt;lgl&gt; \n├─FMILYP = [139:0x3093e8000] &lt;lgl&gt; \n├─FOCCP = [140:0x309a88000] &lt;lgl&gt; \n├─FOIP = [141:0x30a128000] &lt;lgl&gt; \n├─FPAP = [142:0x143e00000] &lt;lgl&gt; \n├─FPOBP = [143:0x1444a0000] &lt;lgl&gt; \n├─FPOWSP = [144:0x125158000] &lt;lgl&gt; \n├─FRACP = [145:0x1257f8000] &lt;lgl&gt; \n├─FRELP = [146:0x17c380000] &lt;lgl&gt; \n├─FRETP = [147:0x152058000] &lt;lgl&gt; \n├─FSCHGP = [148:0x1526f8000] &lt;lgl&gt; \n├─FSCHLP = [149:0x152d98000] &lt;lgl&gt; \n├─FSCHP = [150:0x163dc8000] &lt;lgl&gt; \n├─FSEMP = [151:0x144b40000] &lt;lgl&gt; \n├─FSEXP = [152:0x1451e0000] &lt;lgl&gt; \n├─FSSIP = [153:0x302138000] &lt;lgl&gt; \n├─FSSP = [154:0x3027d8000] &lt;lgl&gt; \n├─FWAGP = [155:0x302e78000] &lt;lgl&gt; \n├─FWKHP = [156:0x303518000] &lt;lgl&gt; \n├─FWKLP = [157:0x30a7c8000] &lt;lgl&gt; \n├─FWKWP = [158:0x30ae68000] &lt;lgl&gt; \n├─FYOEP = [159:0x17ca20000] &lt;lgl&gt; \n├─PWGTP1 = [160:0x351a88000] &lt;int&gt; \n├─PWGTP2 = [161:0x3527c8000] &lt;int&gt; \n├─PWGTP3 = [162:0x353508000] &lt;int&gt; \n├─PWGTP4 = [163:0x354248000] &lt;int&gt; \n├─PWGTP5 = [164:0x354f88000] &lt;int&gt; \n├─PWGTP6 = [165:0x1321e8000] &lt;int&gt; \n├─PWGTP7 = [166:0x360008000] &lt;int&gt; \n├─PWGTP8 = [167:0x360d48000] &lt;int&gt; \n├─PWGTP9 = [168:0x361a88000] &lt;int&gt; \n├─PWGTP10 = [169:0x3627c8000] &lt;int&gt; \n├─PWGTP11 = [170:0x363508000] &lt;int&gt; \n├─PWGTP12 = [171:0x364248000] &lt;int&gt; \n├─PWGTP13 = [172:0x347748000] &lt;int&gt; \n├─PWGTP14 = [173:0x3686a8000] &lt;int&gt; \n├─PWGTP15 = [174:0x3693e8000] &lt;int&gt; \n├─PWGTP16 = [175:0x355cc8000] &lt;int&gt; \n├─PWGTP17 = [176:0x36a128000] &lt;int&gt; \n├─PWGTP18 = [177:0x36ae68000] &lt;int&gt; \n├─PWGTP19 = [178:0x36bba8000] &lt;int&gt; \n├─PWGTP20 = [179:0x36c8e8000] &lt;int&gt; \n├─PWGTP21 = [180:0x156fd8000] &lt;int&gt; \n├─PWGTP22 = [181:0x370008000] &lt;int&gt; \n├─PWGTP23 = [182:0x370d48000] &lt;int&gt; \n├─PWGTP24 = [183:0x371a88000] &lt;int&gt; \n├─PWGTP25 = [184:0x3727c8000] &lt;int&gt; \n├─PWGTP26 = [185:0x364f88000] &lt;int&gt; \n├─PWGTP27 = [186:0x365cc8000] &lt;int&gt; \n├─PWGTP28 = [187:0x366a08000] &lt;int&gt; \n├─PWGTP29 = [188:0x367748000] &lt;int&gt; \n├─PWGTP30 = [189:0x3786a8000] &lt;int&gt; \n├─PWGTP31 = [190:0x3793e8000] &lt;int&gt; \n├─PWGTP32 = [191:0x37a128000] &lt;int&gt; \n├─PWGTP33 = [192:0x37ae68000] &lt;int&gt; \n├─PWGTP34 = [193:0x37bba8000] &lt;int&gt; \n├─PWGTP35 = [194:0x37c8e8000] &lt;int&gt; \n├─PWGTP36 = [195:0x37d628000] &lt;int&gt; \n├─PWGTP37 = [196:0x37e368000] &lt;int&gt; \n├─PWGTP38 = [197:0x37f0a8000] &lt;int&gt; \n├─PWGTP39 = [198:0x380008000] &lt;int&gt; \n├─PWGTP40 = [199:0x36d628000] &lt;int&gt; \n├─PWGTP41 = [200:0x36e368000] &lt;int&gt; \n├─PWGTP42 = [201:0x373508000] &lt;int&gt; \n├─PWGTP43 = [202:0x374248000] &lt;int&gt; \n├─PWGTP44 = [203:0x380d48000] &lt;int&gt; \n├─PWGTP45 = [204:0x381a88000] &lt;int&gt; \n├─PWGTP46 = [205:0x3827c8000] &lt;int&gt; \n├─PWGTP47 = [206:0x383508000] &lt;int&gt; \n├─PWGTP48 = [207:0x384248000] &lt;int&gt; \n├─PWGTP49 = [208:0x384f88000] &lt;int&gt; \n├─PWGTP50 = [209:0x385cc8000] &lt;int&gt; \n├─PWGTP51 = [210:0x386a08000] &lt;int&gt; \n├─PWGTP52 = [211:0x387748000] &lt;int&gt; \n├─PWGTP53 = [212:0x356a08000] &lt;int&gt; \n├─PWGTP54 = [213:0x357748000] &lt;int&gt; \n├─PWGTP55 = [214:0x3906a8000] &lt;int&gt; \n├─PWGTP56 = [215:0x3913e8000] &lt;int&gt; \n├─PWGTP57 = [216:0x392128000] &lt;int&gt; \n├─PWGTP58 = [217:0x392e68000] &lt;int&gt; \n├─PWGTP59 = [218:0x393ba8000] &lt;int&gt; \n├─PWGTP60 = [219:0x3948e8000] &lt;int&gt; \n├─PWGTP61 = [220:0x395628000] &lt;int&gt; \n├─PWGTP62 = [221:0x396368000] &lt;int&gt; \n├─PWGTP63 = [222:0x3970a8000] &lt;int&gt; \n├─PWGTP64 = [223:0x398008000] &lt;int&gt; \n├─PWGTP65 = [224:0x398d48000] &lt;int&gt; \n├─PWGTP66 = [225:0x399a88000] &lt;int&gt; \n├─PWGTP67 = [226:0x39a7c8000] &lt;int&gt; \n├─PWGTP68 = [227:0x39b508000] &lt;int&gt; \n├─PWGTP69 = [228:0x39c248000] &lt;int&gt; \n├─PWGTP70 = [229:0x39cf88000] &lt;int&gt; \n├─PWGTP71 = [230:0x39dcc8000] &lt;int&gt; \n├─PWGTP72 = [231:0x39ea08000] &lt;int&gt; \n├─PWGTP73 = [232:0x39f748000] &lt;int&gt; \n├─PWGTP74 = [233:0x3a06a8000] &lt;int&gt; \n├─PWGTP75 = [234:0x374f88000] &lt;int&gt; \n├─PWGTP76 = [235:0x36f0a8000] &lt;int&gt; \n├─PWGTP77 = [236:0x3a8008000] &lt;int&gt; \n├─PWGTP78 = [237:0x3a8d48000] &lt;int&gt; \n├─PWGTP79 = [238:0x3a9a88000] &lt;int&gt; \n├─PWGTP80 = [239:0x3aa7c8000] &lt;int&gt; \n├─NOP = [240:0x3ab508000] &lt;fct&gt; \n├─ADJINC = [241:0x35b500000] &lt;dbl&gt; \n├─CITWP = [242:0x35cf80000] &lt;chr&gt; \n├─DEAR = [243:0x31bba8000] &lt;lgl&gt; \n├─DRAT = [244:0x3886a8000] &lt;fct&gt; \n├─DRATX = [245:0x153438000] &lt;lgl&gt; \n├─HINS1 = [246:0x153ad8000] &lt;lgl&gt; \n├─HINS2 = [247:0x145880000] &lt;lgl&gt; \n├─HINS3 = [248:0x145f20000] &lt;lgl&gt; \n├─HINS4 = [249:0x1465c0000] &lt;lgl&gt; \n├─HINS5 = [250:0x31c248000] &lt;lgl&gt; \n├─HINS6 = [251:0x31c8e8000] &lt;lgl&gt; \n├─HINS7 = [252:0x164468000] &lt;lgl&gt; \n├─MARHD = [253:0x164b08000] &lt;lgl&gt; \n├─MARHM = [254:0x1314a8000] &lt;lgl&gt; \n├─MARHT = [255:0x3893e8000] &lt;fct&gt; \n├─MARHW = [256:0x125e98000] &lt;lgl&gt; \n├─MARHYP = [257:0x35ea00000] &lt;chr&gt; \n├─DIS = [258:0x154178000] &lt;lgl&gt; \n├─HICOV = [259:0x1651a8000] &lt;lgl&gt; \n├─PRIVCOV = [260:0x165848000] &lt;lgl&gt; \n├─PUBCOV = [261:0x3227c8000] &lt;lgl&gt; \n├─FCITWP = [262:0x154818000] &lt;lgl&gt; \n├─FDEARP = [263:0x322e68000] &lt;lgl&gt; \n├─FDRATP = [264:0x323508000] &lt;lgl&gt; \n├─FDRATXP = [265:0x17d0c0000] &lt;lgl&gt; \n├─FHINS1P = [266:0x17d760000] &lt;lgl&gt; \n├─FHINS2P = [267:0x328008000] &lt;lgl&gt; \n├─FHINS3P = [268:0x154eb8000] &lt;lgl&gt; \n├─FHINS4P = [269:0x155558000] &lt;lgl&gt; \n├─FHINS5P = [270:0x30b508000] &lt;lgl&gt; \n├─FHINS6P = [271:0x31cf88000] &lt;lgl&gt; \n├─FHINS7P = [272:0x3113e8000] &lt;lgl&gt; \n├─FMARHDP = [273:0x3286a8000] &lt;lgl&gt; \n├─FMARHMP = [274:0x328d48000] &lt;lgl&gt; \n├─FMARHTP = [275:0x323ba8000] &lt;lgl&gt; \n├─FMARHWP = [276:0x324248000] &lt;lgl&gt; \n├─FMARHYP = [277:0x3248e8000] &lt;lgl&gt; \n├─WRK = [278:0x146c60000] &lt;lgl&gt; \n├─FOD1P = [279:0x3b0d40000] &lt;chr&gt; \n├─FOD2P = [280:0x3b27c0000] &lt;chr&gt; \n├─SCIENGP = [281:0x311a88000] &lt;lgl&gt; \n├─SCIENGRLP = [282:0x17de00000] &lt;lgl&gt; \n├─FFODP = [283:0x30bba8000] &lt;lgl&gt; \n├─FHINS3C = [284:0x38a128000] &lt;fct&gt; \n├─FHINS4C = [285:0x38ae68000] &lt;fct&gt; \n├─FHINS5C = [286:0x38bba8000] &lt;fct&gt; \n├─RELP = [287:0x3b4240000] &lt;chr&gt; \n├─FWRKP = [288:0x17e4a0000] &lt;lgl&gt; \n├─FDISP = [289:0x17eb40000] &lt;lgl&gt; \n├─FPERNP = [290:0x17f1e0000] &lt;lgl&gt; \n├─FPINCP = [291:0x31d628000] &lt;lgl&gt; \n├─FPRIVCOVP = [292:0x31dcc8000] &lt;lgl&gt; \n├─FPUBCOVP = [293:0x31e368000] &lt;lgl&gt; \n├─RACNH = [294:0x126538000] &lt;lgl&gt; \n├─RACPI = [295:0x3293e8000] &lt;lgl&gt; \n├─SSPA = [296:0x38c8e8000] &lt;fct&gt; \n├─MLPCD = [297:0x329a88000] &lt;lgl&gt; \n├─MLPFG = [298:0x32a128000] &lt;lgl&gt; \n├─FHICOVP = [299:0x32a7c8000] &lt;lgl&gt; \n├─DIVISION = [300:0x38d628000] &lt;fct&gt; \n├─REGION = [301:0x38e368000] &lt;fct&gt; \n├─HIMRKS = [302:0x38f0a8000] &lt;fct&gt; \n├─JWTRNS = [303:0x3b5cc0000] &lt;chr&gt; \n├─RELSHIPP = [304:0x3b7740000] &lt;chr&gt; \n├─WKWN = [305:0x132f28000] &lt;int&gt; \n├─FHIMRKSP = [306:0x131b48000] &lt;lgl&gt; \n├─FJWTRNSP = [307:0x155bf8000] &lt;lgl&gt; \n├─FRELSHIPP = [308:0x32ae68000] &lt;lgl&gt; \n├─FWKWNP = [309:0x32b508000] &lt;lgl&gt; \n├─MLPIK = [310:0x32bba8000] &lt;lgl&gt; \n├─year = [311:0x133c68000] &lt;int&gt; \n├─location = [312:0x3b91c0000] &lt;chr&gt; \n├─age_groups = [313:0x15c540000] &lt;chr&gt; \n├─ins_type = [314:0x15dfc0000] &lt;chr&gt; \n└─age_decade = [315:0x35dcc0000] &lt;dbl&gt; \n\n\n\n\nlobstr::ref(pums_nocopy)\n\n█ [1:0x10d207e00] &lt;dt[,314]&gt; \n├─SPORDER = [2:0x165f38000] &lt;int&gt; \n├─RT = [3:0x166c78000] &lt;fct&gt; \n├─SERIALNO = [4:0x10d800000] &lt;chr&gt; \n├─PUMA = [5:0x116800000] &lt;chr&gt; \n├─ST = [6:0x118280000] &lt;chr&gt; \n├─ADJUST = [7:0x147300000] &lt;int&gt; \n├─PWGTP = [8:0x3386a8000] &lt;int&gt; \n├─AGEP = [9:0x3393e8000] &lt;int&gt; \n├─CIT = [10:0x33a128000] &lt;fct&gt; \n├─COW = [11:0x33ae68000] &lt;fct&gt; \n├─DDRS = [12:0x140900000] &lt;lgl&gt; \n├─DEYE = [13:0x300018000] &lt;lgl&gt; \n├─DOUT = [14:0x3006b8000] &lt;lgl&gt; \n├─DPHY = [15:0x308008000] &lt;lgl&gt; \n├─DREM = [16:0x178140000] &lt;lgl&gt; \n├─DWRK = [17:0x1787e0000] &lt;lgl&gt; \n├─ENG = [18:0x33bba8000] &lt;fct&gt; \n├─FER = [19:0x120878000] &lt;lgl&gt; \n├─GCL = [20:0x161608000] &lt;lgl&gt; \n├─GCM = [21:0x33c8e8000] &lt;fct&gt; \n├─GCR = [22:0x140fa0000] &lt;lgl&gt; \n├─INTP = [23:0x33d628000] &lt;int&gt; \n├─JWMNP = [24:0x33e368000] &lt;int&gt; \n├─JWRIP = [25:0x11e200000] &lt;chr&gt; \n├─JWTR = [26:0x128000000] &lt;chr&gt; \n├─LANX = [27:0x141640000] &lt;lgl&gt; \n├─MAR = [28:0x33f0a8000] &lt;fct&gt; \n├─MIG = [29:0x141ce0000] &lt;lgl&gt; \n├─MIL = [30:0x340008000] &lt;fct&gt; \n├─MILY = [31:0x340d48000] &lt;fct&gt; \n├─MLPA = [32:0x310008000] &lt;lgl&gt; \n├─MLPB = [33:0x142380000] &lt;lgl&gt; \n├─MLPC = [34:0x142a20000] &lt;lgl&gt; \n├─MLPD = [35:0x318008000] &lt;lgl&gt; \n├─MLPE = [36:0x161ca8000] &lt;lgl&gt; \n├─MLPF = [37:0x162348000] &lt;lgl&gt; \n├─MLPG = [38:0x1629e8000] &lt;lgl&gt; \n├─MLPH = [39:0x1300c8000] &lt;lgl&gt; \n├─MLPI = [40:0x1430c0000] &lt;lgl&gt; \n├─MLPJ = [41:0x3186a8000] &lt;lgl&gt; \n├─MLPK = [42:0x318d48000] &lt;lgl&gt; \n├─NWAB = [43:0x3193e8000] &lt;lgl&gt; \n├─NWAV = [44:0x341a88000] &lt;fct&gt; \n├─NWLA = [45:0x319a88000] &lt;lgl&gt; \n├─NWLK = [46:0x31a128000] &lt;lgl&gt; \n├─NWRE = [47:0x120f18000] &lt;lgl&gt; \n├─OIP = [48:0x3427c8000] &lt;int&gt; \n├─PAP = [49:0x343508000] &lt;int&gt; \n├─REL = [50:0x12c000000] &lt;chr&gt; \n├─RETP = [51:0x303bb8000] &lt;int&gt; \n├─SCH = [52:0x1215b8000] &lt;lgl&gt; \n├─SCHG = [53:0x12da80000] &lt;chr&gt; \n├─SCHL = [54:0x138000000] &lt;chr&gt; \n├─SEMP = [55:0x330410000] &lt;int&gt; \n├─SEX = [56:0x331150000] &lt;fct&gt; \n├─SSIP = [57:0x331e90000] &lt;int&gt; \n├─SSP = [58:0x332bd0000] &lt;int&gt; \n├─WAGP = [59:0x333910000] &lt;int&gt; \n├─WKHP = [60:0x334650000] &lt;int&gt; \n├─WKL = [61:0x335390000] &lt;fct&gt; \n├─WKW = [62:0x3360d0000] &lt;fct&gt; \n├─YOEP = [63:0x13b800000] &lt;chr&gt; \n├─UWRK = [64:0x121c58000] &lt;lgl&gt; \n├─ANC = [65:0x336e10000] &lt;fct&gt; \n├─ANC1P = [66:0x13d280000] &lt;chr&gt; \n├─ANC2P = [67:0x13ed00000] &lt;chr&gt; \n├─DECADE = [68:0x344248000] &lt;fct&gt; \n├─DRIVESP = [69:0x344f88000] &lt;fct&gt; \n├─DS = [70:0x1222f8000] &lt;lgl&gt; \n├─ESP = [71:0x345cc8000] &lt;fct&gt; \n├─ESR = [72:0x346a08000] &lt;fct&gt; \n├─HISP = [73:0x148d40000] &lt;chr&gt; \n├─INDP = [74:0x14dd40000] &lt;chr&gt; \n├─JWAP = [75:0x158000000] &lt;chr&gt; \n├─JWDP = [76:0x15b800000] &lt;chr&gt; \n├─LANP = [77:0x15d280000] &lt;chr&gt; \n├─MIGPUMA = [78:0x156298000] &lt;fct&gt; \n├─MIGSP = [79:0x15ed00000] &lt;chr&gt; \n├─MSP = [80:0x126bd8000] &lt;fct&gt; \n├─NAICSP = [81:0x168d40000] &lt;chr&gt; \n├─NATIVITY = [82:0x127918000] &lt;fct&gt; \n├─OC = [83:0x178e80000] &lt;lgl&gt; \n├─OCCP = [84:0x16a7c0000] &lt;chr&gt; \n├─PAOC = [85:0x3486a8000] &lt;fct&gt; \n├─PERNP = [86:0x3493e8000] &lt;int&gt; \n├─PINCP = [87:0x34a128000] &lt;int&gt; \n├─POBP = [88:0x1711a0000] &lt;chr&gt; \n├─POVPIP = [89:0x34ae68000] &lt;int&gt; \n├─POWPUMA = [90:0x34bba8000] &lt;fct&gt; \n├─POWSP = [91:0x172c20000] &lt;chr&gt; \n├─QTRBIR = [92:0x34c8e8000] &lt;fct&gt; \n├─RAC1P = [93:0x34d628000] &lt;fct&gt; \n├─RAC2P = [94:0x1746a0000] &lt;chr&gt; \n├─RAC3P = [95:0x176120000] &lt;chr&gt; \n├─RACAIAN = [96:0x122998000] &lt;lgl&gt; \n├─RACASN = [97:0x320008000] &lt;lgl&gt; \n├─RACBLK = [98:0x130768000] &lt;lgl&gt; \n├─RACNHPI = [99:0x3206a8000] &lt;lgl&gt; \n├─RACNUM = [100:0x34e368000] &lt;int&gt; \n├─RACSOR = [101:0x163088000] &lt;lgl&gt; \n├─RACWHT = [102:0x3086a8000] &lt;lgl&gt; \n├─RC = [103:0x31a7c8000] &lt;lgl&gt; \n├─SFN = [104:0x34f0a8000] &lt;fct&gt; \n├─SFR = [105:0x350008000] &lt;fct&gt; \n├─SOCP = [106:0x358000000] &lt;chr&gt; \n├─VPS = [107:0x359a80000] &lt;chr&gt; \n├─WAOB = [108:0x350d48000] &lt;fct&gt; \n├─FAGEP = [109:0x150c78000] &lt;lgl&gt; \n├─FANCP = [110:0x143760000] &lt;lgl&gt; \n├─FCITP = [111:0x320d48000] &lt;lgl&gt; \n├─FCOWP = [112:0x300d58000] &lt;lgl&gt; \n├─FDDRSP = [113:0x130e08000] &lt;lgl&gt; \n├─FDEYEP = [114:0x179520000] &lt;lgl&gt; \n├─FDOUTP = [115:0x179bc0000] &lt;lgl&gt; \n├─FDPHYP = [116:0x151318000] &lt;lgl&gt; \n├─FDREMP = [117:0x3106a8000] &lt;lgl&gt; \n├─FDWRKP = [118:0x17a260000] &lt;lgl&gt; \n├─FENGP = [119:0x17a900000] &lt;lgl&gt; \n├─FESRP = [120:0x17afa0000] &lt;lgl&gt; \n├─FFERP = [121:0x123038000] &lt;lgl&gt; \n├─FGCLP = [122:0x1236d8000] &lt;lgl&gt; \n├─FGCMP = [123:0x1519b8000] &lt;lgl&gt; \n├─FGCRP = [124:0x3213e8000] &lt;lgl&gt; \n├─FHISP = [125:0x123d78000] &lt;lgl&gt; \n├─FINDP = [126:0x124418000] &lt;lgl&gt; \n├─FINTP = [127:0x124ab8000] &lt;lgl&gt; \n├─FJWDP = [128:0x163728000] &lt;lgl&gt; \n├─FJWMNP = [129:0x321a88000] &lt;lgl&gt; \n├─FJWRIP = [130:0x310d48000] &lt;lgl&gt; \n├─FJWTRP = [131:0x31ae68000] &lt;lgl&gt; \n├─FLANP = [132:0x31b508000] &lt;lgl&gt; \n├─FLANXP = [133:0x308d48000] &lt;lgl&gt; \n├─FMARP = [134:0x3013f8000] &lt;lgl&gt; \n├─FMIGP = [135:0x301a98000] &lt;lgl&gt; \n├─FMIGSP = [136:0x322128000] &lt;lgl&gt; \n├─FMILPP = [137:0x17b640000] &lt;lgl&gt; \n├─FMILSP = [138:0x17bce0000] &lt;lgl&gt; \n├─FMILYP = [139:0x3093e8000] &lt;lgl&gt; \n├─FOCCP = [140:0x309a88000] &lt;lgl&gt; \n├─FOIP = [141:0x30a128000] &lt;lgl&gt; \n├─FPAP = [142:0x143e00000] &lt;lgl&gt; \n├─FPOBP = [143:0x1444a0000] &lt;lgl&gt; \n├─FPOWSP = [144:0x125158000] &lt;lgl&gt; \n├─FRACP = [145:0x1257f8000] &lt;lgl&gt; \n├─FRELP = [146:0x17c380000] &lt;lgl&gt; \n├─FRETP = [147:0x152058000] &lt;lgl&gt; \n├─FSCHGP = [148:0x1526f8000] &lt;lgl&gt; \n├─FSCHLP = [149:0x152d98000] &lt;lgl&gt; \n├─FSCHP = [150:0x163dc8000] &lt;lgl&gt; \n├─FSEMP = [151:0x144b40000] &lt;lgl&gt; \n├─FSEXP = [152:0x1451e0000] &lt;lgl&gt; \n├─FSSIP = [153:0x302138000] &lt;lgl&gt; \n├─FSSP = [154:0x3027d8000] &lt;lgl&gt; \n├─FWAGP = [155:0x302e78000] &lt;lgl&gt; \n├─FWKHP = [156:0x303518000] &lt;lgl&gt; \n├─FWKLP = [157:0x30a7c8000] &lt;lgl&gt; \n├─FWKWP = [158:0x30ae68000] &lt;lgl&gt; \n├─FYOEP = [159:0x17ca20000] &lt;lgl&gt; \n├─PWGTP1 = [160:0x351a88000] &lt;int&gt; \n├─PWGTP2 = [161:0x3527c8000] &lt;int&gt; \n├─PWGTP3 = [162:0x353508000] &lt;int&gt; \n├─PWGTP4 = [163:0x354248000] &lt;int&gt; \n├─PWGTP5 = [164:0x354f88000] &lt;int&gt; \n├─PWGTP6 = [165:0x1321e8000] &lt;int&gt; \n├─PWGTP7 = [166:0x360008000] &lt;int&gt; \n├─PWGTP8 = [167:0x360d48000] &lt;int&gt; \n├─PWGTP9 = [168:0x361a88000] &lt;int&gt; \n├─PWGTP10 = [169:0x3627c8000] &lt;int&gt; \n├─PWGTP11 = [170:0x363508000] &lt;int&gt; \n├─PWGTP12 = [171:0x364248000] &lt;int&gt; \n├─PWGTP13 = [172:0x347748000] &lt;int&gt; \n├─PWGTP14 = [173:0x3686a8000] &lt;int&gt; \n├─PWGTP15 = [174:0x3693e8000] &lt;int&gt; \n├─PWGTP16 = [175:0x355cc8000] &lt;int&gt; \n├─PWGTP17 = [176:0x36a128000] &lt;int&gt; \n├─PWGTP18 = [177:0x36ae68000] &lt;int&gt; \n├─PWGTP19 = [178:0x36bba8000] &lt;int&gt; \n├─PWGTP20 = [179:0x36c8e8000] &lt;int&gt; \n├─PWGTP21 = [180:0x156fd8000] &lt;int&gt; \n├─PWGTP22 = [181:0x370008000] &lt;int&gt; \n├─PWGTP23 = [182:0x370d48000] &lt;int&gt; \n├─PWGTP24 = [183:0x371a88000] &lt;int&gt; \n├─PWGTP25 = [184:0x3727c8000] &lt;int&gt; \n├─PWGTP26 = [185:0x364f88000] &lt;int&gt; \n├─PWGTP27 = [186:0x365cc8000] &lt;int&gt; \n├─PWGTP28 = [187:0x366a08000] &lt;int&gt; \n├─PWGTP29 = [188:0x367748000] &lt;int&gt; \n├─PWGTP30 = [189:0x3786a8000] &lt;int&gt; \n├─PWGTP31 = [190:0x3793e8000] &lt;int&gt; \n├─PWGTP32 = [191:0x37a128000] &lt;int&gt; \n├─PWGTP33 = [192:0x37ae68000] &lt;int&gt; \n├─PWGTP34 = [193:0x37bba8000] &lt;int&gt; \n├─PWGTP35 = [194:0x37c8e8000] &lt;int&gt; \n├─PWGTP36 = [195:0x37d628000] &lt;int&gt; \n├─PWGTP37 = [196:0x37e368000] &lt;int&gt; \n├─PWGTP38 = [197:0x37f0a8000] &lt;int&gt; \n├─PWGTP39 = [198:0x380008000] &lt;int&gt; \n├─PWGTP40 = [199:0x36d628000] &lt;int&gt; \n├─PWGTP41 = [200:0x36e368000] &lt;int&gt; \n├─PWGTP42 = [201:0x373508000] &lt;int&gt; \n├─PWGTP43 = [202:0x374248000] &lt;int&gt; \n├─PWGTP44 = [203:0x380d48000] &lt;int&gt; \n├─PWGTP45 = [204:0x381a88000] &lt;int&gt; \n├─PWGTP46 = [205:0x3827c8000] &lt;int&gt; \n├─PWGTP47 = [206:0x383508000] &lt;int&gt; \n├─PWGTP48 = [207:0x384248000] &lt;int&gt; \n├─PWGTP49 = [208:0x384f88000] &lt;int&gt; \n├─PWGTP50 = [209:0x385cc8000] &lt;int&gt; \n├─PWGTP51 = [210:0x386a08000] &lt;int&gt; \n├─PWGTP52 = [211:0x387748000] &lt;int&gt; \n├─PWGTP53 = [212:0x356a08000] &lt;int&gt; \n├─PWGTP54 = [213:0x357748000] &lt;int&gt; \n├─PWGTP55 = [214:0x3906a8000] &lt;int&gt; \n├─PWGTP56 = [215:0x3913e8000] &lt;int&gt; \n├─PWGTP57 = [216:0x392128000] &lt;int&gt; \n├─PWGTP58 = [217:0x392e68000] &lt;int&gt; \n├─PWGTP59 = [218:0x393ba8000] &lt;int&gt; \n├─PWGTP60 = [219:0x3948e8000] &lt;int&gt; \n├─PWGTP61 = [220:0x395628000] &lt;int&gt; \n├─PWGTP62 = [221:0x396368000] &lt;int&gt; \n├─PWGTP63 = [222:0x3970a8000] &lt;int&gt; \n├─PWGTP64 = [223:0x398008000] &lt;int&gt; \n├─PWGTP65 = [224:0x398d48000] &lt;int&gt; \n├─PWGTP66 = [225:0x399a88000] &lt;int&gt; \n├─PWGTP67 = [226:0x39a7c8000] &lt;int&gt; \n├─PWGTP68 = [227:0x39b508000] &lt;int&gt; \n├─PWGTP69 = [228:0x39c248000] &lt;int&gt; \n├─PWGTP70 = [229:0x39cf88000] &lt;int&gt; \n├─PWGTP71 = [230:0x39dcc8000] &lt;int&gt; \n├─PWGTP72 = [231:0x39ea08000] &lt;int&gt; \n├─PWGTP73 = [232:0x39f748000] &lt;int&gt; \n├─PWGTP74 = [233:0x3a06a8000] &lt;int&gt; \n├─PWGTP75 = [234:0x374f88000] &lt;int&gt; \n├─PWGTP76 = [235:0x36f0a8000] &lt;int&gt; \n├─PWGTP77 = [236:0x3a8008000] &lt;int&gt; \n├─PWGTP78 = [237:0x3a8d48000] &lt;int&gt; \n├─PWGTP79 = [238:0x3a9a88000] &lt;int&gt; \n├─PWGTP80 = [239:0x3aa7c8000] &lt;int&gt; \n├─NOP = [240:0x3ab508000] &lt;fct&gt; \n├─ADJINC = [241:0x35b500000] &lt;dbl&gt; \n├─CITWP = [242:0x35cf80000] &lt;chr&gt; \n├─DEAR = [243:0x31bba8000] &lt;lgl&gt; \n├─DRAT = [244:0x3886a8000] &lt;fct&gt; \n├─DRATX = [245:0x153438000] &lt;lgl&gt; \n├─HINS1 = [246:0x153ad8000] &lt;lgl&gt; \n├─HINS2 = [247:0x145880000] &lt;lgl&gt; \n├─HINS3 = [248:0x145f20000] &lt;lgl&gt; \n├─HINS4 = [249:0x1465c0000] &lt;lgl&gt; \n├─HINS5 = [250:0x31c248000] &lt;lgl&gt; \n├─HINS6 = [251:0x31c8e8000] &lt;lgl&gt; \n├─HINS7 = [252:0x164468000] &lt;lgl&gt; \n├─MARHD = [253:0x164b08000] &lt;lgl&gt; \n├─MARHM = [254:0x1314a8000] &lt;lgl&gt; \n├─MARHT = [255:0x3893e8000] &lt;fct&gt; \n├─MARHW = [256:0x125e98000] &lt;lgl&gt; \n├─MARHYP = [257:0x35ea00000] &lt;chr&gt; \n├─DIS = [258:0x154178000] &lt;lgl&gt; \n├─HICOV = [259:0x1651a8000] &lt;lgl&gt; \n├─PRIVCOV = [260:0x165848000] &lt;lgl&gt; \n├─PUBCOV = [261:0x3227c8000] &lt;lgl&gt; \n├─FCITWP = [262:0x154818000] &lt;lgl&gt; \n├─FDEARP = [263:0x322e68000] &lt;lgl&gt; \n├─FDRATP = [264:0x323508000] &lt;lgl&gt; \n├─FDRATXP = [265:0x17d0c0000] &lt;lgl&gt; \n├─FHINS1P = [266:0x17d760000] &lt;lgl&gt; \n├─FHINS2P = [267:0x328008000] &lt;lgl&gt; \n├─FHINS3P = [268:0x154eb8000] &lt;lgl&gt; \n├─FHINS4P = [269:0x155558000] &lt;lgl&gt; \n├─FHINS5P = [270:0x30b508000] &lt;lgl&gt; \n├─FHINS6P = [271:0x31cf88000] &lt;lgl&gt; \n├─FHINS7P = [272:0x3113e8000] &lt;lgl&gt; \n├─FMARHDP = [273:0x3286a8000] &lt;lgl&gt; \n├─FMARHMP = [274:0x328d48000] &lt;lgl&gt; \n├─FMARHTP = [275:0x323ba8000] &lt;lgl&gt; \n├─FMARHWP = [276:0x324248000] &lt;lgl&gt; \n├─FMARHYP = [277:0x3248e8000] &lt;lgl&gt; \n├─WRK = [278:0x146c60000] &lt;lgl&gt; \n├─FOD1P = [279:0x3b0d40000] &lt;chr&gt; \n├─FOD2P = [280:0x3b27c0000] &lt;chr&gt; \n├─SCIENGP = [281:0x311a88000] &lt;lgl&gt; \n├─SCIENGRLP = [282:0x17de00000] &lt;lgl&gt; \n├─FFODP = [283:0x30bba8000] &lt;lgl&gt; \n├─FHINS3C = [284:0x38a128000] &lt;fct&gt; \n├─FHINS4C = [285:0x38ae68000] &lt;fct&gt; \n├─FHINS5C = [286:0x38bba8000] &lt;fct&gt; \n├─RELP = [287:0x3b4240000] &lt;chr&gt; \n├─FWRKP = [288:0x17e4a0000] &lt;lgl&gt; \n├─FDISP = [289:0x17eb40000] &lt;lgl&gt; \n├─FPERNP = [290:0x17f1e0000] &lt;lgl&gt; \n├─FPINCP = [291:0x31d628000] &lt;lgl&gt; \n├─FPRIVCOVP = [292:0x31dcc8000] &lt;lgl&gt; \n├─FPUBCOVP = [293:0x31e368000] &lt;lgl&gt; \n├─RACNH = [294:0x126538000] &lt;lgl&gt; \n├─RACPI = [295:0x3293e8000] &lt;lgl&gt; \n├─SSPA = [296:0x38c8e8000] &lt;fct&gt; \n├─MLPCD = [297:0x329a88000] &lt;lgl&gt; \n├─MLPFG = [298:0x32a128000] &lt;lgl&gt; \n├─FHICOVP = [299:0x32a7c8000] &lt;lgl&gt; \n├─DIVISION = [300:0x38d628000] &lt;fct&gt; \n├─REGION = [301:0x38e368000] &lt;fct&gt; \n├─HIMRKS = [302:0x38f0a8000] &lt;fct&gt; \n├─JWTRNS = [303:0x3b5cc0000] &lt;chr&gt; \n├─RELSHIPP = [304:0x3b7740000] &lt;chr&gt; \n├─WKWN = [305:0x132f28000] &lt;int&gt; \n├─FHIMRKSP = [306:0x131b48000] &lt;lgl&gt; \n├─FJWTRNSP = [307:0x155bf8000] &lt;lgl&gt; \n├─FRELSHIPP = [308:0x32ae68000] &lt;lgl&gt; \n├─FWKWNP = [309:0x32b508000] &lt;lgl&gt; \n├─MLPIK = [310:0x32bba8000] &lt;lgl&gt; \n├─year = [311:0x133c68000] &lt;int&gt; \n├─location = [312:0x3b91c0000] &lt;chr&gt; \n├─age_groups = [313:0x15c540000] &lt;chr&gt; \n├─ins_type = [314:0x15dfc0000] &lt;chr&gt; \n└─age_decade = [315:0x35dcc0000] &lt;dbl&gt;"
  },
  {
    "objectID": "materials/slides/02-datatable.html#memory-efficient-1",
    "href": "materials/slides/02-datatable.html#memory-efficient-1",
    "title": "data.table",
    "section": "3. Memory Efficient",
    "text": "3. Memory Efficient\nModify by reference - no copies\n\n# Deep Copy (full dataset copied)\npums_copy &lt;- copy(pums)\n\n# adding variable to this does not alter the original\npums_copy[, age_decade := floor(AGEP / 10) * 10]\n\n\n\n\n\nlobstr::ref(pums)\n\n█ [1:0x10d207e00] &lt;dt[,314]&gt; \n├─SPORDER = [2:0x165f38000] &lt;int&gt; \n├─RT = [3:0x166c78000] &lt;fct&gt; \n├─SERIALNO = [4:0x10d800000] &lt;chr&gt; \n├─PUMA = [5:0x116800000] &lt;chr&gt; \n├─ST = [6:0x118280000] &lt;chr&gt; \n├─ADJUST = [7:0x147300000] &lt;int&gt; \n├─PWGTP = [8:0x3386a8000] &lt;int&gt; \n├─AGEP = [9:0x3393e8000] &lt;int&gt; \n├─CIT = [10:0x33a128000] &lt;fct&gt; \n├─COW = [11:0x33ae68000] &lt;fct&gt; \n├─DDRS = [12:0x140900000] &lt;lgl&gt; \n├─DEYE = [13:0x300018000] &lt;lgl&gt; \n├─DOUT = [14:0x3006b8000] &lt;lgl&gt; \n├─DPHY = [15:0x308008000] &lt;lgl&gt; \n├─DREM = [16:0x178140000] &lt;lgl&gt; \n├─DWRK = [17:0x1787e0000] &lt;lgl&gt; \n├─ENG = [18:0x33bba8000] &lt;fct&gt; \n├─FER = [19:0x120878000] &lt;lgl&gt; \n├─GCL = [20:0x161608000] &lt;lgl&gt; \n├─GCM = [21:0x33c8e8000] &lt;fct&gt; \n├─GCR = [22:0x140fa0000] &lt;lgl&gt; \n├─INTP = [23:0x33d628000] &lt;int&gt; \n├─JWMNP = [24:0x33e368000] &lt;int&gt; \n├─JWRIP = [25:0x11e200000] &lt;chr&gt; \n├─JWTR = [26:0x128000000] &lt;chr&gt; \n├─LANX = [27:0x141640000] &lt;lgl&gt; \n├─MAR = [28:0x33f0a8000] &lt;fct&gt; \n├─MIG = [29:0x141ce0000] &lt;lgl&gt; \n├─MIL = [30:0x340008000] &lt;fct&gt; \n├─MILY = [31:0x340d48000] &lt;fct&gt; \n├─MLPA = [32:0x310008000] &lt;lgl&gt; \n├─MLPB = [33:0x142380000] &lt;lgl&gt; \n├─MLPC = [34:0x142a20000] &lt;lgl&gt; \n├─MLPD = [35:0x318008000] &lt;lgl&gt; \n├─MLPE = [36:0x161ca8000] &lt;lgl&gt; \n├─MLPF = [37:0x162348000] &lt;lgl&gt; \n├─MLPG = [38:0x1629e8000] &lt;lgl&gt; \n├─MLPH = [39:0x1300c8000] &lt;lgl&gt; \n├─MLPI = [40:0x1430c0000] &lt;lgl&gt; \n├─MLPJ = [41:0x3186a8000] &lt;lgl&gt; \n├─MLPK = [42:0x318d48000] &lt;lgl&gt; \n├─NWAB = [43:0x3193e8000] &lt;lgl&gt; \n├─NWAV = [44:0x341a88000] &lt;fct&gt; \n├─NWLA = [45:0x319a88000] &lt;lgl&gt; \n├─NWLK = [46:0x31a128000] &lt;lgl&gt; \n├─NWRE = [47:0x120f18000] &lt;lgl&gt; \n├─OIP = [48:0x3427c8000] &lt;int&gt; \n├─PAP = [49:0x343508000] &lt;int&gt; \n├─REL = [50:0x12c000000] &lt;chr&gt; \n├─RETP = [51:0x303bb8000] &lt;int&gt; \n├─SCH = [52:0x1215b8000] &lt;lgl&gt; \n├─SCHG = [53:0x12da80000] &lt;chr&gt; \n├─SCHL = [54:0x138000000] &lt;chr&gt; \n├─SEMP = [55:0x330410000] &lt;int&gt; \n├─SEX = [56:0x331150000] &lt;fct&gt; \n├─SSIP = [57:0x331e90000] &lt;int&gt; \n├─SSP = [58:0x332bd0000] &lt;int&gt; \n├─WAGP = [59:0x333910000] &lt;int&gt; \n├─WKHP = [60:0x334650000] &lt;int&gt; \n├─WKL = [61:0x335390000] &lt;fct&gt; \n├─WKW = [62:0x3360d0000] &lt;fct&gt; \n├─YOEP = [63:0x13b800000] &lt;chr&gt; \n├─UWRK = [64:0x121c58000] &lt;lgl&gt; \n├─ANC = [65:0x336e10000] &lt;fct&gt; \n├─ANC1P = [66:0x13d280000] &lt;chr&gt; \n├─ANC2P = [67:0x13ed00000] &lt;chr&gt; \n├─DECADE = [68:0x344248000] &lt;fct&gt; \n├─DRIVESP = [69:0x344f88000] &lt;fct&gt; \n├─DS = [70:0x1222f8000] &lt;lgl&gt; \n├─ESP = [71:0x345cc8000] &lt;fct&gt; \n├─ESR = [72:0x346a08000] &lt;fct&gt; \n├─HISP = [73:0x148d40000] &lt;chr&gt; \n├─INDP = [74:0x14dd40000] &lt;chr&gt; \n├─JWAP = [75:0x158000000] &lt;chr&gt; \n├─JWDP = [76:0x15b800000] &lt;chr&gt; \n├─LANP = [77:0x15d280000] &lt;chr&gt; \n├─MIGPUMA = [78:0x156298000] &lt;fct&gt; \n├─MIGSP = [79:0x15ed00000] &lt;chr&gt; \n├─MSP = [80:0x126bd8000] &lt;fct&gt; \n├─NAICSP = [81:0x168d40000] &lt;chr&gt; \n├─NATIVITY = [82:0x127918000] &lt;fct&gt; \n├─OC = [83:0x178e80000] &lt;lgl&gt; \n├─OCCP = [84:0x16a7c0000] &lt;chr&gt; \n├─PAOC = [85:0x3486a8000] &lt;fct&gt; \n├─PERNP = [86:0x3493e8000] &lt;int&gt; \n├─PINCP = [87:0x34a128000] &lt;int&gt; \n├─POBP = [88:0x1711a0000] &lt;chr&gt; \n├─POVPIP = [89:0x34ae68000] &lt;int&gt; \n├─POWPUMA = [90:0x34bba8000] &lt;fct&gt; \n├─POWSP = [91:0x172c20000] &lt;chr&gt; \n├─QTRBIR = [92:0x34c8e8000] &lt;fct&gt; \n├─RAC1P = [93:0x34d628000] &lt;fct&gt; \n├─RAC2P = [94:0x1746a0000] &lt;chr&gt; \n├─RAC3P = [95:0x176120000] &lt;chr&gt; \n├─RACAIAN = [96:0x122998000] &lt;lgl&gt; \n├─RACASN = [97:0x320008000] &lt;lgl&gt; \n├─RACBLK = [98:0x130768000] &lt;lgl&gt; \n├─RACNHPI = [99:0x3206a8000] &lt;lgl&gt; \n├─RACNUM = [100:0x34e368000] &lt;int&gt; \n├─RACSOR = [101:0x163088000] &lt;lgl&gt; \n├─RACWHT = [102:0x3086a8000] &lt;lgl&gt; \n├─RC = [103:0x31a7c8000] &lt;lgl&gt; \n├─SFN = [104:0x34f0a8000] &lt;fct&gt; \n├─SFR = [105:0x350008000] &lt;fct&gt; \n├─SOCP = [106:0x358000000] &lt;chr&gt; \n├─VPS = [107:0x359a80000] &lt;chr&gt; \n├─WAOB = [108:0x350d48000] &lt;fct&gt; \n├─FAGEP = [109:0x150c78000] &lt;lgl&gt; \n├─FANCP = [110:0x143760000] &lt;lgl&gt; \n├─FCITP = [111:0x320d48000] &lt;lgl&gt; \n├─FCOWP = [112:0x300d58000] &lt;lgl&gt; \n├─FDDRSP = [113:0x130e08000] &lt;lgl&gt; \n├─FDEYEP = [114:0x179520000] &lt;lgl&gt; \n├─FDOUTP = [115:0x179bc0000] &lt;lgl&gt; \n├─FDPHYP = [116:0x151318000] &lt;lgl&gt; \n├─FDREMP = [117:0x3106a8000] &lt;lgl&gt; \n├─FDWRKP = [118:0x17a260000] &lt;lgl&gt; \n├─FENGP = [119:0x17a900000] &lt;lgl&gt; \n├─FESRP = [120:0x17afa0000] &lt;lgl&gt; \n├─FFERP = [121:0x123038000] &lt;lgl&gt; \n├─FGCLP = [122:0x1236d8000] &lt;lgl&gt; \n├─FGCMP = [123:0x1519b8000] &lt;lgl&gt; \n├─FGCRP = [124:0x3213e8000] &lt;lgl&gt; \n├─FHISP = [125:0x123d78000] &lt;lgl&gt; \n├─FINDP = [126:0x124418000] &lt;lgl&gt; \n├─FINTP = [127:0x124ab8000] &lt;lgl&gt; \n├─FJWDP = [128:0x163728000] &lt;lgl&gt; \n├─FJWMNP = [129:0x321a88000] &lt;lgl&gt; \n├─FJWRIP = [130:0x310d48000] &lt;lgl&gt; \n├─FJWTRP = [131:0x31ae68000] &lt;lgl&gt; \n├─FLANP = [132:0x31b508000] &lt;lgl&gt; \n├─FLANXP = [133:0x308d48000] &lt;lgl&gt; \n├─FMARP = [134:0x3013f8000] &lt;lgl&gt; \n├─FMIGP = [135:0x301a98000] &lt;lgl&gt; \n├─FMIGSP = [136:0x322128000] &lt;lgl&gt; \n├─FMILPP = [137:0x17b640000] &lt;lgl&gt; \n├─FMILSP = [138:0x17bce0000] &lt;lgl&gt; \n├─FMILYP = [139:0x3093e8000] &lt;lgl&gt; \n├─FOCCP = [140:0x309a88000] &lt;lgl&gt; \n├─FOIP = [141:0x30a128000] &lt;lgl&gt; \n├─FPAP = [142:0x143e00000] &lt;lgl&gt; \n├─FPOBP = [143:0x1444a0000] &lt;lgl&gt; \n├─FPOWSP = [144:0x125158000] &lt;lgl&gt; \n├─FRACP = [145:0x1257f8000] &lt;lgl&gt; \n├─FRELP = [146:0x17c380000] &lt;lgl&gt; \n├─FRETP = [147:0x152058000] &lt;lgl&gt; \n├─FSCHGP = [148:0x1526f8000] &lt;lgl&gt; \n├─FSCHLP = [149:0x152d98000] &lt;lgl&gt; \n├─FSCHP = [150:0x163dc8000] &lt;lgl&gt; \n├─FSEMP = [151:0x144b40000] &lt;lgl&gt; \n├─FSEXP = [152:0x1451e0000] &lt;lgl&gt; \n├─FSSIP = [153:0x302138000] &lt;lgl&gt; \n├─FSSP = [154:0x3027d8000] &lt;lgl&gt; \n├─FWAGP = [155:0x302e78000] &lt;lgl&gt; \n├─FWKHP = [156:0x303518000] &lt;lgl&gt; \n├─FWKLP = [157:0x30a7c8000] &lt;lgl&gt; \n├─FWKWP = [158:0x30ae68000] &lt;lgl&gt; \n├─FYOEP = [159:0x17ca20000] &lt;lgl&gt; \n├─PWGTP1 = [160:0x351a88000] &lt;int&gt; \n├─PWGTP2 = [161:0x3527c8000] &lt;int&gt; \n├─PWGTP3 = [162:0x353508000] &lt;int&gt; \n├─PWGTP4 = [163:0x354248000] &lt;int&gt; \n├─PWGTP5 = [164:0x354f88000] &lt;int&gt; \n├─PWGTP6 = [165:0x1321e8000] &lt;int&gt; \n├─PWGTP7 = [166:0x360008000] &lt;int&gt; \n├─PWGTP8 = [167:0x360d48000] &lt;int&gt; \n├─PWGTP9 = [168:0x361a88000] &lt;int&gt; \n├─PWGTP10 = [169:0x3627c8000] &lt;int&gt; \n├─PWGTP11 = [170:0x363508000] &lt;int&gt; \n├─PWGTP12 = [171:0x364248000] &lt;int&gt; \n├─PWGTP13 = [172:0x347748000] &lt;int&gt; \n├─PWGTP14 = [173:0x3686a8000] &lt;int&gt; \n├─PWGTP15 = [174:0x3693e8000] &lt;int&gt; \n├─PWGTP16 = [175:0x355cc8000] &lt;int&gt; \n├─PWGTP17 = [176:0x36a128000] &lt;int&gt; \n├─PWGTP18 = [177:0x36ae68000] &lt;int&gt; \n├─PWGTP19 = [178:0x36bba8000] &lt;int&gt; \n├─PWGTP20 = [179:0x36c8e8000] &lt;int&gt; \n├─PWGTP21 = [180:0x156fd8000] &lt;int&gt; \n├─PWGTP22 = [181:0x370008000] &lt;int&gt; \n├─PWGTP23 = [182:0x370d48000] &lt;int&gt; \n├─PWGTP24 = [183:0x371a88000] &lt;int&gt; \n├─PWGTP25 = [184:0x3727c8000] &lt;int&gt; \n├─PWGTP26 = [185:0x364f88000] &lt;int&gt; \n├─PWGTP27 = [186:0x365cc8000] &lt;int&gt; \n├─PWGTP28 = [187:0x366a08000] &lt;int&gt; \n├─PWGTP29 = [188:0x367748000] &lt;int&gt; \n├─PWGTP30 = [189:0x3786a8000] &lt;int&gt; \n├─PWGTP31 = [190:0x3793e8000] &lt;int&gt; \n├─PWGTP32 = [191:0x37a128000] &lt;int&gt; \n├─PWGTP33 = [192:0x37ae68000] &lt;int&gt; \n├─PWGTP34 = [193:0x37bba8000] &lt;int&gt; \n├─PWGTP35 = [194:0x37c8e8000] &lt;int&gt; \n├─PWGTP36 = [195:0x37d628000] &lt;int&gt; \n├─PWGTP37 = [196:0x37e368000] &lt;int&gt; \n├─PWGTP38 = [197:0x37f0a8000] &lt;int&gt; \n├─PWGTP39 = [198:0x380008000] &lt;int&gt; \n├─PWGTP40 = [199:0x36d628000] &lt;int&gt; \n├─PWGTP41 = [200:0x36e368000] &lt;int&gt; \n├─PWGTP42 = [201:0x373508000] &lt;int&gt; \n├─PWGTP43 = [202:0x374248000] &lt;int&gt; \n├─PWGTP44 = [203:0x380d48000] &lt;int&gt; \n├─PWGTP45 = [204:0x381a88000] &lt;int&gt; \n├─PWGTP46 = [205:0x3827c8000] &lt;int&gt; \n├─PWGTP47 = [206:0x383508000] &lt;int&gt; \n├─PWGTP48 = [207:0x384248000] &lt;int&gt; \n├─PWGTP49 = [208:0x384f88000] &lt;int&gt; \n├─PWGTP50 = [209:0x385cc8000] &lt;int&gt; \n├─PWGTP51 = [210:0x386a08000] &lt;int&gt; \n├─PWGTP52 = [211:0x387748000] &lt;int&gt; \n├─PWGTP53 = [212:0x356a08000] &lt;int&gt; \n├─PWGTP54 = [213:0x357748000] &lt;int&gt; \n├─PWGTP55 = [214:0x3906a8000] &lt;int&gt; \n├─PWGTP56 = [215:0x3913e8000] &lt;int&gt; \n├─PWGTP57 = [216:0x392128000] &lt;int&gt; \n├─PWGTP58 = [217:0x392e68000] &lt;int&gt; \n├─PWGTP59 = [218:0x393ba8000] &lt;int&gt; \n├─PWGTP60 = [219:0x3948e8000] &lt;int&gt; \n├─PWGTP61 = [220:0x395628000] &lt;int&gt; \n├─PWGTP62 = [221:0x396368000] &lt;int&gt; \n├─PWGTP63 = [222:0x3970a8000] &lt;int&gt; \n├─PWGTP64 = [223:0x398008000] &lt;int&gt; \n├─PWGTP65 = [224:0x398d48000] &lt;int&gt; \n├─PWGTP66 = [225:0x399a88000] &lt;int&gt; \n├─PWGTP67 = [226:0x39a7c8000] &lt;int&gt; \n├─PWGTP68 = [227:0x39b508000] &lt;int&gt; \n├─PWGTP69 = [228:0x39c248000] &lt;int&gt; \n├─PWGTP70 = [229:0x39cf88000] &lt;int&gt; \n├─PWGTP71 = [230:0x39dcc8000] &lt;int&gt; \n├─PWGTP72 = [231:0x39ea08000] &lt;int&gt; \n├─PWGTP73 = [232:0x39f748000] &lt;int&gt; \n├─PWGTP74 = [233:0x3a06a8000] &lt;int&gt; \n├─PWGTP75 = [234:0x374f88000] &lt;int&gt; \n├─PWGTP76 = [235:0x36f0a8000] &lt;int&gt; \n├─PWGTP77 = [236:0x3a8008000] &lt;int&gt; \n├─PWGTP78 = [237:0x3a8d48000] &lt;int&gt; \n├─PWGTP79 = [238:0x3a9a88000] &lt;int&gt; \n├─PWGTP80 = [239:0x3aa7c8000] &lt;int&gt; \n├─NOP = [240:0x3ab508000] &lt;fct&gt; \n├─ADJINC = [241:0x35b500000] &lt;dbl&gt; \n├─CITWP = [242:0x35cf80000] &lt;chr&gt; \n├─DEAR = [243:0x31bba8000] &lt;lgl&gt; \n├─DRAT = [244:0x3886a8000] &lt;fct&gt; \n├─DRATX = [245:0x153438000] &lt;lgl&gt; \n├─HINS1 = [246:0x153ad8000] &lt;lgl&gt; \n├─HINS2 = [247:0x145880000] &lt;lgl&gt; \n├─HINS3 = [248:0x145f20000] &lt;lgl&gt; \n├─HINS4 = [249:0x1465c0000] &lt;lgl&gt; \n├─HINS5 = [250:0x31c248000] &lt;lgl&gt; \n├─HINS6 = [251:0x31c8e8000] &lt;lgl&gt; \n├─HINS7 = [252:0x164468000] &lt;lgl&gt; \n├─MARHD = [253:0x164b08000] &lt;lgl&gt; \n├─MARHM = [254:0x1314a8000] &lt;lgl&gt; \n├─MARHT = [255:0x3893e8000] &lt;fct&gt; \n├─MARHW = [256:0x125e98000] &lt;lgl&gt; \n├─MARHYP = [257:0x35ea00000] &lt;chr&gt; \n├─DIS = [258:0x154178000] &lt;lgl&gt; \n├─HICOV = [259:0x1651a8000] &lt;lgl&gt; \n├─PRIVCOV = [260:0x165848000] &lt;lgl&gt; \n├─PUBCOV = [261:0x3227c8000] &lt;lgl&gt; \n├─FCITWP = [262:0x154818000] &lt;lgl&gt; \n├─FDEARP = [263:0x322e68000] &lt;lgl&gt; \n├─FDRATP = [264:0x323508000] &lt;lgl&gt; \n├─FDRATXP = [265:0x17d0c0000] &lt;lgl&gt; \n├─FHINS1P = [266:0x17d760000] &lt;lgl&gt; \n├─FHINS2P = [267:0x328008000] &lt;lgl&gt; \n├─FHINS3P = [268:0x154eb8000] &lt;lgl&gt; \n├─FHINS4P = [269:0x155558000] &lt;lgl&gt; \n├─FHINS5P = [270:0x30b508000] &lt;lgl&gt; \n├─FHINS6P = [271:0x31cf88000] &lt;lgl&gt; \n├─FHINS7P = [272:0x3113e8000] &lt;lgl&gt; \n├─FMARHDP = [273:0x3286a8000] &lt;lgl&gt; \n├─FMARHMP = [274:0x328d48000] &lt;lgl&gt; \n├─FMARHTP = [275:0x323ba8000] &lt;lgl&gt; \n├─FMARHWP = [276:0x324248000] &lt;lgl&gt; \n├─FMARHYP = [277:0x3248e8000] &lt;lgl&gt; \n├─WRK = [278:0x146c60000] &lt;lgl&gt; \n├─FOD1P = [279:0x3b0d40000] &lt;chr&gt; \n├─FOD2P = [280:0x3b27c0000] &lt;chr&gt; \n├─SCIENGP = [281:0x311a88000] &lt;lgl&gt; \n├─SCIENGRLP = [282:0x17de00000] &lt;lgl&gt; \n├─FFODP = [283:0x30bba8000] &lt;lgl&gt; \n├─FHINS3C = [284:0x38a128000] &lt;fct&gt; \n├─FHINS4C = [285:0x38ae68000] &lt;fct&gt; \n├─FHINS5C = [286:0x38bba8000] &lt;fct&gt; \n├─RELP = [287:0x3b4240000] &lt;chr&gt; \n├─FWRKP = [288:0x17e4a0000] &lt;lgl&gt; \n├─FDISP = [289:0x17eb40000] &lt;lgl&gt; \n├─FPERNP = [290:0x17f1e0000] &lt;lgl&gt; \n├─FPINCP = [291:0x31d628000] &lt;lgl&gt; \n├─FPRIVCOVP = [292:0x31dcc8000] &lt;lgl&gt; \n├─FPUBCOVP = [293:0x31e368000] &lt;lgl&gt; \n├─RACNH = [294:0x126538000] &lt;lgl&gt; \n├─RACPI = [295:0x3293e8000] &lt;lgl&gt; \n├─SSPA = [296:0x38c8e8000] &lt;fct&gt; \n├─MLPCD = [297:0x329a88000] &lt;lgl&gt; \n├─MLPFG = [298:0x32a128000] &lt;lgl&gt; \n├─FHICOVP = [299:0x32a7c8000] &lt;lgl&gt; \n├─DIVISION = [300:0x38d628000] &lt;fct&gt; \n├─REGION = [301:0x38e368000] &lt;fct&gt; \n├─HIMRKS = [302:0x38f0a8000] &lt;fct&gt; \n├─JWTRNS = [303:0x3b5cc0000] &lt;chr&gt; \n├─RELSHIPP = [304:0x3b7740000] &lt;chr&gt; \n├─WKWN = [305:0x132f28000] &lt;int&gt; \n├─FHIMRKSP = [306:0x131b48000] &lt;lgl&gt; \n├─FJWTRNSP = [307:0x155bf8000] &lt;lgl&gt; \n├─FRELSHIPP = [308:0x32ae68000] &lt;lgl&gt; \n├─FWKWNP = [309:0x32b508000] &lt;lgl&gt; \n├─MLPIK = [310:0x32bba8000] &lt;lgl&gt; \n├─year = [311:0x133c68000] &lt;int&gt; \n├─location = [312:0x3b91c0000] &lt;chr&gt; \n├─age_groups = [313:0x15c540000] &lt;chr&gt; \n├─ins_type = [314:0x15dfc0000] &lt;chr&gt; \n└─age_decade = [315:0x35dcc0000] &lt;dbl&gt; \n\n\n\n\nlobstr::ref(pums_copy)\n\n█ [1:0x3bdfc2e00] &lt;dt[,314]&gt; \n├─SPORDER = [2:0x43a688000] &lt;int&gt; \n├─RT = [3:0x4359a8000] &lt;fct&gt; \n├─SERIALNO = [4:0x3b1a80000] &lt;chr&gt; \n├─PUMA = [5:0x3b0000000] &lt;chr&gt; \n├─ST = [6:0x168000000] &lt;chr&gt; \n├─ADJUST = [7:0x430488000] &lt;int&gt; \n├─PWGTP = [8:0x433028000] &lt;int&gt; \n├─AGEP = [9:0x43aea8000] &lt;int&gt; \n├─CIT = [10:0x438008000] &lt;fct&gt; \n├─COW = [11:0x43ca08000] &lt;fct&gt; \n├─DDRS = [12:0x43c068000] &lt;lgl&gt; \n├─DEYE = [13:0x41f4c8000] &lt;lgl&gt; \n├─DOUT = [14:0x418488000] &lt;lgl&gt; \n├─DPHY = [15:0x4013e8000] &lt;lgl&gt; \n├─DREM = [16:0x401a88000] &lt;lgl&gt; \n├─DWRK = [17:0x402128000] &lt;lgl&gt; \n├─ENG = [18:0x4027c8000] &lt;fct&gt; \n├─FER = [19:0x402e68000] &lt;lgl&gt; \n├─GCL = [20:0x403508000] &lt;lgl&gt; \n├─GCM = [21:0x403ba8000] &lt;fct&gt; \n├─GCR = [22:0x404248000] &lt;lgl&gt; \n├─INTP = [23:0x4048e8000] &lt;int&gt; \n├─JWMNP = [24:0x404f88000] &lt;int&gt; \n├─JWRIP = [25:0x169a80000] &lt;chr&gt; \n├─JWTR = [26:0x170460000] &lt;chr&gt; \n├─LANX = [27:0x411738000] &lt;lgl&gt; \n├─MAR = [28:0x411dd8000] &lt;fct&gt; \n├─MIG = [29:0x412478000] &lt;lgl&gt; \n├─MIL = [30:0x412b18000] &lt;fct&gt; \n├─MILY = [31:0x4131b8000] &lt;fct&gt; \n├─MLPA = [32:0x413858000] &lt;lgl&gt; \n├─MLPB = [33:0x413ef8000] &lt;lgl&gt; \n├─MLPC = [34:0x414a30000] &lt;lgl&gt; \n├─MLPD = [35:0x4150d0000] &lt;lgl&gt; \n├─MLPE = [36:0x415770000] &lt;lgl&gt; \n├─MLPF = [37:0x415e10000] &lt;lgl&gt; \n├─MLPG = [38:0x4164b0000] &lt;lgl&gt; \n├─MLPH = [39:0x416b50000] &lt;lgl&gt; \n├─MLPI = [40:0x4171f0000] &lt;lgl&gt; \n├─MLPJ = [41:0x417890000] &lt;lgl&gt; \n├─MLPK = [42:0x42f388000] &lt;lgl&gt; \n├─NWAB = [43:0x429ce8000] &lt;lgl&gt; \n├─NWAV = [44:0x4289a8000] &lt;fct&gt; \n├─NWLA = [45:0x428008000] &lt;lgl&gt; \n├─NWLK = [46:0x42d528000] &lt;lgl&gt; \n├─NWRE = [47:0x42cb88000] &lt;lgl&gt; \n├─OIP = [48:0x42b848000] &lt;int&gt; \n├─PAP = [49:0x4291c8000] &lt;int&gt; \n├─REL = [50:0x171ee0000] &lt;chr&gt; \n├─RETP = [51:0x4478a8000] &lt;int&gt; \n├─SCH = [52:0x446f08000] &lt;lgl&gt; \n├─SCHG = [53:0x173960000] &lt;chr&gt; \n├─SCHL = [54:0x1753e0000] &lt;chr&gt; \n├─SEMP = [55:0x446568000] &lt;int&gt; \n├─SEX = [56:0x445bc8000] &lt;fct&gt; \n├─SSIP = [57:0x445228000] &lt;int&gt; \n├─SSP = [58:0x444888000] &lt;int&gt; \n├─WAGP = [59:0x443ee8000] &lt;int&gt; \n├─WKHP = [60:0x443548000] &lt;int&gt; \n├─WKL = [61:0x4211c8000] &lt;fct&gt; \n├─WKW = [62:0x424b88000] &lt;fct&gt; \n├─YOEP = [63:0x176e60000] &lt;chr&gt; \n├─UWRK = [64:0x422ea8000] &lt;lgl&gt; \n├─ANC = [65:0x40bc88000] &lt;fct&gt; \n├─ANC1P = [66:0x358d40000] &lt;chr&gt; \n├─ANC2P = [67:0x35a7c0000] &lt;chr&gt; \n├─DECADE = [68:0x40c328000] &lt;fct&gt; \n├─DRIVESP = [69:0x40d7e8000] &lt;fct&gt; \n├─DS = [70:0x40de88000] &lt;lgl&gt; \n├─ESP = [71:0x40e528000] &lt;fct&gt; \n├─ESR = [72:0x40ebc8000] &lt;fct&gt; \n├─HISP = [73:0x35c240000] &lt;chr&gt; \n├─INDP = [74:0x3b3500000] &lt;chr&gt; \n├─JWAP = [75:0x3b4f80000] &lt;chr&gt; \n├─JWDP = [76:0x480000000] &lt;chr&gt; \n├─LANP = [77:0x481a7c000] &lt;chr&gt; \n├─MIGPUMA = [78:0x40f268000] &lt;fct&gt; \n├─MIGSP = [79:0x4834f8000] &lt;chr&gt; \n├─MSP = [80:0x40b2e8000] &lt;fct&gt; \n├─NAICSP = [81:0x484f74000] &lt;chr&gt; \n├─NATIVITY = [82:0x40a948000] &lt;fct&gt; \n├─OC = [83:0x40ce48000] &lt;lgl&gt; \n├─OCCP = [84:0x4869f0000] &lt;chr&gt; \n├─PAOC = [85:0x4236c8000] &lt;fct&gt; \n├─PERNP = [86:0x424068000] &lt;int&gt; \n├─PINCP = [87:0x426048000] &lt;int&gt; \n├─POBP = [88:0x48846c000] &lt;chr&gt; \n├─POVPIP = [89:0x4219e8000] &lt;int&gt; \n├─POWPUMA = [90:0x44f688000] &lt;fct&gt; \n├─POWSP = [91:0x489ee8000] &lt;chr&gt; \n├─QTRBIR = [92:0x44ece8000] &lt;fct&gt; \n├─RAC1P = [93:0x44e348000] &lt;fct&gt; \n├─RAC2P = [94:0x48b964000] &lt;chr&gt; \n├─RAC3P = [95:0x48d3e0000] &lt;chr&gt; \n├─RACAIAN = [96:0x44d9a8000] &lt;lgl&gt; \n├─RACASN = [97:0x44d008000] &lt;lgl&gt; \n├─RACBLK = [98:0x44c668000] &lt;lgl&gt; \n├─RACNHPI = [99:0x44bcc8000] &lt;lgl&gt; \n├─RACNUM = [100:0x44b328000] &lt;int&gt; \n├─RACSOR = [101:0x44a988000] &lt;lgl&gt; \n├─RACWHT = [102:0x449fe8000] &lt;lgl&gt; \n├─RC = [103:0x449648000] &lt;lgl&gt; \n├─SFN = [104:0x448ca8000] &lt;fct&gt; \n├─SFR = [105:0x448308000] &lt;fct&gt; \n├─SOCP = [106:0x48ee5c000] &lt;chr&gt; \n├─VPS = [107:0x3eea68000] &lt;chr&gt; \n├─WAOB = [108:0x457508000] &lt;fct&gt; \n├─FAGEP = [109:0x456b68000] &lt;lgl&gt; \n├─FANCP = [110:0x4561c8000] &lt;lgl&gt; \n├─FCITP = [111:0x442ba8000] &lt;lgl&gt; \n├─FCOWP = [112:0x442208000] &lt;lgl&gt; \n├─FDDRSP = [113:0x441868000] &lt;lgl&gt; \n├─FDEYEP = [114:0x440ec8000] &lt;lgl&gt; \n├─FDOUTP = [115:0x440008000] &lt;lgl&gt; \n├─FDPHYP = [116:0x4406a8000] &lt;lgl&gt; \n├─FDREMP = [117:0x498008000] &lt;lgl&gt; \n├─FDWRKP = [118:0x4986a8000] &lt;lgl&gt; \n├─FENGP = [119:0x498d48000] &lt;lgl&gt; \n├─FESRP = [120:0x4993e8000] &lt;lgl&gt; \n├─FFERP = [121:0x397748000] &lt;lgl&gt; \n├─FGCLP = [122:0x476048000] &lt;lgl&gt; \n├─FGCMP = [123:0x474d08000] &lt;lgl&gt; \n├─FGCRP = [124:0x471ce8000] &lt;lgl&gt; \n├─FHISP = [125:0x474368000] &lt;lgl&gt; \n├─FINDP = [126:0x47bcc8000] &lt;lgl&gt; \n├─FINTP = [127:0x472688000] &lt;lgl&gt; \n├─FJWDP = [128:0x4739c8000] &lt;lgl&gt; \n├─FJWMNP = [129:0x473028000] &lt;lgl&gt; \n├─FJWRIP = [130:0x4756a8000] &lt;lgl&gt; \n├─FJWTRP = [131:0x4709a8000] &lt;lgl&gt; \n├─FLANP = [132:0x471348000] &lt;lgl&gt; \n├─FLANXP = [133:0x470008000] &lt;lgl&gt; \n├─FMARP = [134:0x478188000] &lt;lgl&gt; \n├─FMIGP = [135:0x476b68000] &lt;lgl&gt; \n├─FMIGSP = [136:0x479e68000] &lt;lgl&gt; \n├─FMILPP = [137:0x4794c8000] &lt;lgl&gt; \n├─FMILSP = [138:0x478b28000] &lt;lgl&gt; \n├─FMILYP = [139:0x47a808000] &lt;lgl&gt; \n├─FOCCP = [140:0x47c668000] &lt;lgl&gt; \n├─FOIP = [141:0x47b1a8000] &lt;lgl&gt; \n├─FPAP = [142:0x46f508000] &lt;lgl&gt; \n├─FPOBP = [143:0x46eb68000] &lt;lgl&gt; \n├─FPOWSP = [144:0x46e1c8000] &lt;lgl&gt; \n├─FRACP = [145:0x46d828000] &lt;lgl&gt; \n├─FRELP = [146:0x46ce88000] &lt;lgl&gt; \n├─FRETP = [147:0x46c4e8000] &lt;lgl&gt; \n├─FSCHGP = [148:0x46bb48000] &lt;lgl&gt; \n├─FSCHLP = [149:0x46b1a8000] &lt;lgl&gt; \n├─FSCHP = [150:0x3f86a8000] &lt;lgl&gt; \n├─FSEMP = [151:0x3f8d48000] &lt;lgl&gt; \n├─FSEXP = [152:0x3f93e8000] &lt;lgl&gt; \n├─FSSIP = [153:0x3f9a88000] &lt;lgl&gt; \n├─FSSP = [154:0x3fa128000] &lt;lgl&gt; \n├─FWAGP = [155:0x3fa7c8000] &lt;lgl&gt; \n├─FWKHP = [156:0x3fae68000] &lt;lgl&gt; \n├─FWKLP = [157:0x3fb508000] &lt;lgl&gt; \n├─FWKWP = [158:0x3fbba8000] &lt;lgl&gt; \n├─FYOEP = [159:0x3fc248000] &lt;lgl&gt; \n├─PWGTP1 = [160:0x3fc8e8000] &lt;int&gt; \n├─PWGTP2 = [161:0x3fcf88000] &lt;int&gt; \n├─PWGTP3 = [162:0x3fd628000] &lt;int&gt; \n├─PWGTP4 = [163:0x3fe350000] &lt;int&gt; \n├─PWGTP5 = [164:0x3fe9f0000] &lt;int&gt; \n├─PWGTP6 = [165:0x3ff090000] &lt;int&gt; \n├─PWGTP7 = [166:0x3ff730000] &lt;int&gt; \n├─PWGTP8 = [167:0x4a0008000] &lt;int&gt; \n├─PWGTP9 = [168:0x4a06a8000] &lt;int&gt; \n├─PWGTP10 = [169:0x4a0d48000] &lt;int&gt; \n├─PWGTP11 = [170:0x4a13e8000] &lt;int&gt; \n├─PWGTP12 = [171:0x405628000] &lt;int&gt; \n├─PWGTP13 = [172:0x46a808000] &lt;int&gt; \n├─PWGTP14 = [173:0x469e68000] &lt;int&gt; \n├─PWGTP15 = [174:0x4694c8000] &lt;int&gt; \n├─PWGTP16 = [175:0x455828000] &lt;int&gt; \n├─PWGTP17 = [176:0x454e88000] &lt;int&gt; \n├─PWGTP18 = [177:0x499a88000] &lt;int&gt; \n├─PWGTP19 = [178:0x49a128000] &lt;int&gt; \n├─PWGTP20 = [179:0x49a7c8000] &lt;int&gt; \n├─PWGTP21 = [180:0x405cc8000] &lt;int&gt; \n├─PWGTP22 = [181:0x406368000] &lt;int&gt; \n├─PWGTP23 = [182:0x406a08000] &lt;int&gt; \n├─PWGTP24 = [183:0x4070a8000] &lt;int&gt; \n├─PWGTP25 = [184:0x4544e8000] &lt;int&gt; \n├─PWGTP26 = [185:0x453b48000] &lt;int&gt; \n├─PWGTP27 = [186:0x4531a8000] &lt;int&gt; \n├─PWGTP28 = [187:0x452808000] &lt;int&gt; \n├─PWGTP29 = [188:0x49ae68000] &lt;int&gt; \n├─PWGTP30 = [189:0x49b508000] &lt;int&gt; \n├─PWGTP31 = [190:0x451e68000] &lt;int&gt; \n├─PWGTP32 = [191:0x4514c8000] &lt;int&gt; \n├─PWGTP33 = [192:0x450b28000] &lt;int&gt; \n├─PWGTP34 = [193:0x450188000] &lt;int&gt; \n├─PWGTP35 = [194:0x4689a8000] &lt;int&gt; \n├─PWGTP36 = [195:0x468008000] &lt;int&gt; \n├─PWGTP37 = [196:0x467508000] &lt;int&gt; \n├─PWGTP38 = [197:0x466b68000] &lt;int&gt; \n├─PWGTP39 = [198:0x4661c8000] &lt;int&gt; \n├─PWGTP40 = [199:0x4a8008000] &lt;int&gt; \n├─PWGTP41 = [200:0x49bba8000] &lt;int&gt; \n├─PWGTP42 = [201:0x4a1a88000] &lt;int&gt; \n├─PWGTP43 = [202:0x4a2128000] &lt;int&gt; \n├─PWGTP44 = [203:0x4a27c8000] &lt;int&gt; \n├─PWGTP45 = [204:0x4a2e68000] &lt;int&gt; \n├─PWGTP46 = [205:0x40f908000] &lt;int&gt; \n├─PWGTP47 = [206:0x4a86a8000] &lt;int&gt; \n├─PWGTP48 = [207:0x407748000] &lt;int&gt; \n├─PWGTP49 = [208:0x41c328000] &lt;int&gt; \n├─PWGTP50 = [209:0x49c248000] &lt;int&gt; \n├─PWGTP51 = [210:0x49c8e8000] &lt;int&gt; \n├─PWGTP52 = [211:0x4a8d48000] &lt;int&gt; \n├─PWGTP53 = [212:0x49cf88000] &lt;int&gt; \n├─PWGTP54 = [213:0x49d628000] &lt;int&gt; \n├─PWGTP55 = [214:0x49dcc8000] &lt;int&gt; \n├─PWGTP56 = [215:0x41a728000] &lt;int&gt; \n├─PWGTP57 = [216:0x49e368000] &lt;int&gt; \n├─PWGTP58 = [217:0x49ea08000] &lt;int&gt; \n├─PWGTP59 = [218:0x49f0a8000] &lt;int&gt; \n├─PWGTP60 = [219:0x49f748000] &lt;int&gt; \n├─PWGTP61 = [220:0x4b0008000] &lt;int&gt; \n├─PWGTP62 = [221:0x4a93e8000] &lt;int&gt; \n├─PWGTP63 = [222:0x465828000] &lt;int&gt; \n├─PWGTP64 = [223:0x464e88000] &lt;int&gt; \n├─PWGTP65 = [224:0x4644e8000] &lt;int&gt; \n├─PWGTP66 = [225:0x463b48000] &lt;int&gt; \n├─PWGTP67 = [226:0x4a9a88000] &lt;int&gt; \n├─PWGTP68 = [227:0x4631a8000] &lt;int&gt; \n├─PWGTP69 = [228:0x462808000] &lt;int&gt; \n├─PWGTP70 = [229:0x4aa128000] &lt;int&gt; \n├─PWGTP71 = [230:0x4aa7c8000] &lt;int&gt; \n├─PWGTP72 = [231:0x4a3508000] &lt;int&gt; \n├─PWGTP73 = [232:0x4b06a8000] &lt;int&gt; \n├─PWGTP74 = [233:0x4aae68000] &lt;int&gt; \n├─PWGTP75 = [234:0x4ab508000] &lt;int&gt; \n├─PWGTP76 = [235:0x461e68000] &lt;int&gt; \n├─PWGTP77 = [236:0x4614c8000] &lt;int&gt; \n├─PWGTP78 = [237:0x4b0d48000] &lt;int&gt; \n├─PWGTP79 = [238:0x4b13e8000] &lt;int&gt; \n├─PWGTP80 = [239:0x4b1a88000] &lt;int&gt; \n├─NOP = [240:0x460b28000] &lt;fct&gt; \n├─ADJINC = [241:0x4908d8000] &lt;dbl&gt; \n├─CITWP = [242:0x491618000] &lt;chr&gt; \n├─DEAR = [243:0x4abba8000] &lt;lgl&gt; \n├─DRAT = [244:0x4b2128000] &lt;fct&gt; \n├─DRATX = [245:0x45f508000] &lt;lgl&gt; \n├─HINS1 = [246:0x45e9e8000] &lt;lgl&gt; \n├─HINS2 = [247:0x45e048000] &lt;lgl&gt; \n├─HINS3 = [248:0x4b27c8000] &lt;lgl&gt; \n├─HINS4 = [249:0x45d6a8000] &lt;lgl&gt; \n├─HINS5 = [250:0x4ac248000] &lt;lgl&gt; \n├─HINS6 = [251:0x4ac8e8000] &lt;lgl&gt; \n├─HINS7 = [252:0x45cd08000] &lt;lgl&gt; \n├─MARHD = [253:0x45c368000] &lt;lgl&gt; \n├─MARHM = [254:0x45b9c8000] &lt;lgl&gt; \n├─MARHT = [255:0x45b028000] &lt;fct&gt; \n├─MARHW = [256:0x45a688000] &lt;lgl&gt; \n├─MARHYP = [257:0x492358000] &lt;chr&gt; \n├─DIS = [258:0x4acf88000] &lt;lgl&gt; \n├─HICOV = [259:0x4ad628000] &lt;lgl&gt; \n├─PRIVCOV = [260:0x4adcc8000] &lt;lgl&gt; \n├─PUBCOV = [261:0x4b2e68000] &lt;lgl&gt; \n├─FCITWP = [262:0x4b3508000] &lt;lgl&gt; \n├─FDEARP = [263:0x4b3ba8000] &lt;lgl&gt; \n├─FDRATP = [264:0x4b4248000] &lt;lgl&gt; \n├─FDRATXP = [265:0x4b48e8000] &lt;lgl&gt; \n├─FHINS1P = [266:0x4b4f88000] &lt;lgl&gt; \n├─FHINS2P = [267:0x459ce8000] &lt;lgl&gt; \n├─FHINS3P = [268:0x459348000] &lt;lgl&gt; \n├─FHINS4P = [269:0x4ae368000] &lt;lgl&gt; \n├─FHINS5P = [270:0x4aea08000] &lt;lgl&gt; \n├─FHINS6P = [271:0x4af0a8000] &lt;lgl&gt; \n├─FHINS7P = [272:0x4af748000] &lt;lgl&gt; \n├─FMARHDP = [273:0x4b8008000] &lt;lgl&gt; \n├─FMARHMP = [274:0x4b86a8000] &lt;lgl&gt; \n├─FMARHTP = [275:0x4b8d48000] &lt;lgl&gt; \n├─FMARHWP = [276:0x4a3ba8000] &lt;lgl&gt; \n├─FMARHYP = [277:0x4589a8000] &lt;lgl&gt; \n├─WRK = [278:0x458008000] &lt;lgl&gt; \n├─FOD1P = [279:0x493098000] &lt;chr&gt; \n├─FOD2P = [280:0x493dd8000] &lt;chr&gt; \n├─SCIENGP = [281:0x4b93e8000] &lt;lgl&gt; \n├─SCIENGRLP = [282:0x4b9a88000] &lt;lgl&gt; \n├─FFODP = [283:0x47ce88000] &lt;lgl&gt; \n├─FHINS3C = [284:0x47d528000] &lt;fct&gt; \n├─FHINS4C = [285:0x47dbc8000] &lt;fct&gt; \n├─FHINS5C = [286:0x4b5628000] &lt;fct&gt; \n├─RELP = [287:0x494b18000] &lt;chr&gt; \n├─FWRKP = [288:0x4ba128000] &lt;lgl&gt; \n├─FDISP = [289:0x4ba7c8000] &lt;lgl&gt; \n├─FPERNP = [290:0x4bae68000] &lt;lgl&gt; \n├─FPINCP = [291:0x4bb508000] &lt;lgl&gt; \n├─FPRIVCOVP = [292:0x4bbba8000] &lt;lgl&gt; \n├─FPUBCOVP = [293:0x47e268000] &lt;lgl&gt; \n├─RACNH = [294:0x47e908000] &lt;lgl&gt; \n├─RACPI = [295:0x4b5cc8000] &lt;lgl&gt; \n├─SSPA = [296:0x47efa8000] &lt;fct&gt; \n├─MLPCD = [297:0x47f648000] &lt;lgl&gt; \n├─MLPFG = [298:0x4bc248000] &lt;lgl&gt; \n├─FHICOVP = [299:0x4b6368000] &lt;lgl&gt; \n├─DIVISION = [300:0x4bc8e8000] &lt;fct&gt; \n├─REGION = [301:0x4bcf88000] &lt;fct&gt; \n├─HIMRKS = [302:0x4b6a08000] &lt;fct&gt; \n├─JWTRNS = [303:0x495858000] &lt;chr&gt; \n├─RELSHIPP = [304:0x496598000] &lt;chr&gt; \n├─WKWN = [305:0x4a4248000] &lt;int&gt; \n├─FHIMRKSP = [306:0x4a48e8000] &lt;lgl&gt; \n├─FJWTRNSP = [307:0x4a4f88000] &lt;lgl&gt; \n├─FRELSHIPP = [308:0x4a5628000] &lt;lgl&gt; \n├─FWKWNP = [309:0x4c0008000] &lt;lgl&gt; \n├─MLPIK = [310:0x4c06a8000] &lt;lgl&gt; \n├─year = [311:0x4bd628000] &lt;int&gt; \n├─location = [312:0x4c8000000] &lt;chr&gt; \n├─age_groups = [313:0x4c8d40000] &lt;chr&gt; \n├─ins_type = [314:0x4c9a80000] &lt;chr&gt; \n└─age_decade = [315:0x4cb500000] &lt;dbl&gt;"
  },
  {
    "objectID": "materials/slides/02-datatable.html#set-functions",
    "href": "materials/slides/02-datatable.html#set-functions",
    "title": "data.table",
    "section": "set*() Functions",
    "text": "set*() Functions\nMemory-efficient operations by reference\nThe set*() family of functions modify data.table objects directly in memory without creating copies, making them essential for large datasets.\n\nWhy set functions are useful:\n\nMemory efficiency: No copies made, lower RAM usage\nSpeed: Faster than traditional assignment operations\n\nLarge data friendly: Essential when working with datasets that approach memory limits\nConsistent syntax: Uniform approach across different operations"
  },
  {
    "objectID": "materials/slides/02-datatable.html#key-set-functions",
    "href": "materials/slides/02-datatable.html#key-set-functions",
    "title": "data.table",
    "section": "Key set functions:",
    "text": "Key set functions:\n\n# setnames() - rename columns by reference\nsetnames(pums, \"AGEP\", \"age\") \nsetnames(pums, c(\"old1\", \"old2\"), c(\"new1\", \"new2\"))\n\n# setkey() - set keys for fast operations\nsetkey(pums, ST, year)  # Fast lookups and joins\n\n# setorder() - sort by reference\nsetorder(pums, ST, -AGEP)  # Sort by state, then age descending\n\n# set() - general purpose setter\nset(pums, i = 1L, j = \"AGEP\", value = 99L)  # Set specific cell\nset(pums, j = \"new_col\", value = 0L)        # Add column with default value"
  },
  {
    "objectID": "materials/slides/02-datatable.html#tradeoffs-of-modify-by-reference",
    "href": "materials/slides/02-datatable.html#tradeoffs-of-modify-by-reference",
    "title": "data.table",
    "section": "Tradeoffs of Modify by Reference",
    "text": "Tradeoffs of Modify by Reference\n\nNeed to keep track of what is referencing the same data\nUse copies if you want to keep data independent\nWhen done properly, it can be very memory efficient"
  },
  {
    "objectID": "materials/slides/02-datatable.html#what-will-this-do-2",
    "href": "materials/slides/02-datatable.html#what-will-this-do-2",
    "title": "data.table",
    "section": "What will this do?",
    "text": "What will this do?\n\npums2 = pums\nsetnames(pums2, old = \"SPORDER\", new = \"id\")"
  },
  {
    "objectID": "materials/slides/02-datatable.html#what-will-this-do-3",
    "href": "materials/slides/02-datatable.html#what-will-this-do-3",
    "title": "data.table",
    "section": "What will this do?",
    "text": "What will this do?\n\npums2 = pums\nsetnames(pums2, old = \"SPORDER\", new = \"id\")\nnames(pums)\n\n  [1] \"id\"         \"RT\"         \"SERIALNO\"   \"PUMA\"       \"ST\"        \n  [6] \"ADJUST\"     \"PWGTP\"      \"AGEP\"       \"CIT\"        \"COW\"       \n [11] \"DDRS\"       \"DEYE\"       \"DOUT\"       \"DPHY\"       \"DREM\"      \n [16] \"DWRK\"       \"ENG\"        \"FER\"        \"GCL\"        \"GCM\"       \n [21] \"GCR\"        \"INTP\"       \"JWMNP\"      \"JWRIP\"      \"JWTR\"      \n [26] \"LANX\"       \"MAR\"        \"MIG\"        \"MIL\"        \"MILY\"      \n [31] \"MLPA\"       \"MLPB\"       \"MLPC\"       \"MLPD\"       \"MLPE\"      \n [36] \"MLPF\"       \"MLPG\"       \"MLPH\"       \"MLPI\"       \"MLPJ\"      \n [41] \"MLPK\"       \"NWAB\"       \"NWAV\"       \"NWLA\"       \"NWLK\"      \n [46] \"NWRE\"       \"OIP\"        \"PAP\"        \"REL\"        \"RETP\"      \n [51] \"SCH\"        \"SCHG\"       \"SCHL\"       \"SEMP\"       \"SEX\"       \n [56] \"SSIP\"       \"SSP\"        \"WAGP\"       \"WKHP\"       \"WKL\"       \n [61] \"WKW\"        \"YOEP\"       \"UWRK\"       \"ANC\"        \"ANC1P\"     \n [66] \"ANC2P\"      \"DECADE\"     \"DRIVESP\"    \"DS\"         \"ESP\"       \n [71] \"ESR\"        \"HISP\"       \"INDP\"       \"JWAP\"       \"JWDP\"      \n [76] \"LANP\"       \"MIGPUMA\"    \"MIGSP\"      \"MSP\"        \"NAICSP\"    \n [81] \"NATIVITY\"   \"OC\"         \"OCCP\"       \"PAOC\"       \"PERNP\"     \n [86] \"PINCP\"      \"POBP\"       \"POVPIP\"     \"POWPUMA\"    \"POWSP\"     \n [91] \"QTRBIR\"     \"RAC1P\"      \"RAC2P\"      \"RAC3P\"      \"RACAIAN\"   \n [96] \"RACASN\"     \"RACBLK\"     \"RACNHPI\"    \"RACNUM\"     \"RACSOR\"    \n[101] \"RACWHT\"     \"RC\"         \"SFN\"        \"SFR\"        \"SOCP\"      \n[106] \"VPS\"        \"WAOB\"       \"FAGEP\"      \"FANCP\"      \"FCITP\"     \n[111] \"FCOWP\"      \"FDDRSP\"     \"FDEYEP\"     \"FDOUTP\"     \"FDPHYP\"    \n[116] \"FDREMP\"     \"FDWRKP\"     \"FENGP\"      \"FESRP\"      \"FFERP\"     \n[121] \"FGCLP\"      \"FGCMP\"      \"FGCRP\"      \"FHISP\"      \"FINDP\"     \n[126] \"FINTP\"      \"FJWDP\"      \"FJWMNP\"     \"FJWRIP\"     \"FJWTRP\"    \n[131] \"FLANP\"      \"FLANXP\"     \"FMARP\"      \"FMIGP\"      \"FMIGSP\"    \n[136] \"FMILPP\"     \"FMILSP\"     \"FMILYP\"     \"FOCCP\"      \"FOIP\"      \n[141] \"FPAP\"       \"FPOBP\"      \"FPOWSP\"     \"FRACP\"      \"FRELP\"     \n[146] \"FRETP\"      \"FSCHGP\"     \"FSCHLP\"     \"FSCHP\"      \"FSEMP\"     \n[151] \"FSEXP\"      \"FSSIP\"      \"FSSP\"       \"FWAGP\"      \"FWKHP\"     \n[156] \"FWKLP\"      \"FWKWP\"      \"FYOEP\"      \"PWGTP1\"     \"PWGTP2\"    \n[161] \"PWGTP3\"     \"PWGTP4\"     \"PWGTP5\"     \"PWGTP6\"     \"PWGTP7\"    \n[166] \"PWGTP8\"     \"PWGTP9\"     \"PWGTP10\"    \"PWGTP11\"    \"PWGTP12\"   \n[171] \"PWGTP13\"    \"PWGTP14\"    \"PWGTP15\"    \"PWGTP16\"    \"PWGTP17\"   \n[176] \"PWGTP18\"    \"PWGTP19\"    \"PWGTP20\"    \"PWGTP21\"    \"PWGTP22\"   \n[181] \"PWGTP23\"    \"PWGTP24\"    \"PWGTP25\"    \"PWGTP26\"    \"PWGTP27\"   \n[186] \"PWGTP28\"    \"PWGTP29\"    \"PWGTP30\"    \"PWGTP31\"    \"PWGTP32\"   \n[191] \"PWGTP33\"    \"PWGTP34\"    \"PWGTP35\"    \"PWGTP36\"    \"PWGTP37\"   \n[196] \"PWGTP38\"    \"PWGTP39\"    \"PWGTP40\"    \"PWGTP41\"    \"PWGTP42\"   \n[201] \"PWGTP43\"    \"PWGTP44\"    \"PWGTP45\"    \"PWGTP46\"    \"PWGTP47\"   \n[206] \"PWGTP48\"    \"PWGTP49\"    \"PWGTP50\"    \"PWGTP51\"    \"PWGTP52\"   \n[211] \"PWGTP53\"    \"PWGTP54\"    \"PWGTP55\"    \"PWGTP56\"    \"PWGTP57\"   \n[216] \"PWGTP58\"    \"PWGTP59\"    \"PWGTP60\"    \"PWGTP61\"    \"PWGTP62\"   \n[221] \"PWGTP63\"    \"PWGTP64\"    \"PWGTP65\"    \"PWGTP66\"    \"PWGTP67\"   \n[226] \"PWGTP68\"    \"PWGTP69\"    \"PWGTP70\"    \"PWGTP71\"    \"PWGTP72\"   \n[231] \"PWGTP73\"    \"PWGTP74\"    \"PWGTP75\"    \"PWGTP76\"    \"PWGTP77\"   \n[236] \"PWGTP78\"    \"PWGTP79\"    \"PWGTP80\"    \"NOP\"        \"ADJINC\"    \n[241] \"CITWP\"      \"DEAR\"       \"DRAT\"       \"DRATX\"      \"HINS1\"     \n[246] \"HINS2\"      \"HINS3\"      \"HINS4\"      \"HINS5\"      \"HINS6\"     \n[251] \"HINS7\"      \"MARHD\"      \"MARHM\"      \"MARHT\"      \"MARHW\"     \n[256] \"MARHYP\"     \"DIS\"        \"HICOV\"      \"PRIVCOV\"    \"PUBCOV\"    \n[261] \"FCITWP\"     \"FDEARP\"     \"FDRATP\"     \"FDRATXP\"    \"FHINS1P\"   \n[266] \"FHINS2P\"    \"FHINS3P\"    \"FHINS4P\"    \"FHINS5P\"    \"FHINS6P\"   \n[271] \"FHINS7P\"    \"FMARHDP\"    \"FMARHMP\"    \"FMARHTP\"    \"FMARHWP\"   \n[276] \"FMARHYP\"    \"WRK\"        \"FOD1P\"      \"FOD2P\"      \"SCIENGP\"   \n[281] \"SCIENGRLP\"  \"FFODP\"      \"FHINS3C\"    \"FHINS4C\"    \"FHINS5C\"   \n[286] \"RELP\"       \"FWRKP\"      \"FDISP\"      \"FPERNP\"     \"FPINCP\"    \n[291] \"FPRIVCOVP\"  \"FPUBCOVP\"   \"RACNH\"      \"RACPI\"      \"SSPA\"      \n[296] \"MLPCD\"      \"MLPFG\"      \"FHICOVP\"    \"DIVISION\"   \"REGION\"    \n[301] \"HIMRKS\"     \"JWTRNS\"     \"RELSHIPP\"   \"WKWN\"       \"FHIMRKSP\"  \n[306] \"FJWTRNSP\"   \"FRELSHIPP\"  \"FWKWNP\"     \"MLPIK\"      \"year\"      \n[311] \"location\"   \"age_groups\" \"ins_type\"   \"age_decade\""
  },
  {
    "objectID": "materials/slides/02-datatable.html#what-creates-a-copy-besides-copy",
    "href": "materials/slides/02-datatable.html#what-creates-a-copy-besides-copy",
    "title": "data.table",
    "section": "What creates a copy besides copy()",
    "text": "What creates a copy besides copy()\n\n\nWhen you subset the data (select columns or filter rows)\nChange a data.table to a data.frame or tibble\nAggregate or summarizing of the data.table"
  },
  {
    "objectID": "materials/slides/02-datatable.html#api-lifecycle-management",
    "href": "materials/slides/02-datatable.html#api-lifecycle-management",
    "title": "data.table",
    "section": "4. API Lifecycle Management",
    "text": "4. API Lifecycle Management\n“I’m not superstitious, but I am a little stitious.”\n\nStable and backward compatible\nKey principles:\n\nBackward compatibility maintained\nNew features don’t break existing code\nClear deprecation warnings when needed"
  },
  {
    "objectID": "materials/slides/02-datatable.html#community",
    "href": "materials/slides/02-datatable.html#community",
    "title": "data.table",
    "section": "5. Community",
    "text": "5. Community\nActive development and strong ecosystem\n\nNew Governance: As part of a NSF grant, new expansive governance\nGitHub: 3,500+ stars, active issues and PRs\nCRAN: Over 2,000 reverse dependencies\nStack Overflow: 15,000+ questions tagged with data.table\nDocumentation: Comprehensive vignettes and examples\nExtensions: dtplyr, data.table.express, tidyfast, tidytable, and more\n\n# Getting help\n?data.table\nvignette(\"datatable-intro\")\nbrowseVignettes(\"data.table\")"
  },
  {
    "objectID": "materials/slides/02-datatable.html#feature-rich",
    "href": "materials/slides/02-datatable.html#feature-rich",
    "title": "data.table",
    "section": "6. Feature Rich",
    "text": "6. Feature Rich\nComprehensive data manipulation toolkit\nJoins\n\n# Load household data for comparison\nhousehold_data &lt;- open_dataset(here::here(\"data/household\")) |&gt;\n  filter(year &gt;= 2020, location %in% c(\"ca\", \"tx\", \"ny\")) |&gt;\n  collect()\nsetDT(household_data)\n\n# Create state-year summary from household data\nhousehold_summary &lt;- household_data[, \n  .(avg_income = mean(HINCP, na.rm = TRUE)), \n  by = .(ST, year)\n]\n\n# Join person and household summaries\npums[household_summary, on = c(\"ST\", \"year\")] # merge(pums, household_summary, by = c(\"ST\", \"year\"))\n\n            id            RT      SERIALNO   PUMA          ST ADJUST PWGTP\n         &lt;int&gt;        &lt;fctr&gt;        &lt;char&gt; &lt;char&gt;      &lt;char&gt;  &lt;int&gt; &lt;int&gt;\n      1:     1 Person Record 2021HU0896827  00904 New York/NY     NA   179\n      2:     2 Person Record 2021HU0896827  00904 New York/NY     NA   182\n      3:     3 Person Record 2021HU0896827  00904 New York/NY     NA   199\n      4:     4 Person Record 2021HU0896827  00904 New York/NY     NA   197\n      5:     5 Person Record 2021HU0896827  00904 New York/NY     NA   229\n     ---                                                                  \n1735551:     1 Person Record 2022HU0609672  04611    Texas/TX     NA   136\n1735552:     2 Person Record 2022HU0609672  04611    Texas/TX     NA   140\n1735553:     3 Person Record 2022HU0609672  04611    Texas/TX     NA   167\n1735554:     1 Person Record 2022HU0609675  04302    Texas/TX     NA    20\n1735555:     2 Person Record 2022HU0609675  04302    Texas/TX     NA    33\n          AGEP                            CIT\n         &lt;int&gt;                         &lt;fctr&gt;\n      1:    60 U.S. citizen by naturalization\n      2:    40 U.S. citizen by naturalization\n      3:    34 U.S. citizen by naturalization\n      4:    26 U.S. citizen by naturalization\n      5:    20      Born in the United States\n     ---                                     \n1735551:    56 U.S. citizen by naturalization\n1735552:    67 U.S. citizen by naturalization\n1735553:    21      Born in the United States\n1735554:    66      Born in the United States\n1735555:    64      Born in the United States\n                                                                                                       COW\n                                                                                                    &lt;fctr&gt;\n      1:                      Employee of a private not-for-profit, tax-exempt, or charitable organization\n      2:                                                                                              &lt;NA&gt;\n      3:                      Employee of a private not-for-profit, tax-exempt, or charitable organization\n      4: Employee of a private for-profit co. or bus., or of an individual, for wages, salary, commissions\n      5: Employee of a private for-profit co. or bus., or of an individual, for wages, salary, commissions\n     ---                                                                                                  \n1735551: Employee of a private for-profit co. or bus., or of an individual, for wages, salary, commissions\n1735552: Employee of a private for-profit co. or bus., or of an individual, for wages, salary, commissions\n1735553: Employee of a private for-profit co. or bus., or of an individual, for wages, salary, commissions\n1735554:                                                                                              &lt;NA&gt;\n1735555: Employee of a private for-profit co. or bus., or of an individual, for wages, salary, commissions\n           DDRS   DEYE   DOUT   DPHY   DREM   DWRK       ENG    FER    GCL\n         &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt;    &lt;fctr&gt; &lt;lgcl&gt; &lt;lgcl&gt;\n      1:  FALSE  FALSE  FALSE  FALSE  FALSE     NA      Well     NA  FALSE\n      2:  FALSE  FALSE  FALSE  FALSE  FALSE     NA  Not well  FALSE  FALSE\n      3:  FALSE  FALSE  FALSE  FALSE  FALSE     NA      Well     NA  FALSE\n      4:  FALSE  FALSE  FALSE  FALSE  FALSE     NA      Well     NA     NA\n      5:  FALSE  FALSE  FALSE  FALSE  FALSE     NA      Well     NA     NA\n     ---                                                                  \n1735551:  FALSE  FALSE  FALSE  FALSE   TRUE     NA      Well     NA  FALSE\n1735552:  FALSE  FALSE  FALSE  FALSE  FALSE     NA      Well     NA  FALSE\n1735553:  FALSE  FALSE  FALSE  FALSE  FALSE     NA Very well  FALSE     NA\n1735554:   TRUE  FALSE   TRUE   TRUE   TRUE     NA      &lt;NA&gt;     NA  FALSE\n1735555:  FALSE  FALSE  FALSE   TRUE   TRUE     NA      &lt;NA&gt;     NA  FALSE\n            GCM    GCR  INTP JWMNP  JWRIP   JWTR   LANX\n         &lt;fctr&gt; &lt;lgcl&gt; &lt;int&gt; &lt;int&gt; &lt;char&gt; &lt;char&gt; &lt;lgcl&gt;\n      1:   &lt;NA&gt;     NA     0    30      1   &lt;NA&gt;   TRUE\n      2:   &lt;NA&gt;     NA     0    NA   &lt;NA&gt;   &lt;NA&gt;   TRUE\n      3:   &lt;NA&gt;     NA   290    10      1   &lt;NA&gt;   TRUE\n      4:   &lt;NA&gt;     NA     0     5      1   &lt;NA&gt;   TRUE\n      5:   &lt;NA&gt;     NA     0    12      1   &lt;NA&gt;   TRUE\n     ---                                               \n1735551:   &lt;NA&gt;     NA -2400    40      1   &lt;NA&gt;   TRUE\n1735552:   &lt;NA&gt;     NA     0    30      1   &lt;NA&gt;   TRUE\n1735553:   &lt;NA&gt;     NA     0    20      1   &lt;NA&gt;   TRUE\n1735554:   &lt;NA&gt;     NA     0    NA   &lt;NA&gt;   &lt;NA&gt;  FALSE\n1735555:   &lt;NA&gt;     NA     0    30      1   &lt;NA&gt;  FALSE\n                                         MAR    MIG\n                                      &lt;fctr&gt; &lt;lgcl&gt;\n      1:                             Married   TRUE\n      2:                             Married   TRUE\n      3: Never married or under 15 years old   TRUE\n      4: Never married or under 15 years old   TRUE\n      5: Never married or under 15 years old   TRUE\n     ---                                           \n1735551:                             Married   TRUE\n1735552:                             Married   TRUE\n1735553: Never married or under 15 years old   TRUE\n1735554:                             Married   TRUE\n1735555:                             Married   TRUE\n                                  MIL   MILY   MLPA   MLPB   MLPC   MLPD   MLPE\n                               &lt;fctr&gt; &lt;fctr&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt;\n      1: Never served in the military   &lt;NA&gt;     NA     NA     NA     NA     NA\n      2: Never served in the military   &lt;NA&gt;     NA     NA     NA     NA     NA\n      3: Never served in the military   &lt;NA&gt;     NA     NA     NA     NA     NA\n      4: Never served in the military   &lt;NA&gt;     NA     NA     NA     NA     NA\n      5: Never served in the military   &lt;NA&gt;     NA     NA     NA     NA     NA\n     ---                                                                       \n1735551: Never served in the military   &lt;NA&gt;     NA     NA     NA     NA     NA\n1735552: Never served in the military   &lt;NA&gt;     NA     NA     NA     NA     NA\n1735553: Never served in the military   &lt;NA&gt;     NA     NA     NA     NA     NA\n1735554: Never served in the military   &lt;NA&gt;     NA     NA     NA     NA     NA\n1735555: Never served in the military   &lt;NA&gt;     NA     NA     NA     NA     NA\n           MLPF   MLPG   MLPH   MLPI   MLPJ   MLPK   NWAB              NWAV\n         &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt;            &lt;fctr&gt;\n      1:     NA     NA     NA     NA     NA     NA     NA    Did not report\n      2:     NA     NA     NA     NA     NA     NA  FALSE    Did not report\n      3:     NA     NA     NA     NA     NA     NA     NA    Did not report\n      4:     NA     NA     NA     NA     NA     NA     NA    Did not report\n      5:     NA     NA     NA     NA     NA     NA     NA    Did not report\n     ---                                                                   \n1735551:     NA     NA     NA     NA     NA     NA     NA    Did not report\n1735552:     NA     NA     NA     NA     NA     NA     NA    Did not report\n1735553:     NA     NA     NA     NA     NA     NA     NA    Did not report\n1735554:     NA     NA     NA     NA     NA     NA  FALSE No, other reasons\n1735555:     NA     NA     NA     NA     NA     NA  FALSE               Yes\n           NWLA   NWLK   NWRE   OIP   PAP    REL  RETP    SCH\n         &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;int&gt; &lt;int&gt; &lt;char&gt; &lt;int&gt; &lt;lgcl&gt;\n      1:     NA     NA     NA  3300  3300   &lt;NA&gt;     0  FALSE\n      2:  FALSE  FALSE     NA     0     0   &lt;NA&gt;     0  FALSE\n      3:     NA     NA     NA     0     0   &lt;NA&gt;     0  FALSE\n      4:     NA     NA     NA     0     0   &lt;NA&gt;     0  FALSE\n      5:     NA     NA     NA     0     0   &lt;NA&gt;     0  FALSE\n     ---                                                     \n1735551:     NA     NA     NA     0     0   &lt;NA&gt;     0  FALSE\n1735552:     NA     NA     NA     0     0   &lt;NA&gt;     0  FALSE\n1735553:     NA     NA     NA     0     0   &lt;NA&gt;     0   TRUE\n1735554:  FALSE  FALSE  FALSE     0     0   &lt;NA&gt;     0  FALSE\n1735555:  FALSE  FALSE     NA     0     0   &lt;NA&gt;     0  FALSE\n                                                     SCHG\n                                                   &lt;char&gt;\n      1:                                             &lt;NA&gt;\n      2:                                             &lt;NA&gt;\n      3:                                             &lt;NA&gt;\n      4:                                             &lt;NA&gt;\n      5:                                             &lt;NA&gt;\n     ---                                                 \n1735551:                                             &lt;NA&gt;\n1735552:                                             &lt;NA&gt;\n1735553: College undergraduate years (freshman to senior)\n1735554:                                             &lt;NA&gt;\n1735555:                                             &lt;NA&gt;\n                                                 SCHL  SEMP    SEX  SSIP   SSP\n                                               &lt;char&gt; &lt;int&gt; &lt;fctr&gt; &lt;int&gt; &lt;int&gt;\n      1:                           Associate's degree     0   Male     0     0\n      2:                  Regular high school diploma     0 Female     0     0\n      3:                           Associate's degree     0   Male     0     0\n      4:                  Regular high school diploma     0   Male     0     0\n      5:                  Regular high school diploma     0   Male     0     0\n     ---                                                                      \n1735551:                            Bachelor's degree     0 Female     0     0\n1735552:                  Regular high school diploma     0   Male     0     0\n1735553: 1 or more years of college credit, no degree     0 Female     0     0\n1735554:           Some college, but less than 1 year     0   Male  3600 30100\n1735555:                  Regular high school diploma 12100 Female     0     0\n          WAGP  WKHP                              WKL    WKW   YOEP   UWRK\n         &lt;int&gt; &lt;int&gt;                           &lt;fctr&gt; &lt;fctr&gt; &lt;char&gt; &lt;lgcl&gt;\n      1: 68000    40        Within the past 12 months   &lt;NA&gt;   1990     NA\n      2:     0    NA Over 5 years ago or never worked   &lt;NA&gt;   2012     NA\n      3: 36000    32        Within the past 12 months   &lt;NA&gt;   2004     NA\n      4: 40000    40        Within the past 12 months   &lt;NA&gt;   1998     NA\n      5: 12000    30        Within the past 12 months   &lt;NA&gt;   &lt;NA&gt;     NA\n     ---                                                                  \n1735551: 30000    40        Within the past 12 months   &lt;NA&gt;   1975     NA\n1735552: 50000    40        Within the past 12 months   &lt;NA&gt;   1957     NA\n1735553: 18000    20        Within the past 12 months   &lt;NA&gt;   &lt;NA&gt;     NA\n1735554:     0    NA Over 5 years ago or never worked   &lt;NA&gt;   &lt;NA&gt;     NA\n1735555: 30100    40        Within the past 12 months   &lt;NA&gt;   &lt;NA&gt;     NA\n            ANC      ANC1P        ANC2P        DECADE\n         &lt;fctr&gt;     &lt;char&gt;       &lt;char&gt;        &lt;fctr&gt;\n      1: Single     Yemeni Not reported   1990 - 1999\n      2: Single     Yemeni Not reported 2010 or later\n      3: Single     Yemeni Not reported   2000 - 2009\n      4: Single     Yemeni Not reported   1990 - 1999\n      5: Single     Yemeni Not reported          &lt;NA&gt;\n     ---                                             \n1735551: Single    Chinese Not reported   1970 - 1979\n1735552: Single Vietnamese Not reported   1950 - 1959\n1735553: Single Vietnamese Not reported          &lt;NA&gt;\n1735554: Single      White Not reported          &lt;NA&gt;\n1735555: Single    Mexican Not reported          &lt;NA&gt;\n                              DRIVESP     DS    ESP                        ESR\n                               &lt;fctr&gt; &lt;lgcl&gt; &lt;fctr&gt;                     &lt;fctr&gt;\n      1: 1.000 vehicles (Drove alone)     NA   &lt;NA&gt; Civilian employed, at work\n      2:                         &lt;NA&gt;     NA   &lt;NA&gt;         Not in Labor Force\n      3: 1.000 vehicles (Drove alone)     NA   &lt;NA&gt; Civilian employed, at work\n      4: 1.000 vehicles (Drove alone)     NA   &lt;NA&gt; Civilian employed, at work\n      5: 1.000 vehicles (Drove alone)     NA   &lt;NA&gt; Civilian employed, at work\n     ---                                                                      \n1735551: 1.000 vehicles (Drove alone)     NA   &lt;NA&gt; Civilian employed, at work\n1735552: 1.000 vehicles (Drove alone)     NA   &lt;NA&gt; Civilian employed, at work\n1735553: 1.000 vehicles (Drove alone)     NA   &lt;NA&gt; Civilian employed, at work\n1735554:                         &lt;NA&gt;     NA   &lt;NA&gt;         Not in Labor Force\n1735555: 1.000 vehicles (Drove alone)     NA   &lt;NA&gt; Civilian employed, at work\n                                HISP\n                              &lt;char&gt;\n      1: Not Spanish/Hispanic/Latino\n      2: Not Spanish/Hispanic/Latino\n      3: Not Spanish/Hispanic/Latino\n      4: Not Spanish/Hispanic/Latino\n      5: Not Spanish/Hispanic/Latino\n     ---                            \n1735551: Not Spanish/Hispanic/Latino\n1735552: Not Spanish/Hispanic/Latino\n1735553: Not Spanish/Hispanic/Latino\n1735554: Not Spanish/Hispanic/Latino\n1735555:                     Mexican\n                                                                                                                 INDP\n                                                                                                               &lt;char&gt;\n      1: MED-General Medical And Surgical Hospitals, And Specialty (Except Psychiatric And Substance Abuse) Hospitals\n      2:                                                                                                         &lt;NA&gt;\n      3:                                                                           SCA-Individual And Family Services\n      4:                                                        MFG-Knitting Fabric Mills, And Apparel Knitting Mills\n      5:                                               RET-Supermarkets and Other Grocery (Except Convenience) Stores\n     ---                                                                                                             \n1735551:                                                                           FIN-Banking And Related Activities\n1735552:                                                                                       RET-Automobile Dealers\n1735553:                                   RET-General Merchandise Stores, Including Warehouse Clubs and Supercenters\n1735554:                                                                                                         &lt;NA&gt;\n1735555:                                                                         EDU-Elementary And Secondary Schools\n                             JWAP                     JWDP       LANP MIGPUMA\n                           &lt;char&gt;                   &lt;char&gt;     &lt;char&gt;  &lt;fctr&gt;\n      1:   9:00 a.m. to 9:04 a.m.   8:30 a.m. to 8:34 a.m.     Arabic    &lt;NA&gt;\n      2:                     &lt;NA&gt;                     &lt;NA&gt;     Arabic    &lt;NA&gt;\n      3:   8:10 a.m. to 8:14 a.m.   8:00 a.m. to 8:04 a.m.     Arabic    &lt;NA&gt;\n      4:   8:05 a.m. to 8:09 a.m.   8:00 a.m. to 8:04 a.m.     Arabic    &lt;NA&gt;\n      5:   7:10 a.m. to 7:14 a.m.   7:00 a.m. to 7:04 a.m.     Arabic    &lt;NA&gt;\n     ---                                                                     \n1735551:   7:55 a.m. to 7:59 a.m.   7:15 a.m. to 7:19 a.m. Vietnamese    &lt;NA&gt;\n1735552:   7:30 a.m. to 7:34 a.m.   7:00 a.m. to 7:04 a.m. Vietnamese    &lt;NA&gt;\n1735553: 11:50 a.m. to 11:54 a.m. 11:30 a.m. to 11:39 a.m. Vietnamese    &lt;NA&gt;\n1735554:                     &lt;NA&gt;                     &lt;NA&gt;       &lt;NA&gt;    &lt;NA&gt;\n1735555:   7:00 a.m. to 7:04 a.m.   6:30 a.m. to 6:34 a.m.       &lt;NA&gt;    &lt;NA&gt;\n          MIGSP                         MSP\n         &lt;char&gt;                      &lt;fctr&gt;\n      1:   &lt;NA&gt; Now Married, Spouse Present\n      2:   &lt;NA&gt; Now Married, Spouse Present\n      3:   &lt;NA&gt;               Never Married\n      4:   &lt;NA&gt;               Never Married\n      5:   &lt;NA&gt;               Never Married\n     ---                                   \n1735551:   &lt;NA&gt; Now Married, Spouse Present\n1735552:   &lt;NA&gt; Now Married, Spouse Present\n1735553:   &lt;NA&gt;               Never Married\n1735554:   &lt;NA&gt; Now Married, Spouse Present\n1735555:   &lt;NA&gt; Now Married, Spouse Present\n                                                                                                               NAICSP\n                                                                                                               &lt;char&gt;\n      1: MED-General Medical And Surgical Hospitals, And Specialty (Except Psychiatric And Substance Abuse) Hospitals\n      2:                                                                                                         &lt;NA&gt;\n      3:                                                                           SCA-Individual And Family Services\n      4:                                                        MFG-Knitting Fabric Mills, And Apparel Knitting Mills\n      5:                                               RET-Supermarkets And Other Grocery (Except Convenience) Stores\n     ---                                                                                                             \n1735551:                                                                           FIN-Banking And Related Activities\n1735552:                                                                                       RET-Automobile Dealers\n1735553:                                   RET-General Merchandise Stores, Including Warehouse Clubs and Supercenters\n1735554:                                                                                                         &lt;NA&gt;\n1735555:                                                                         EDU-Elementary And Secondary Schools\n             NATIVITY     OC                                             OCCP\n               &lt;fctr&gt; &lt;lgcl&gt;                                           &lt;char&gt;\n      1: Foreign born     NA               EDU-Other Teachers and Instructors\n      2: Foreign born     NA                                             &lt;NA&gt;\n      3: Foreign born     NA                          HLS-Personal Care Aides\n      4: Foreign born     NA       CON-Other Construction And Related Workers\n      5:       Native     NA                   TRN-Stockers And Order Fillers\n     ---                                                                     \n1735551: Foreign born     NA                                      OFF-Tellers\n1735552: Foreign born     NA RPR-Automotive Service Technicians And Mechanics\n1735553:       Native     NA                         MED-Pharmacy Technicians\n1735554:       Native     NA                                             &lt;NA&gt;\n1735555:       Native     NA                          EDU-Teaching Assistants\n                                                 PAOC PERNP PINCP         POBP\n                                               &lt;fctr&gt; &lt;int&gt; &lt;int&gt;       &lt;char&gt;\n      1:                                         &lt;NA&gt; 68000 74600        Yemen\n      2: Females with own children under 6 years only     0     0        Yemen\n      3:                                         &lt;NA&gt; 36000 36290        Yemen\n      4:                                         &lt;NA&gt; 40000 40000        Yemen\n      5:                                         &lt;NA&gt; 12000 12000  New York/NY\n     ---                                                                      \n1735551:                 Females with no own children 30000 27600      Vietnam\n1735552:                                         &lt;NA&gt; 50000 50000      Vietnam\n1735553:                 Females with no own children 18000 18000     Texas/TX\n1735554:                                         &lt;NA&gt;     0 33700 Minnesota/MN\n1735555:                 Females with no own children 42200 42200     Texas/TX\n         POVPIP POWPUMA       POWSP                   QTRBIR\n          &lt;int&gt;  &lt;fctr&gt;      &lt;char&gt;                   &lt;fctr&gt;\n      1:    386    &lt;NA&gt; New York/NY       April through June\n      2:    386    &lt;NA&gt;        &lt;NA&gt;    January through March\n      3:    386    &lt;NA&gt; New York/NY       April through June\n      4:    386    &lt;NA&gt; New York/NY   July through September\n      5:    386    &lt;NA&gt; New York/NY October through December\n     ---                                                    \n1735551:    419    &lt;NA&gt;    Texas/TX October through December\n1735552:    419    &lt;NA&gt;    Texas/TX       April through June\n1735553:    419    &lt;NA&gt;    Texas/TX    January through March\n1735554:    431    &lt;NA&gt;        &lt;NA&gt;       April through June\n1735555:    431    &lt;NA&gt;    Texas/TX       April through June\n                         RAC1P                 RAC2P                 RAC3P\n                        &lt;fctr&gt;                &lt;char&gt;                &lt;char&gt;\n      1:           White alone           White alone           White alone\n      2:           White alone           White alone           White alone\n      3:           White alone           White alone           White alone\n      4:           White alone           White alone           White alone\n      5:           White alone           White alone           White alone\n     ---                                                                  \n1735551:           Asian alone      Vietnamese alone      Vietnamese alone\n1735552:           Asian alone      Vietnamese alone      Vietnamese alone\n1735553:           Asian alone      Vietnamese alone      Vietnamese alone\n1735554:           White alone           White alone           White alone\n1735555: Some other race alone Some Other Race alone Some Other Race alone\n         RACAIAN RACASN RACBLK RACNHPI RACNUM RACSOR RACWHT     RC    SFN\n          &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt;  &lt;lgcl&gt;  &lt;int&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;fctr&gt;\n      1:   FALSE  FALSE  FALSE      NA      1  FALSE   TRUE     NA   &lt;NA&gt;\n      2:   FALSE  FALSE  FALSE      NA      1  FALSE   TRUE     NA   &lt;NA&gt;\n      3:   FALSE  FALSE  FALSE      NA      1  FALSE   TRUE     NA   &lt;NA&gt;\n      4:   FALSE  FALSE  FALSE      NA      1  FALSE   TRUE     NA   &lt;NA&gt;\n      5:   FALSE  FALSE  FALSE      NA      1  FALSE   TRUE     NA   &lt;NA&gt;\n     ---                                                                 \n1735551:   FALSE   TRUE  FALSE      NA      1  FALSE  FALSE     NA   &lt;NA&gt;\n1735552:   FALSE   TRUE  FALSE      NA      1  FALSE  FALSE     NA   &lt;NA&gt;\n1735553:   FALSE   TRUE  FALSE      NA      1  FALSE  FALSE     NA   &lt;NA&gt;\n1735554:   FALSE  FALSE  FALSE      NA      1  FALSE   TRUE     NA   &lt;NA&gt;\n1735555:   FALSE  FALSE  FALSE      NA      1   TRUE  FALSE     NA   &lt;NA&gt;\n            SFR                                             SOCP    VPS\n         &lt;fctr&gt;                                           &lt;char&gt; &lt;char&gt;\n      1:   &lt;NA&gt;               EDU-Other Teachers And Instructors   &lt;NA&gt;\n      2:   &lt;NA&gt;                                             &lt;NA&gt;   &lt;NA&gt;\n      3:   &lt;NA&gt;                          HLS-Personal Care Aides   &lt;NA&gt;\n      4:   &lt;NA&gt;       CON-Other Construction And Related Workers   &lt;NA&gt;\n      5:   &lt;NA&gt;                   TRN-Stockers And Order Fillers   &lt;NA&gt;\n     ---                                                               \n1735551:   &lt;NA&gt;                                      OFF-Tellers   &lt;NA&gt;\n1735552:   &lt;NA&gt; RPR-Automotive Service Technicians And Mechanics   &lt;NA&gt;\n1735553:   &lt;NA&gt;                         MED-Pharmacy Technicians   &lt;NA&gt;\n1735554:   &lt;NA&gt;                                             &lt;NA&gt;   &lt;NA&gt;\n1735555:   &lt;NA&gt;                          EDU-Teaching Assistants   &lt;NA&gt;\n                                      WAOB  FAGEP  FANCP  FCITP  FCOWP FDDRSP\n                                    &lt;fctr&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt;\n      1: Asia (POBP = 158-159,161,200-299)  FALSE  FALSE  FALSE   TRUE  FALSE\n      2: Asia (POBP = 158-159,161,200-299)  FALSE  FALSE   TRUE  FALSE  FALSE\n      3: Asia (POBP = 158-159,161,200-299)  FALSE  FALSE  FALSE   TRUE  FALSE\n      4: Asia (POBP = 158-159,161,200-299)  FALSE  FALSE  FALSE   TRUE  FALSE\n      5:         US state (POBP = 001-059)  FALSE  FALSE  FALSE   TRUE  FALSE\n     ---                                                                     \n1735551: Asia (POBP = 158-159,161,200-299)  FALSE  FALSE  FALSE  FALSE  FALSE\n1735552: Asia (POBP = 158-159,161,200-299)  FALSE  FALSE  FALSE  FALSE  FALSE\n1735553:         US state (POBP = 001-059)  FALSE  FALSE  FALSE  FALSE  FALSE\n1735554:         US state (POBP = 001-059)  FALSE  FALSE  FALSE  FALSE  FALSE\n1735555:         US state (POBP = 001-059)  FALSE  FALSE  FALSE  FALSE  FALSE\n         FDEYEP FDOUTP FDPHYP FDREMP FDWRKP  FENGP  FESRP  FFERP  FGCLP  FGCMP\n         &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt;\n      1:  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE\n      2:  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE\n      3:  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE\n      4:  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE\n      5:  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE\n     ---                                                                      \n1735551:  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE\n1735552:  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE\n1735553:  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE\n1735554:  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE\n1735555:  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE\n          FGCRP  FHISP  FINDP  FINTP  FJWDP FJWMNP FJWRIP FJWTRP  FLANP FLANXP\n         &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt;\n      1:  FALSE  FALSE   TRUE   TRUE   TRUE   TRUE   TRUE     NA  FALSE  FALSE\n      2:  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE\n      3:  FALSE  FALSE   TRUE   TRUE   TRUE   TRUE   TRUE     NA  FALSE  FALSE\n      4:  FALSE  FALSE   TRUE   TRUE   TRUE   TRUE   TRUE     NA  FALSE  FALSE\n      5:  FALSE  FALSE   TRUE   TRUE   TRUE   TRUE   TRUE     NA  FALSE  FALSE\n     ---                                                                      \n1735551:  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE\n1735552:  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE\n1735553:  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE\n1735554:  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE\n1735555:  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE     NA  FALSE   TRUE\n          FMARP  FMIGP FMIGSP FMILPP FMILSP FMILYP  FOCCP   FOIP   FPAP  FPOBP\n         &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt;\n      1:  FALSE  FALSE  FALSE  FALSE  FALSE     NA   TRUE   TRUE   TRUE  FALSE\n      2:  FALSE  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE\n      3:  FALSE  FALSE  FALSE  FALSE  FALSE     NA   TRUE   TRUE   TRUE  FALSE\n      4:  FALSE  FALSE  FALSE  FALSE  FALSE     NA   TRUE   TRUE   TRUE  FALSE\n      5:  FALSE  FALSE  FALSE  FALSE  FALSE     NA   TRUE   TRUE   TRUE  FALSE\n     ---                                                                      \n1735551:  FALSE  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE\n1735552:  FALSE  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE\n1735553:  FALSE  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE\n1735554:  FALSE  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE\n1735555:  FALSE  FALSE  FALSE  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE\n         FPOWSP  FRACP  FRELP  FRETP FSCHGP FSCHLP  FSCHP  FSEMP  FSEXP  FSSIP\n         &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt;\n      1:   TRUE  FALSE     NA   TRUE  FALSE  FALSE  FALSE   TRUE  FALSE   TRUE\n      2:  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE\n      3:   TRUE  FALSE     NA   TRUE  FALSE  FALSE  FALSE   TRUE  FALSE   TRUE\n      4:   TRUE  FALSE     NA   TRUE  FALSE  FALSE  FALSE   TRUE  FALSE   TRUE\n      5:   TRUE  FALSE     NA   TRUE  FALSE  FALSE  FALSE   TRUE  FALSE   TRUE\n     ---                                                                      \n1735551:  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE\n1735552:  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE\n1735553:  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE\n1735554:  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE   TRUE\n1735555:  FALSE  FALSE     NA  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE\n           FSSP  FWAGP  FWKHP  FWKLP  FWKWP  FYOEP PWGTP1 PWGTP2 PWGTP3 PWGTP4\n         &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;\n      1:   TRUE   TRUE   TRUE   TRUE     NA  FALSE    266    197     50    300\n      2:  FALSE  FALSE  FALSE  FALSE     NA   TRUE    291    172     54    322\n      3:   TRUE   TRUE   TRUE   TRUE     NA   TRUE    270    192     54    353\n      4:   TRUE   TRUE   TRUE   TRUE     NA   TRUE    311    211     57    307\n      5:   TRUE   TRUE   TRUE   TRUE     NA  FALSE    305    237     66    466\n     ---                                                                      \n1735551:  FALSE  FALSE  FALSE  FALSE     NA   TRUE     35    231    139    217\n1735552:  FALSE  FALSE  FALSE  FALSE     NA   TRUE     41    236    143    221\n1735553:  FALSE  FALSE  FALSE  FALSE     NA  FALSE     50    285    180    237\n1735554:  FALSE  FALSE  FALSE  FALSE     NA  FALSE      5     31      6     16\n1735555:  FALSE  FALSE  FALSE  FALSE     NA  FALSE      6     65      9     27\n         PWGTP5 PWGTP6 PWGTP7 PWGTP8 PWGTP9 PWGTP10 PWGTP11 PWGTP12 PWGTP13\n          &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n      1:    191    287    190     57    152      56     283     170      54\n      2:    172    282    197     55    169      57     304     167      61\n      3:    228    317    189     59    173      71     294     184      63\n      4:    211    274    203     63    159      69     293     189      65\n      5:    211    358    235     66    186      95     385     221      62\n     ---                                                                   \n1735551:    149     36    153     44    198     123      40      42     139\n1735552:    157     35    139     41    196     132      44      46     151\n1735553:    179     46    206     54    250     133      50      53     167\n1735554:     25     28     31     41     23      16       5      40      17\n1735555:     45     42     64     52     35      28       7      49      31\n         PWGTP14 PWGTP15 PWGTP16 PWGTP17 PWGTP18 PWGTP19 PWGTP20 PWGTP21\n           &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n      1:      54     177     169     180     197     179      57      54\n      2:      57     163     169     184     212     192      58      52\n      3:      60     164     179     200     223     218      66      60\n      4:      71     187     179     222     198     217      62      66\n      5:      76     204     205     249     243     219      79      80\n     ---                                                                \n1735551:     160     130     142     117     170     162      53     187\n1735552:     152     141     161     117     183     168      53     216\n1735553:     178     152     187     142     212     232      54     267\n1735554:       5      23      22      24      17       6       6      26\n1735555:      10      30      33      40      25      10      12      38\n         PWGTP22 PWGTP23 PWGTP24 PWGTP25 PWGTP26 PWGTP27 PWGTP28 PWGTP29\n           &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n      1:     185     280      58     187      59     164     296     184\n      2:     190     313      56     176      60     186     275     189\n      3:     213     313      76     204      63     186     294     225\n      4:     218     278      66     210      67     196     304     194\n      5:     230     314      84     226      71     217     389     234\n     ---                                                                \n1735551:      49     134      40     179     218     141     198      36\n1735552:      53     141      42     169     206     139     208      36\n1735553:      70     164      38     202     218     167     256      40\n1735554:      19      25      29       6      18      18      16      34\n1735555:      26      47      46      10      46      27      28      63\n         PWGTP30 PWGTP31 PWGTP32 PWGTP33 PWGTP34 PWGTP35 PWGTP36 PWGTP37\n           &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n      1:     295      56     166     338     295     180     189     165\n      2:     290      57     180     332     312     175     180     165\n      3:     303      67     224     346     350     213     206     172\n      4:     289      74     224     353     322     186     180     191\n      5:     343      89     207     358     335     249     257     245\n     ---                                                                \n1735551:     127     224     190     132     141     141     161     138\n1735552:     129     231     203     137     126     145     172     129\n1735553:     172     278     243     197     177     177     204     153\n1735554:       6      16      21      34      19      40      34       7\n1735555:      13      25      41      89      33      58      59      12\n         PWGTP38 PWGTP39 PWGTP40 PWGTP41 PWGTP42 PWGTP43 PWGTP44 PWGTP45\n           &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n      1:     176     174     297     274     159      56     280     193\n      2:     179     185     301     272     161      64     268     176\n      3:     202     190     298     298     187      59     282     214\n      4:     191     180     302     298     200      55     345     271\n      5:     230     231     335     388     170      70     353     274\n     ---                                                                \n1735551:      33     163     275      41     221     141     210     131\n1735552:      35     156     288      39     248     140     209     142\n1735553:      41     188     336      46     263     164     255     156\n1735554:       5      22      20       6      40       8      16      18\n1735555:       7      38      34       8      54       8      27      42\n         PWGTP46 PWGTP47 PWGTP48 PWGTP49 PWGTP50 PWGTP51 PWGTP52 PWGTP53\n           &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n      1:     282     164      54     155      56     286     180      53\n      2:     276     168      56     180      60     278     198      52\n      3:     338     190      60     165      70     287     216      66\n      4:     303     194      52     194      68     301     174      53\n      5:     374     167      76     211      72     327     203      73\n     ---                                                                \n1735551:      38     154      47     230     121      41      34     107\n1735552:      40     159      45     223     140      44      35     105\n1735553:      48     181      59     240     151      47      41     143\n1735554:      33      31      29      22      17       5      37      17\n1735555:      61      54      43      33      19       9      77      31\n         PWGTP54 PWGTP55 PWGTP56 PWGTP57 PWGTP58 PWGTP59 PWGTP60 PWGTP61\n           &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n      1:      55     178     170     194     196     209      51      56\n      2:      56     184     178     207     180     206      52      58\n      3:      60     222     191     193     218     225      56      64\n      4:      66     184     190     210     196     220      57      59\n      5:      66     210     239     266     222     217      66      83\n     ---                                                                \n1735551:     145     156     142     145     209     141      41     201\n1735552:     144     156     151     154     196     152      50     209\n1735553:     179     175     196     158     249     211      58     300\n1735554:       5      20      21      18      18       8       7      23\n1735555:      10      50      28      29      31      13      11      50\n         PWGTP62 PWGTP63 PWGTP64 PWGTP65 PWGTP66 PWGTP67 PWGTP68 PWGTP69\n           &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n      1:     191     308      53     180      55     182     299     193\n      2:     192     304      63     194      57     188     316     189\n      3:     203     320      63     190      67     212     296     240\n      4:     241     316      64     198      59     184     291     216\n      5:     271     350      75     245      82     237     385     225\n     ---                                                                \n1735551:      46     148      39     127     193     121     255      38\n1735552:      49     158      37     134     192     130     268      41\n1735553:      64     167      40     181     233     162     327      49\n1735554:      15      19      29       5      21      26      20      32\n1735555:      22      36      37       9      40      39      25      47\n         PWGTP70 PWGTP71 PWGTP72 PWGTP73 PWGTP74 PWGTP75 PWGTP76 PWGTP77\n           &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n      1:     270      57     190     303     311     171     176     181\n      2:     291      54     189     306     295     172     170     185\n      3:     265      57     220     307     339     217     207     225\n      4:     310      60     208     309     412     197     168     218\n      5:     331      80     247     355     426     224     217     264\n     ---                                                                \n1735551:     124     208     208     124     139     172     156     151\n1735552:     135     193     212     123     128     159     169     186\n1735553:     150     277     220     174     172     183     227     208\n1735554:       4      16      21      40      20      36      42       7\n1735555:       8      30      52      67      32      82      67      16\n         PWGTP78 PWGTP79 PWGTP80    NOP   ADJINC  CITWP   DEAR   DRAT  DRATX\n           &lt;int&gt;   &lt;int&gt;   &lt;int&gt; &lt;fctr&gt;    &lt;num&gt; &lt;char&gt; &lt;lgcl&gt; &lt;fctr&gt; &lt;lgcl&gt;\n      1:     179     178     305   &lt;NA&gt; 1.029928   2007  FALSE   &lt;NA&gt;     NA\n      2:     171     185     283   &lt;NA&gt; 1.029928   2018  FALSE   &lt;NA&gt;     NA\n      3:     192     201     322   &lt;NA&gt; 1.029928   2014  FALSE   &lt;NA&gt;     NA\n      4:     240     194     265   &lt;NA&gt; 1.029928   2005  FALSE   &lt;NA&gt;     NA\n      5:     252     212     316   &lt;NA&gt; 1.029928   &lt;NA&gt;  FALSE   &lt;NA&gt;     NA\n     ---                                                                    \n1735551:      43     130     245   &lt;NA&gt; 1.042311   1989  FALSE   &lt;NA&gt;     NA\n1735552:      42     138     275   &lt;NA&gt; 1.042311   1993  FALSE   &lt;NA&gt;     NA\n1735553:      50     158     344   &lt;NA&gt; 1.042311   &lt;NA&gt;  FALSE   &lt;NA&gt;     NA\n1735554:       5      19      22   &lt;NA&gt; 1.042311   &lt;NA&gt;   TRUE   &lt;NA&gt;     NA\n1735555:       9      46      44   &lt;NA&gt; 1.042311   &lt;NA&gt;  FALSE   &lt;NA&gt;     NA\n          HINS1  HINS2  HINS3  HINS4  HINS5  HINS6  HINS7  MARHD  MARHM\n         &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt;\n      1:  FALSE   TRUE  FALSE   TRUE  FALSE  FALSE  FALSE  FALSE  FALSE\n      2:  FALSE   TRUE  FALSE   TRUE  FALSE  FALSE  FALSE  FALSE  FALSE\n      3:  FALSE   TRUE  FALSE  FALSE  FALSE  FALSE  FALSE     NA     NA\n      4:  FALSE   TRUE  FALSE  FALSE  FALSE  FALSE  FALSE     NA     NA\n      5:  FALSE   TRUE  FALSE  FALSE  FALSE  FALSE  FALSE     NA     NA\n     ---                                                               \n1735551:   TRUE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE\n1735552:   TRUE   TRUE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE\n1735553:  FALSE   TRUE  FALSE  FALSE  FALSE  FALSE  FALSE     NA     NA\n1735554:   TRUE  FALSE   TRUE   TRUE  FALSE  FALSE  FALSE  FALSE  FALSE\n1735555:   TRUE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE  FALSE\n            MARHT  MARHW MARHYP    DIS  HICOV PRIVCOV PUBCOV FCITWP FDEARP\n           &lt;fctr&gt; &lt;lgcl&gt; &lt;char&gt; &lt;lgcl&gt; &lt;lgcl&gt;  &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt;\n      1: One time  FALSE   2009  FALSE   TRUE    TRUE   TRUE  FALSE  FALSE\n      2: One time  FALSE   2009  FALSE   TRUE    TRUE   TRUE   TRUE  FALSE\n      3:     &lt;NA&gt;     NA   &lt;NA&gt;  FALSE   TRUE    TRUE  FALSE   TRUE  FALSE\n      4:     &lt;NA&gt;     NA   &lt;NA&gt;  FALSE   TRUE    TRUE  FALSE  FALSE  FALSE\n      5:     &lt;NA&gt;     NA   &lt;NA&gt;  FALSE   TRUE    TRUE  FALSE  FALSE  FALSE\n     ---                                                                  \n1735551: One time  FALSE   1998   TRUE   TRUE    TRUE  FALSE  FALSE  FALSE\n1735552: One time  FALSE   1998  FALSE   TRUE    TRUE  FALSE  FALSE  FALSE\n1735553:     &lt;NA&gt;     NA   &lt;NA&gt;  FALSE   TRUE    TRUE  FALSE  FALSE  FALSE\n1735554: One time  FALSE   1974   TRUE   TRUE    TRUE   TRUE  FALSE  FALSE\n1735555: One time  FALSE   1974   TRUE   TRUE    TRUE  FALSE  FALSE  FALSE\n         FDRATP FDRATXP FHINS1P FHINS2P FHINS3P FHINS4P FHINS5P FHINS6P FHINS7P\n         &lt;lgcl&gt;  &lt;lgcl&gt;  &lt;lgcl&gt;  &lt;lgcl&gt;  &lt;lgcl&gt;  &lt;lgcl&gt;  &lt;lgcl&gt;  &lt;lgcl&gt;  &lt;lgcl&gt;\n      1:  FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE\n      2:  FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE\n      3:  FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE\n      4:  FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE\n      5:  FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE\n     ---                                                                       \n1735551:  FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE\n1735552:  FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE\n1735553:  FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE\n1735554:  FALSE   FALSE   FALSE    TRUE   FALSE   FALSE    TRUE    TRUE    TRUE\n1735555:  FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE\n         FMARHDP FMARHMP FMARHTP FMARHWP FMARHYP    WRK            FOD1P  FOD2P\n          &lt;lgcl&gt;  &lt;lgcl&gt;  &lt;lgcl&gt;  &lt;lgcl&gt;  &lt;lgcl&gt; &lt;lgcl&gt;           &lt;char&gt; &lt;char&gt;\n      1:   FALSE   FALSE    TRUE   FALSE    TRUE   TRUE             &lt;NA&gt;   &lt;NA&gt;\n      2:   FALSE   FALSE    TRUE   FALSE    TRUE  FALSE             &lt;NA&gt;   &lt;NA&gt;\n      3:   FALSE   FALSE   FALSE   FALSE   FALSE   TRUE             &lt;NA&gt;   &lt;NA&gt;\n      4:   FALSE   FALSE   FALSE   FALSE   FALSE   TRUE             &lt;NA&gt;   &lt;NA&gt;\n      5:   FALSE   FALSE   FALSE   FALSE   FALSE   TRUE             &lt;NA&gt;   &lt;NA&gt;\n     ---                                                                       \n1735551:   FALSE   FALSE   FALSE   FALSE   FALSE   TRUE General Business   &lt;NA&gt;\n1735552:   FALSE   FALSE   FALSE   FALSE   FALSE   TRUE             &lt;NA&gt;   &lt;NA&gt;\n1735553:   FALSE   FALSE   FALSE   FALSE   FALSE   TRUE             &lt;NA&gt;   &lt;NA&gt;\n1735554:   FALSE   FALSE   FALSE   FALSE   FALSE  FALSE             &lt;NA&gt;   &lt;NA&gt;\n1735555:   FALSE   FALSE   FALSE   FALSE   FALSE   TRUE             &lt;NA&gt;   &lt;NA&gt;\n         SCIENGP SCIENGRLP  FFODP FHINS3C FHINS4C FHINS5C   RELP  FWRKP  FDISP\n          &lt;lgcl&gt;    &lt;lgcl&gt; &lt;lgcl&gt;  &lt;fctr&gt;  &lt;fctr&gt;  &lt;fctr&gt; &lt;char&gt; &lt;lgcl&gt; &lt;lgcl&gt;\n      1:      NA        NA  FALSE    &lt;NA&gt;     Yes    &lt;NA&gt;   &lt;NA&gt;  FALSE  FALSE\n      2:      NA        NA  FALSE    &lt;NA&gt;     Yes    &lt;NA&gt;   &lt;NA&gt;  FALSE  FALSE\n      3:      NA        NA  FALSE    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   &lt;NA&gt;  FALSE  FALSE\n      4:      NA        NA  FALSE    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   &lt;NA&gt;  FALSE  FALSE\n      5:      NA        NA  FALSE    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   &lt;NA&gt;  FALSE  FALSE\n     ---                                                                      \n1735551:   FALSE     FALSE  FALSE    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   &lt;NA&gt;  FALSE  FALSE\n1735552:      NA        NA  FALSE    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   &lt;NA&gt;  FALSE  FALSE\n1735553:      NA        NA  FALSE    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   &lt;NA&gt;  FALSE  FALSE\n1735554:      NA        NA  FALSE      No     Yes    &lt;NA&gt;   &lt;NA&gt;  FALSE  FALSE\n1735555:      NA        NA  FALSE    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;   &lt;NA&gt;  FALSE  FALSE\n         FPERNP FPINCP FPRIVCOVP FPUBCOVP  RACNH  RACPI   SSPA  MLPCD  MLPFG\n         &lt;lgcl&gt; &lt;lgcl&gt;    &lt;lgcl&gt;   &lt;lgcl&gt; &lt;lgcl&gt; &lt;lgcl&gt; &lt;fctr&gt; &lt;lgcl&gt; &lt;lgcl&gt;\n      1:   TRUE   TRUE     FALSE    FALSE  FALSE  FALSE   &lt;NA&gt;     NA     NA\n      2:  FALSE  FALSE     FALSE    FALSE  FALSE  FALSE   &lt;NA&gt;     NA     NA\n      3:   TRUE   TRUE     FALSE    FALSE  FALSE  FALSE   &lt;NA&gt;     NA     NA\n      4:   TRUE   TRUE     FALSE    FALSE  FALSE  FALSE   &lt;NA&gt;     NA     NA\n      5:   TRUE   TRUE     FALSE    FALSE  FALSE  FALSE   &lt;NA&gt;     NA     NA\n     ---                                                                    \n1735551:  FALSE  FALSE     FALSE    FALSE  FALSE  FALSE   &lt;NA&gt;     NA     NA\n1735552:  FALSE  FALSE     FALSE    FALSE  FALSE  FALSE   &lt;NA&gt;     NA     NA\n1735553:  FALSE  FALSE     FALSE    FALSE  FALSE  FALSE   &lt;NA&gt;     NA     NA\n1735554:  FALSE   TRUE      TRUE     TRUE  FALSE  FALSE   &lt;NA&gt;     NA     NA\n1735555:  FALSE  FALSE     FALSE    FALSE  FALSE  FALSE   &lt;NA&gt;     NA     NA\n         FHICOVP                           DIVISION    REGION\n          &lt;lgcl&gt;                             &lt;fctr&gt;    &lt;fctr&gt;\n      1:   FALSE Middle Atlantic (Northeast region) Northeast\n      2:   FALSE Middle Atlantic (Northeast region) Northeast\n      3:   FALSE Middle Atlantic (Northeast region) Northeast\n      4:   FALSE Middle Atlantic (Northeast region) Northeast\n      5:   FALSE Middle Atlantic (Northeast region) Northeast\n     ---                                                     \n1735551:   FALSE  West South Central (South Region)     South\n1735552:   FALSE  West South Central (South Region)     South\n1735553:   FALSE  West South Central (South Region)     South\n1735554:    TRUE  West South Central (South Region)     South\n1735555:   FALSE  West South Central (South Region)     South\n                                                      HIMRKS             JWTRNS\n                                                      &lt;fctr&gt;             &lt;char&gt;\n      1:      Direct purchase coverage, with premium subsidy Car, truck, or van\n      2: Direct purchase coverage, without a premium subsidy               &lt;NA&gt;\n      3:      Direct purchase coverage, with premium subsidy Car, truck, or van\n      4: Direct purchase coverage, without a premium subsidy Car, truck, or van\n      5: Direct purchase coverage, without a premium subsidy Car, truck, or van\n     ---                                                                       \n1735551:                Categorically ineligible for subsidy Car, truck, or van\n1735552: Direct purchase coverage, without a premium subsidy Car, truck, or van\n1735553: Direct purchase coverage, without a premium subsidy Car, truck, or van\n1735554:                Categorically ineligible for subsidy               &lt;NA&gt;\n1735555:                Categorically ineligible for subsidy Car, truck, or van\n                                 RELSHIPP  WKWN FHIMRKSP FJWTRNSP FRELSHIPP\n                                   &lt;char&gt; &lt;int&gt;   &lt;lgcl&gt;   &lt;lgcl&gt;    &lt;lgcl&gt;\n      1:                 Reference person    52     TRUE     TRUE     FALSE\n      2: Opposite-sex husband/wife/spouse    NA     TRUE    FALSE     FALSE\n      3:       Biological son or daughter    52     TRUE     TRUE     FALSE\n      4:       Biological son or daughter    52     TRUE     TRUE     FALSE\n      5:       Biological son or daughter    52     TRUE     TRUE     FALSE\n     ---                                                                   \n1735551:                 Reference person    52    FALSE    FALSE     FALSE\n1735552: Opposite-sex husband/wife/spouse    52    FALSE    FALSE     FALSE\n1735553:       Biological son or daughter    52    FALSE    FALSE     FALSE\n1735554:                 Reference person    NA    FALSE    FALSE     FALSE\n1735555: Opposite-sex husband/wife/spouse    37    FALSE    FALSE     FALSE\n         FWKWNP  MLPIK  year location age_groups ins_type age_decade avg_income\n         &lt;lgcl&gt; &lt;lgcl&gt; &lt;int&gt;   &lt;char&gt;     &lt;char&gt;   &lt;char&gt;      &lt;num&gt;      &lt;num&gt;\n      1:   TRUE     NA  2021       ny      18-64   direct         60   109935.7\n      2:  FALSE     NA  2021       ny      18-64   direct         40   109935.7\n      3:   TRUE     NA  2021       ny      18-64   direct         30   109935.7\n      4:   TRUE     NA  2021       ny      18-64   direct         20   109935.7\n      5:   TRUE     NA  2021       ny      18-64   direct         20   109935.7\n     ---                                                                       \n1735551:  FALSE     NA  2022       tx      18-64 employer         50   103775.2\n1735552:  FALSE     NA  2022       tx        65+ employer         60   103775.2\n1735553:  FALSE     NA  2022       tx      18-64   direct         20   103775.2\n1735554:  FALSE     NA  2022       tx        65+ employer         60   103775.2\n1735555:  FALSE     NA  2022       tx      18-64 employer         60   103775.2"
  },
  {
    "objectID": "materials/slides/02-datatable.html#feature-rich-1",
    "href": "materials/slides/02-datatable.html#feature-rich-1",
    "title": "data.table",
    "section": "Feature Rich",
    "text": "Feature Rich\nReshaping\n\n# Pivot longer - select key demographics\npums_long &lt;- melt(\n  pums, \n  id.vars = c(\"ST\", \"year\", \"SERIALNO\"),\n  measure.vars = c(\"AGEP\", \"PWGTP\", \"PINCP\")\n)\npums_long\n\n                  ST  year      SERIALNO variable value\n              &lt;char&gt; &lt;int&gt;        &lt;char&gt;   &lt;fctr&gt; &lt;int&gt;\n      1: New York/NY  2021 2021HU0896827     AGEP    60\n      2: New York/NY  2021 2021HU0896827     AGEP    40\n      3: New York/NY  2021 2021HU0896827     AGEP    34\n      4: New York/NY  2021 2021HU0896827     AGEP    26\n      5: New York/NY  2021 2021HU0896827     AGEP    20\n     ---                                               \n5206661:    Texas/TX  2022 2022HU0609672    PINCP 27600\n5206662:    Texas/TX  2022 2022HU0609672    PINCP 50000\n5206663:    Texas/TX  2022 2022HU0609672    PINCP 18000\n5206664:    Texas/TX  2022 2022HU0609675    PINCP 33700\n5206665:    Texas/TX  2022 2022HU0609675    PINCP 42200\n\n# Pivot wider - average by state/year\npums_summary &lt;- pums[, \n  .(avg_age = mean(AGEP, na.rm = TRUE),\n    avg_income = mean(PINCP, na.rm = TRUE)), \n  by = .(ST, year)\n]\ndcast(pums_summary, ST ~ year, value.var = \"avg_age\")\n\nKey: &lt;ST&gt;\n              ST     2021     2022\n          &lt;char&gt;    &lt;num&gt;    &lt;num&gt;\n1: California/CA 41.47709 41.54009\n2:   New York/NY 43.12366 43.18311\n3:      Texas/TX 40.59856 40.82080"
  },
  {
    "objectID": "materials/slides/02-datatable.html#feature-rich-2",
    "href": "materials/slides/02-datatable.html#feature-rich-2",
    "title": "data.table",
    "section": "Feature Rich",
    "text": "Feature Rich\nRolling operations\n\n# Population change over time by state\npums_yearly &lt;- pums[, .(pop = sum(PWGTP)), by = .(ST, year)]\nsetkey(pums_yearly, ST, year)\n\n# Calculate 2-year rolling average (limited years available)\npums_yearly[, pop_2yr_avg := frollmean(pop, 2), by = ST]\npums_yearly\n\nKey: &lt;ST, year&gt;\n              ST  year      pop pop_2yr_avg\n          &lt;char&gt; &lt;int&gt;    &lt;int&gt;       &lt;num&gt;\n1: California/CA  2021 39237836          NA\n2: California/CA  2022 39029342    39133589\n3:   New York/NY  2021 19835913          NA\n4:   New York/NY  2022 19677151    19756532\n5:      Texas/TX  2021 29527941          NA\n6:      Texas/TX  2022 30029572    29778756"
  },
  {
    "objectID": "materials/slides/02-datatable.html#feature-rich-3",
    "href": "materials/slides/02-datatable.html#feature-rich-3",
    "title": "data.table",
    "section": "Feature Rich",
    "text": "Feature Rich\nRolling Joins\n\nbenefit_thresholds &lt;- data.table(\n  age_threshold = c(18, 25, 35, 50, 62, 67),\n  benefit_type = c(\"Youth\", \"Young Adult\", \"Adult\", \"Mid-Career\", \"Pre-Retirement\", \"Senior\"),\n  max_benefit = c(500, 800, 1200, 1500, 2000, 2500)\n)\nsetkey(benefit_thresholds, age_threshold)\nbenefit_thresholds\n\nKey: &lt;age_threshold&gt;\n   age_threshold   benefit_type max_benefit\n           &lt;num&gt;         &lt;char&gt;       &lt;num&gt;\n1:            18          Youth         500\n2:            25    Young Adult         800\n3:            35          Adult        1200\n4:            50     Mid-Career        1500\n5:            62 Pre-Retirement        2000\n6:            67         Senior        2500\n\n\n. . .\n\n# Rolling join to assign benefits based on nearest age threshold\npums[\n  benefit_thresholds, \n  benefit_category := benefit_type, \n  on = .(AGEP = age_threshold), \n  roll = -Inf\n]\npums[, .(AGEP, benefit_category, ins_type, location)]\n\n          AGEP benefit_category ins_type location\n         &lt;int&gt;           &lt;char&gt;   &lt;char&gt;   &lt;char&gt;\n      1:    60             &lt;NA&gt;   direct       ny\n      2:    40             &lt;NA&gt;   direct       ny\n      3:    34             &lt;NA&gt;   direct       ny\n      4:    26             &lt;NA&gt;   direct       ny\n      5:    20             &lt;NA&gt;   direct       ny\n     ---                                         \n1735551:    56             &lt;NA&gt; employer       tx\n1735552:    67           Senior employer       tx\n1735553:    21             &lt;NA&gt;   direct       tx\n1735554:    66             &lt;NA&gt; employer       tx\n1735555:    64             &lt;NA&gt; employer       tx\n\n\nroll = \"nearest\" or roll = +Inf are also possible"
  },
  {
    "objectID": "materials/slides/02-datatable.html#feature-rich-4",
    "href": "materials/slides/02-datatable.html#feature-rich-4",
    "title": "data.table",
    "section": "Feature Rich",
    "text": "Feature Rich\nOperators - Core Symbols\nEssential data.table operators for efficient data manipulation\n\n# .N - Number of rows in each group\npums[, .N, by = ST]  # Count rows by state\n\n              ST      N\n          &lt;char&gt;  &lt;int&gt;\n1:   New York/NY 403958\n2:      Texas/TX 554365\n3: California/CA 777232\n\n# .SD - Subset of Data (all columns except grouping)\npums[, names(.SD) := lapply(.SD, mean, na.rm = TRUE), by = ST, .SDcols = c(\"AGEP\", \"PINCP\")]\npums[, .(ST, AGEP, PINCP)]\n\n                  ST  AGEP PINCP\n              &lt;char&gt; &lt;int&gt; &lt;int&gt;\n      1: New York/NY    43 52025\n      2: New York/NY    43 52025\n      3: New York/NY    43 52025\n      4: New York/NY    43 52025\n      5: New York/NY    43 52025\n     ---                        \n1735551:    Texas/TX    40 45756\n1735552:    Texas/TX    40 45756\n1735553:    Texas/TX    40 45756\n1735554:    Texas/TX    40 45756\n1735555:    Texas/TX    40 45756\n\n# .BY - List of grouping variables\npums[, .(mean_age = mean(AGEP), state = gsub(\"/.*$\", \"\", .BY)), by = ST]\n\n              ST mean_age      state\n          &lt;char&gt;    &lt;num&gt;     &lt;char&gt;\n1:   New York/NY       43   New York\n2:      Texas/TX       40      Texas\n3: California/CA       41 California\n\n# .I - Row indices \npums[, .I[which.max(AGEP)], by = ST]  # Index of oldest person per state\n\n              ST     V1\n          &lt;char&gt;  &lt;int&gt;\n1:   New York/NY      1\n2:      Texas/TX 200068\n3: California/CA 461514"
  },
  {
    "objectID": "materials/slides/02-datatable.html#feature-rich-5",
    "href": "materials/slides/02-datatable.html#feature-rich-5",
    "title": "data.table",
    "section": "Feature Rich",
    "text": "Feature Rich\nOperators - Advanced Features\nSpecialized operators for complex operations\n\n# .EACHI - For each item in i (useful with joins)\nhousehold_summary[pums, on = .(ST, year), mean(AGEP), by = .EACHI]\n\n                  ST  year    V1\n              &lt;char&gt; &lt;int&gt; &lt;num&gt;\n      1: New York/NY  2021    43\n      2: New York/NY  2021    43\n      3: New York/NY  2021    43\n      4: New York/NY  2021    43\n      5: New York/NY  2021    43\n     ---                        \n1735551:    Texas/TX  2022    40\n1735552:    Texas/TX  2022    40\n1735553:    Texas/TX  2022    40\n1735554:    Texas/TX  2022    40\n1735555:    Texas/TX  2022    40\n\n# .GRP - Group counter (1, 2, 3, ...)\npums[, .(grp_num = .GRP, pop = sum(PWGTP)), by = ST]\n\n              ST grp_num      pop\n          &lt;char&gt;   &lt;int&gt;    &lt;int&gt;\n1:   New York/NY       1 39513064\n2:      Texas/TX       2 59557513\n3: California/CA       3 78267178\n\n# Multiple .SD operations with .SDcols\npums[, {\n    means &lt;- lapply(.SD, mean, na.rm = TRUE)\n    medians &lt;- lapply(.SD, median, na.rm = TRUE)\n    vars &lt;- names(.SD)\n    .(vars, means, medians)\n  }, \n  by = ST, \n  .SDcols = c(\"AGEP\", \"PINCP\", \"PWGTP\")\n]\n\n              ST   vars    means medians\n          &lt;char&gt; &lt;char&gt;   &lt;list&gt;  &lt;list&gt;\n1:   New York/NY   AGEP       43      43\n2:   New York/NY  PINCP    52025   52025\n3:   New York/NY  PWGTP 97.81478      73\n4:      Texas/TX   AGEP       40      40\n5:      Texas/TX  PINCP    45756   45756\n6:      Texas/TX  PWGTP 107.4338      76\n7: California/CA   AGEP       41      41\n8: California/CA  PINCP    54155   54155\n9: California/CA  PWGTP 100.6999      75\n\n# Chaining with operators\npums[year == 2022][, .N, by = ST][order(-N)]\n\n              ST      N\n          &lt;char&gt;  &lt;int&gt;\n1: California/CA 391171\n2:      Texas/TX 292919\n3:   New York/NY 203891"
  },
  {
    "objectID": "materials/slides/02-datatable.html#feature-rich-6",
    "href": "materials/slides/02-datatable.html#feature-rich-6",
    "title": "data.table",
    "section": "Feature Rich",
    "text": "Feature Rich\nNot convinced by the syntax?\n\nlibrary(dtplyr)\n\npums_dt &lt;- pums |&gt; \n  lazy_dt() |&gt; \n  select(PINCP, age_groups, year) |&gt; \n  group_by(age_groups, year) |&gt; \n  summarise(avg_tot_income = mean(PINCP)) |&gt; \n  collect()  # or as.data.table() will collect it too\npums_dt\n\n# A tibble: 6 × 3\n# Groups:   age_groups [3]\n  age_groups  year avg_tot_income\n  &lt;chr&gt;      &lt;int&gt;          &lt;dbl&gt;\n1 18-64       2021         51100.\n2 18-64       2022         50939.\n3 65+         2021         51131.\n4 65+         2022         50953.\n5 Under 18    2021         50873.\n6 Under 18    2022         50701.\n\npums |&gt; \n  lazy_dt() |&gt; \n  select(PINCP, age_groups, year) |&gt; \n  group_by(age_groups, year) |&gt; \n  summarise(avg_tot_income = mean(PINCP)) |&gt; \n  show_query()\n\n`_DT2`[, .(PINCP, age_groups, year)][, .(avg_tot_income = mean(PINCP)), \n    keyby = .(age_groups, year)]"
  },
  {
    "objectID": "materials/slides/02-datatable.html#review",
    "href": "materials/slides/02-datatable.html#review",
    "title": "data.table",
    "section": "Review",
    "text": "Review\n\nLearn the DT[i, j, by] syntax - it’s the foundation\nUse keys for fast subsetting and joins\nModify by reference with := for memory efficiency\nChain operations and use operators for readable, efficient code\nCheck the documentation - excellent vignettes available\n\nResources:\n\nOfficial vignettes: vignette(\"datatable-intro\")\nGitHub: https://github.com/Rdatatable/data.table\nStack Overflow: [data.table] tag"
  },
  {
    "objectID": "materials/slides/00-setup-intro.html#jonathan-keane",
    "href": "materials/slides/00-setup-intro.html#jonathan-keane",
    "title": "Welcome!",
    "section": "Jonathan Keane",
    "text": "Jonathan Keane\n\n\n\n\n\nEngineering leader at Posit, PBC.\n15+ years building data tools in R and Python for scientific computing.\nPMC member and maintainer of Apache Arrow; author of dittodb\nExperienced with large-scale data analysis, modeling, and enterprise tools"
  },
  {
    "objectID": "materials/slides/00-setup-intro.html#tyson-barrett",
    "href": "materials/slides/00-setup-intro.html#tyson-barrett",
    "title": "Welcome!",
    "section": "Tyson Barrett",
    "text": "Tyson Barrett\n\n\n\n\n\nApplied statistician at Highmark Health and Utah State University\n\n15+ years of R programming and package development experience\nMaintainer of data.table and 3 other R packages\nConsultant on NSF grant supporting data.table infrastructure\nWorks with large datasets (millions of rows, hundreds of columns)"
  },
  {
    "objectID": "materials/slides/00-setup-intro.html#kelly-bodwin",
    "href": "materials/slides/00-setup-intro.html#kelly-bodwin",
    "title": "Welcome!",
    "section": "Kelly Bodwin",
    "text": "Kelly Bodwin\n\n\n\n\n\nAssociate Professor of Statistics and Data Science at Cal Poly\nCo-author of R packages flair and tidyclust\nConsultant on NSF grant supporting data.table infrastructure\nResearch experience with high-volume, in-memory data"
  },
  {
    "objectID": "materials/slides/00-setup-intro.html#setup-1",
    "href": "materials/slides/00-setup-intro.html#setup-1",
    "title": "Welcome!",
    "section": "Setup",
    "text": "Setup\n\nMake sure you have the most recent version of R. (Recommended minimum: R4.0)\nMake sure you have the most recent version of RStudio. (Recommended minimum: 2025 release.)\n(Positron is probably fine, but we haven’t stress-tested that.)\n(Optional) Download all workshop materials."
  },
  {
    "objectID": "materials/slides/00-setup-intro.html#installs",
    "href": "materials/slides/00-setup-intro.html#installs",
    "title": "Welcome!",
    "section": "Installs",
    "text": "Installs\n(Also available as “installs.R” in the workshop materials repository.)\n\ninstall.packages(\"pak\")\n\npak::pak(c(\n  \"data.table\",\n  \"arrow\",\n  \"duckdb\",\n  \"readr\",\n  \"here\",\n  \"glue\",\n  \"tidyr\",\n  \"dplyr\",\n  \"dtplr\",\n  \"duckplyr\",\n  \"tictoc\",\n  \"microbenchmark\",\n  \"bench\",\n  \"lobstr\",\n  \"nanoparquet\"\n))"
  },
  {
    "objectID": "materials/slides/00-setup-intro.html#easiest-quickest-option",
    "href": "materials/slides/00-setup-intro.html#easiest-quickest-option",
    "title": "Welcome!",
    "section": "Easiest, quickest option",
    "text": "Easiest, quickest option\nDownload a subset of the data\n\nThis subset only includes the person-level data for years 2005, 2018, 2021 and only for states Alaska, Alabama, Arkansas, Arizona, California, Washington, Wisconsin, West Virginia, and Wyoming.\nSimply download it and unzip it into a directory called data in your working directory and you can run the examples in the workshop."
  },
  {
    "objectID": "materials/slides/00-setup-intro.html#longer-but-full-dataset-option",
    "href": "materials/slides/00-setup-intro.html#longer-but-full-dataset-option",
    "title": "Welcome!",
    "section": "Longer, but full dataset option",
    "text": "Longer, but full dataset option\nWe also host a full version of the dataset in AWS S3.\nOnce you have setup your AWS account and CLI, download the data into a data directory to use:\naws s3 cp --recursive s3://scaling-arrow-pums/ ./data/\nThis is the full dataset, but does require that you setup your AWS CLI and wait for the dataset to be downloaded."
  },
  {
    "objectID": "materials/slides/00-setup-intro.html#about-the-data",
    "href": "materials/slides/00-setup-intro.html#about-the-data",
    "title": "Welcome!",
    "section": "About the data",
    "text": "About the data\n\nCollected by the United States Census Bureau as part of the American Community Survey\nDisclosure protection — introduces noise to make it impossible to identify specific people or households\nCovers: 2005–2022 using the 1-year estimates (sans 2020; COVID)\nSplit into person and household\n\ncolumns: person: 230, household: 188\nrows: person: 53M, household: 25M"
  },
  {
    "objectID": "materials/slides/00-setup-intro.html#a-few-example-variables",
    "href": "materials/slides/00-setup-intro.html#a-few-example-variables",
    "title": "Welcome!",
    "section": "A few example variables",
    "text": "A few example variables\n\nPerson\n\nLanguage spoken at home (LANP)\nTravel time to work (JWMNP)\n\nHousehold\n\nAccess to internat (ACCESS)\nMonthly rent (RNTP)\n\nWeights 😵‍💫\n\nPWGTP and WGTP for weights"
  },
  {
    "objectID": "materials/slides/00-setup-intro.html#format-of-the-data",
    "href": "materials/slides/00-setup-intro.html#format-of-the-data",
    "title": "Welcome!",
    "section": "Format of the data",
    "text": "Format of the data\n\nReleased and available as CSV files (~90GB)\nUses survey-style coding\n\n\nFor this workshop:\n\nRecoded the dataset\nSaved as parquet (~12GB) partitioned by year and state\n\n\nsurvey-style coding is where categorical variables will be given a number and there is a separate look up table for the values. Additionally, there are frequently sentinel values that mean missing or “99 and greater”\nWe have pulled the key into the actual data so you don’t need to do the lookups and also converted numeric columns into integers, floats, etc. where appropriate."
  },
  {
    "objectID": "materials/slides/00-setup-intro.html#can-i-analyze-all-of-pums",
    "href": "materials/slides/00-setup-intro.html#can-i-analyze-all-of-pums",
    "title": "Welcome!",
    "section": "Can I analyze all of PUMS?",
    "text": "Can I analyze all of PUMS?\n\nMost analysis of PUMS data starts with subsetting the data. Either by state (or even smaller) or year and often both.\n\n\nBut with the tools we learn about in this workshop, we actually can analyze the whole dataset."
  },
  {
    "objectID": "materials/slides/00-setup-intro.html#caveat",
    "href": "materials/slides/00-setup-intro.html#caveat",
    "title": "Welcome!",
    "section": "Caveat",
    "text": "Caveat\n\nThough we have not purposefully altered this data, this data should not be relied on to be a perfect or even possibly accurate representation of the official PUMS dataset."
  },
  {
    "objectID": "materials/slides/00-setup-intro.html#goals-of-this-workshop",
    "href": "materials/slides/00-setup-intro.html#goals-of-this-workshop",
    "title": "Welcome!",
    "section": "Goals of this Workshop",
    "text": "Goals of this Workshop\n\nHelp you navigate when you need a speed-up trick and which tools will help you.\nGet you off the ground using data.table for faster operations on large data fully in R.\nShow you how to set up a duckdb database and use arrow and duckplyr to partition your analysis.\nGive you tools for a unified workflow of these tools."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JSM 2025 Short Course",
    "section": "",
    "text": "by: Kelly Bodwin, Tyson Barrett & Jonathan Keane"
  },
  {
    "objectID": "index.html#large-local-data",
    "href": "index.html#large-local-data",
    "title": "JSM 2025 Short Course",
    "section": "",
    "text": "by: Kelly Bodwin, Tyson Barrett & Jonathan Keane"
  },
  {
    "objectID": "index.html#short-course-description",
    "href": "index.html#short-course-description",
    "title": "JSM 2025 Short Course",
    "section": "Short Course Description",
    "text": "Short Course Description\nIt is increasingly common in academic and professional settings to encounter datasets large enough to exceed the capabilities of standard data processing tools, yet small enough to be stored on local computers. Recent articles even claim that “the era of big data is over” and that data analysts and researchers should “think small, develop locally, ship joyfully” Such “medium” dataests are instrumental in measuring, tracking, and recording a wide array of phenomena across disciplines such as human behavior, animal studies, geology, economics, and astronomy. In this workshop, we will present modern techniques for handling large local data in R using a tidy data pipeline, encompassing stages from data storage and importing to cleaning, analysis, and exporting data and analyses. Specifically, we will teach a combination of tools from the data.table, arrow, and duckDB packages, with a focus on parquet data files for storage and transfer. By the end of the workshop, participants will understand how to integrate these tools to establish a legible, reproducible, efficient, and high-performance workflow."
  },
  {
    "objectID": "index.html#intended-audience-and-level",
    "href": "index.html#intended-audience-and-level",
    "title": "JSM 2025 Short Course",
    "section": "Intended Audience and Level",
    "text": "Intended Audience and Level\nWe expect attendees to have R fluency at the level of a typical introductory course, such as the textbook R for Data Science (Wickham, Çetinkaya-Rundel, & Grolemund 2023); as well as familiarity with some data application that may motivate tools beyond the introductory level."
  },
  {
    "objectID": "dev/Outline_draft.html",
    "href": "dev/Outline_draft.html",
    "title": "Course Outline",
    "section": "",
    "text": "How big is my data? Long, wide or both?\nHow big is my analysis? Big because many groups? Big because looping? Big because matrix computation?\nHow often will I repeat my analysis? By myself as I refine it? In production?\nHow to choose a tool? -&gt; You have one dataset. It can read into R, but tasks are slow:\ngrouping and summarizing, esp over a variable with many cats\nmapping through a column, e.g to string process or custom function\ncomputing lags, sliders, etc.\nmaking many new columns\n\nWhat’s my slowdown? -&gt; profvis\nPersona: Survey research\n-&gt; You have one dataset. It is too large to read into R.\nPersona: Biological genetic data\nWhat’s my slowdown? -&gt; read a few lines, develop your pipeline, profvis\n-&gt; You have many datasets. At least one is too large to read into R. Joining and subsetting is slow.\nPersona: Customer data\n\nWhat makes some code faster than others?\nEfficiency of pipeline: filter before mutate.\nEfficiency of algorithm: think matrix order\nEfficiency of memory handling: careful C allocations\nEfficiency of interpreting or compiling\nEfficiency of data storage structure\nSmart saving of intermediate objects.\n\nx: data size y: number of repeated operations\n1,1: any 1,2: data table. [write more efficient code] 2,1: parquet & arrow [use better storage formats] 2,2: duckdb & arrow [run in SQL not R]\nhigher x -&gt; cloud database higher y -&gt; bigger machine/parallelize across machines/whatever\n\n\n\n\n\n\nsmall: &lt; 1000 or something, everything is split second\nmedium: 100000 or so, and/or many categories, can read into R but analysis is slow\nlarge: parquet can store on local machine\nmassive: too big for local machine\nQuestions for Tyson/Jon: - Easy way to convert csv to parquet w/o reading into R?\n- Column and row size; handled differently in R? In parquet? In a db?\nTitle of course Storing, Importing, Managing, and Analyzing Large Data Locally with R Instructor 1 Kelly Bodwin Instructor 1 Email kbodwin@calpoly.edu Instructor 2 Tyson Barrett Instructor 2 Email tyson.barrett@usu.edu Instructor 3 Jonathan Keane Instructor 3 Email jkeane@gmail.com Length of Course\nFull-day (7.5 contact hours) Course Description It is increasingly common in academic and professional settings to encounter datasets large enough to exceed the capabilities of standard data processing tools, yet small enough to be stored on local computers. Recent articles even claim that “the era of big data is over” and that data analysts and researchers should “think small, develop locally, ship joyfully.” Such “medium” dataests are instrumental in measuring, tracking, and recording a wide array of phenomena across disciplines such as human behavior, animal studies, geology, economics, and astronomy. In this workshop, we will present modern techniques for handling large local data in R using a tidy data pipeline, encompassing stages from data storage and importing to cleaning, analysis, and exporting data and analyses. Specifically, we will teach a combination of tools from the data.table, arrow, and duckDB packages, with a focus on parquet data files for storage and transfer. By the end of the workshop, participants will understand how to integrate these tools to establish a legible, reproducible, efficient, and high-performance workflow.\nCourse Outline The following outline shows our planned approach to managing and analyzing large data locally in R. Our target audience are individuals in academic or professional data analysis positions, who work regularly with datasets that are manageable in terms of local storage but pose significant challenges in processing and cleaning due to their size and complexity.\nUnit 1: Identifying slowdowns in your local data process (Bodwin; 1 hour)\n1.1 Finding the problem:\n- User-friendly code timing with tictoc - Comparing runtimes with atime - Code profiling with profvis\n1.2 Categories of bottlenecks - Common scenarios for repeated runs of code sections - Speed impact from order-of-operations in data wrangling - Fast vs. slow types of dataset operations in R\n1.3 Activity: Code-along demo - Walkthrough of common data structures and tasks that could benefit from modern large-data tools\nUnit 2: In-Memory data wrangling with data.table (Barrett; 2 hours)\n2.1 Introduction - Basic syntax and structure of data.table - Speed comparison for common simple data tasks - High-level, user-friendly intuition for data.table’s “under the hood” parallel processing and C optimization\n2.2 Data wrangling tools - Filtering, summarizing, grouping, and mutating data - Sophisticated data processing with the set* functions.\n2.3 Activity: Code-Along - Real-data examples of data.table use for processing and analyzing data.\n2.4 Reference semantics - Speed and memory gains from modify-by-reference - Effects and side-effects of modify-by-reference - data.table syntax for fast no-copy data transformation\n2.5 Helper packages - Brief highlight of dtplyr and tidyfast as syntactical wrappers to data.table - Storing and reading data.table objects with parquet.\n2.6 Activity: Case Study - Learners work through a guided but incomplete real-data analysis.\nUnit 3: Storing, Reading, and Converting data with arrow, parquet, and duckdb (Keane 2 hours, Bodwin/Barrett 1 hour)\n3.1 Introduction to Arrow and Parquet - Intro to history and development of Arrow - Basic Arrow infrastructure and syntax - Discussion of the interchange problem - Using arrow reader and nanoparquet for efficient dataset storage and input. - Discussion of the Parquet structure, including column orientation and its benefits\n3.2 Activity: Code-Along - Data analysis with Arrow.\n3.3 Introduction to DuckDB - Introduction to duckDB and the local database model. - Basic duckDB syntax. - Data processing and analysis in duckDB - Helper packages such as duckplyr. - Working with duckDB and parquet files simultaneously.\n3.4 Activity: Code-Along - Data analysis with duckDB.\n3.5 Comparison of tools - Similarities and trade-offs of arrow, duckDB, and data.table. - Options for dplyr syntax in all three packages.\n3.6 Activity: Case Study - Goals: Compare, contrast, and benchmark - Learners repeat a data analysis task three times, using each of the three tools. - Learners benchmark the speed of each step of the task in the three implementations. - Discussion and reflection on learner-preferred syntax and usage.\nUnit 4: Putting it together: a workflow for efficient data manipulation (Bodwin/Barrett 1.5 hours)\n4.1 Showcase: A tidy pipeline using these modern, efficient tools - Import/export: fread, parquet with arrow/duckDB - Tidy: dtplyr, duckplyr, arrow - Transform: dtplyr, duckplyr, arrow\n4.2 Decisions and Guidelines - When to choose fread with csv versus parquet conversion. - Pros and cons of the local database structure versus local raw data files. - Specific data sizes, formats, and computations that are best suited to each tool.\n4.3 Activity: Final Case Study - Learners take ownership of a case study of real world large data, writing their own code with a large dataset from start to finish with instructor support Learning Objectives Diagnosing and Benchmarking: - Incorporate time checks into a data analysis workflow to identify slowdowns. - Recognize workflow sections that are likely to be re-run - Design data pipeline steps to isolate and improve bottlenecks\nSyntax: - Write basic data analysis code in data.table - Write basic data analysis code in arrow - Write basic data analysis code in duckDB - Write dplyr syntax code with dtplyr and duckplyr\nConcepts and Ideas: - Recognize grouping and summarizing operations that will benefit from the data.table implementation - Understand the modify-by-reference approach - Understand the benefits of parquet’s column orientation storage - Know the difference between a collection of local files and a local database.\nWorkflow: - Read csv data with fread and parquet format data with arrow - Set up and read/write data in a local duckDB database - Smoothly switch between major large data tools within a single data processing and analyzing pipeline. Instructor(s) Background Dr. Kelly Bodwin is an educator with over a decade of experience of teaching statistics and data science with R. She has co-authored multiple R packages, including flair and tidyclust, and she is currently a consultant on an NSF Grant building infrastructure for the data.table package. Her published applied research frequently involves manipulating large, in-memory data. Examples include: performing large matrix computations on high-dimensional GWAS (genome-wide association studies) data; constructing temporal social networks at hundreds of time checkpoints for organizational membership data; and summarizing biodiversity metrics grouped over exhaustive permutations of taxa level organism counts and experimental conditions. Above all, Dr. Bodwin’s educational goal is to lower barriers to entry for beginner and intermediate R users to benefit from modern tools and enable more efficient and effective data workflows.\nDr. Tyson Barrett is a researcher and an applied statistician at Highmark Health and Utah State University. He has over 15 years of R package development and programming experience, including maintaining data.table (with over 600,000 monthly downloads) and 3 other published R packages. He is currently a consultant on an NSF Grant building infrastructure for the data.table package. In his research work, he regularly works with large datasets with millions of rows and hundreds of columns. He and his team use data.table, arrow, and duckDB daily to manage and analyze their data to efficiently and quickly communicate insights with stakeholders.\nDr. Jonathan Keane is an engineering leader at Posit, PBC with a background in data science and social science. They have been building data tooling for 15 years, including both R and Python data tools for scientific and data science computing. They are a member of the PMC for Apache Arrow, a maintainer of the Apache Arrow package, and the author of dittodb. They have also worked as a data scientist in a number of different industries (identify verification and fraud, market research, call centers, and social justice among other areas) using a wide range of tools to analyze, model, and use data at large enterprise scales. On top of building data tooling, they have a passion for teaching data scientists and others how to use data and tools to do their work and inform their decisions.\nAdditional Comments Learners should bring a working laptop with an installation of R 4.0+ and a recent (2023 or later) installation of RStudio or Positron. Learners should ensure that their laptop has admin permission for installation of new R packages.\nA beginner-intermediate level of working knowledge in R with the tidyverse is assumed; at approximately the level of Chapters 1-8 in Wickham’s R for Data Science (2e)."
  },
  {
    "objectID": "dev/Outline_draft.html#unit-one-defining-the-problem",
    "href": "dev/Outline_draft.html#unit-one-defining-the-problem",
    "title": "Course Outline",
    "section": "",
    "text": "How big is my data? Long, wide or both?\nHow big is my analysis? Big because many groups? Big because looping? Big because matrix computation?\nHow often will I repeat my analysis? By myself as I refine it? In production?\nHow to choose a tool? -&gt; You have one dataset. It can read into R, but tasks are slow:\ngrouping and summarizing, esp over a variable with many cats\nmapping through a column, e.g to string process or custom function\ncomputing lags, sliders, etc.\nmaking many new columns\n\nWhat’s my slowdown? -&gt; profvis\nPersona: Survey research\n-&gt; You have one dataset. It is too large to read into R.\nPersona: Biological genetic data\nWhat’s my slowdown? -&gt; read a few lines, develop your pipeline, profvis\n-&gt; You have many datasets. At least one is too large to read into R. Joining and subsetting is slow.\nPersona: Customer data\n\nWhat makes some code faster than others?\nEfficiency of pipeline: filter before mutate.\nEfficiency of algorithm: think matrix order\nEfficiency of memory handling: careful C allocations\nEfficiency of interpreting or compiling\nEfficiency of data storage structure\nSmart saving of intermediate objects.\n\nx: data size y: number of repeated operations\n1,1: any 1,2: data table. [write more efficient code] 2,1: parquet & arrow [use better storage formats] 2,2: duckdb & arrow [run in SQL not R]\nhigher x -&gt; cloud database higher y -&gt; bigger machine/parallelize across machines/whatever"
  },
  {
    "objectID": "dev/Outline_draft.html#unit-three-handle-it-in-a-local-database-with-arrow-and-duckdb",
    "href": "dev/Outline_draft.html#unit-three-handle-it-in-a-local-database-with-arrow-and-duckdb",
    "title": "Course Outline",
    "section": "",
    "text": "small: &lt; 1000 or something, everything is split second\nmedium: 100000 or so, and/or many categories, can read into R but analysis is slow\nlarge: parquet can store on local machine\nmassive: too big for local machine\nQuestions for Tyson/Jon: - Easy way to convert csv to parquet w/o reading into R?\n- Column and row size; handled differently in R? In parquet? In a db?\nTitle of course Storing, Importing, Managing, and Analyzing Large Data Locally with R Instructor 1 Kelly Bodwin Instructor 1 Email kbodwin@calpoly.edu Instructor 2 Tyson Barrett Instructor 2 Email tyson.barrett@usu.edu Instructor 3 Jonathan Keane Instructor 3 Email jkeane@gmail.com Length of Course\nFull-day (7.5 contact hours) Course Description It is increasingly common in academic and professional settings to encounter datasets large enough to exceed the capabilities of standard data processing tools, yet small enough to be stored on local computers. Recent articles even claim that “the era of big data is over” and that data analysts and researchers should “think small, develop locally, ship joyfully.” Such “medium” dataests are instrumental in measuring, tracking, and recording a wide array of phenomena across disciplines such as human behavior, animal studies, geology, economics, and astronomy. In this workshop, we will present modern techniques for handling large local data in R using a tidy data pipeline, encompassing stages from data storage and importing to cleaning, analysis, and exporting data and analyses. Specifically, we will teach a combination of tools from the data.table, arrow, and duckDB packages, with a focus on parquet data files for storage and transfer. By the end of the workshop, participants will understand how to integrate these tools to establish a legible, reproducible, efficient, and high-performance workflow.\nCourse Outline The following outline shows our planned approach to managing and analyzing large data locally in R. Our target audience are individuals in academic or professional data analysis positions, who work regularly with datasets that are manageable in terms of local storage but pose significant challenges in processing and cleaning due to their size and complexity.\nUnit 1: Identifying slowdowns in your local data process (Bodwin; 1 hour)\n1.1 Finding the problem:\n- User-friendly code timing with tictoc - Comparing runtimes with atime - Code profiling with profvis\n1.2 Categories of bottlenecks - Common scenarios for repeated runs of code sections - Speed impact from order-of-operations in data wrangling - Fast vs. slow types of dataset operations in R\n1.3 Activity: Code-along demo - Walkthrough of common data structures and tasks that could benefit from modern large-data tools\nUnit 2: In-Memory data wrangling with data.table (Barrett; 2 hours)\n2.1 Introduction - Basic syntax and structure of data.table - Speed comparison for common simple data tasks - High-level, user-friendly intuition for data.table’s “under the hood” parallel processing and C optimization\n2.2 Data wrangling tools - Filtering, summarizing, grouping, and mutating data - Sophisticated data processing with the set* functions.\n2.3 Activity: Code-Along - Real-data examples of data.table use for processing and analyzing data.\n2.4 Reference semantics - Speed and memory gains from modify-by-reference - Effects and side-effects of modify-by-reference - data.table syntax for fast no-copy data transformation\n2.5 Helper packages - Brief highlight of dtplyr and tidyfast as syntactical wrappers to data.table - Storing and reading data.table objects with parquet.\n2.6 Activity: Case Study - Learners work through a guided but incomplete real-data analysis.\nUnit 3: Storing, Reading, and Converting data with arrow, parquet, and duckdb (Keane 2 hours, Bodwin/Barrett 1 hour)\n3.1 Introduction to Arrow and Parquet - Intro to history and development of Arrow - Basic Arrow infrastructure and syntax - Discussion of the interchange problem - Using arrow reader and nanoparquet for efficient dataset storage and input. - Discussion of the Parquet structure, including column orientation and its benefits\n3.2 Activity: Code-Along - Data analysis with Arrow.\n3.3 Introduction to DuckDB - Introduction to duckDB and the local database model. - Basic duckDB syntax. - Data processing and analysis in duckDB - Helper packages such as duckplyr. - Working with duckDB and parquet files simultaneously.\n3.4 Activity: Code-Along - Data analysis with duckDB.\n3.5 Comparison of tools - Similarities and trade-offs of arrow, duckDB, and data.table. - Options for dplyr syntax in all three packages.\n3.6 Activity: Case Study - Goals: Compare, contrast, and benchmark - Learners repeat a data analysis task three times, using each of the three tools. - Learners benchmark the speed of each step of the task in the three implementations. - Discussion and reflection on learner-preferred syntax and usage.\nUnit 4: Putting it together: a workflow for efficient data manipulation (Bodwin/Barrett 1.5 hours)\n4.1 Showcase: A tidy pipeline using these modern, efficient tools - Import/export: fread, parquet with arrow/duckDB - Tidy: dtplyr, duckplyr, arrow - Transform: dtplyr, duckplyr, arrow\n4.2 Decisions and Guidelines - When to choose fread with csv versus parquet conversion. - Pros and cons of the local database structure versus local raw data files. - Specific data sizes, formats, and computations that are best suited to each tool.\n4.3 Activity: Final Case Study - Learners take ownership of a case study of real world large data, writing their own code with a large dataset from start to finish with instructor support Learning Objectives Diagnosing and Benchmarking: - Incorporate time checks into a data analysis workflow to identify slowdowns. - Recognize workflow sections that are likely to be re-run - Design data pipeline steps to isolate and improve bottlenecks\nSyntax: - Write basic data analysis code in data.table - Write basic data analysis code in arrow - Write basic data analysis code in duckDB - Write dplyr syntax code with dtplyr and duckplyr\nConcepts and Ideas: - Recognize grouping and summarizing operations that will benefit from the data.table implementation - Understand the modify-by-reference approach - Understand the benefits of parquet’s column orientation storage - Know the difference between a collection of local files and a local database.\nWorkflow: - Read csv data with fread and parquet format data with arrow - Set up and read/write data in a local duckDB database - Smoothly switch between major large data tools within a single data processing and analyzing pipeline. Instructor(s) Background Dr. Kelly Bodwin is an educator with over a decade of experience of teaching statistics and data science with R. She has co-authored multiple R packages, including flair and tidyclust, and she is currently a consultant on an NSF Grant building infrastructure for the data.table package. Her published applied research frequently involves manipulating large, in-memory data. Examples include: performing large matrix computations on high-dimensional GWAS (genome-wide association studies) data; constructing temporal social networks at hundreds of time checkpoints for organizational membership data; and summarizing biodiversity metrics grouped over exhaustive permutations of taxa level organism counts and experimental conditions. Above all, Dr. Bodwin’s educational goal is to lower barriers to entry for beginner and intermediate R users to benefit from modern tools and enable more efficient and effective data workflows.\nDr. Tyson Barrett is a researcher and an applied statistician at Highmark Health and Utah State University. He has over 15 years of R package development and programming experience, including maintaining data.table (with over 600,000 monthly downloads) and 3 other published R packages. He is currently a consultant on an NSF Grant building infrastructure for the data.table package. In his research work, he regularly works with large datasets with millions of rows and hundreds of columns. He and his team use data.table, arrow, and duckDB daily to manage and analyze their data to efficiently and quickly communicate insights with stakeholders.\nDr. Jonathan Keane is an engineering leader at Posit, PBC with a background in data science and social science. They have been building data tooling for 15 years, including both R and Python data tools for scientific and data science computing. They are a member of the PMC for Apache Arrow, a maintainer of the Apache Arrow package, and the author of dittodb. They have also worked as a data scientist in a number of different industries (identify verification and fraud, market research, call centers, and social justice among other areas) using a wide range of tools to analyze, model, and use data at large enterprise scales. On top of building data tooling, they have a passion for teaching data scientists and others how to use data and tools to do their work and inform their decisions.\nAdditional Comments Learners should bring a working laptop with an installation of R 4.0+ and a recent (2023 or later) installation of RStudio or Positron. Learners should ensure that their laptop has admin permission for installation of new R packages.\nA beginner-intermediate level of working knowledge in R with the tidyverse is assumed; at approximately the level of Chapters 1-8 in Wickham’s R for Data Science (2e)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "bio.html",
    "href": "bio.html",
    "title": "Short Course Presenters",
    "section": "",
    "text": "Dr. Kelly Bodwin is an educator with over a decade of experience of teaching statistics and data science with R. She has co-authored multiple R packages, including flair and tidyclust, and she is currently a consultant on an NSF Grant building infrastructure for the data.table package. Her published applied research frequently involves manipulating large, in-memory data. Examples include: performing large matrix computations on high-dimensional GWAS (genome-wide association studies) data; constructing temporal social networks at hundreds of time checkpoints for organizational membership data; and summarizing biodiversity metrics grouped over exhaustive permutations of taxa level organism counts and experimental conditions. Above all, Dr. Bodwin’s educational goal is to lower barriers to entry for beginner and intermediate R users to benefit from modern tools and enable more efficient and effective data workflows.\n\n\n\n🌐 GitHub.\n🦋 BlueSky.\n🔗 LinkedIn.\n🐘 Fosstodon.\n🌐 Blog. |  | Dr. Tyson Barrett is a researcher and an applied statistician at Highmark Health and Utah State University. He has over 15 years of R package development and programming experience, including maintaining data.table (with over 600,000 monthly downloads) and 3 other published R packages. He is currently a consultant on an NSF Grant building infrastructure for the data.table package. In his research work, he regularly works with large datasets with millions of rows and hundreds of columns. He and his team use data.table, arrow, and duckDB daily to manage and analyze their data to efficiently and quickly communicate insights with stakeholders. 🌐 GitHub\n🦋 BlueSky\n🔗 LinkedIn\n🐘 Fosstodon | |  | Dr. Jonathan Keane is an engineering leader at Posit, PBC with a background in data science and social science. They have been building data tooling for 15 years, including both R and Python data tools for scientific and data science computing. They are a member of the PMC for Apache Arrow, a maintainer of the Apache Arrow package, and the author of dittodb. They have also worked as a data scientist in a number of different industries (identify verification and fraud, market research, call centers, and social justice among other areas) using a wide range of tools to analyze, model, and use data at large enterprise scales. On top of building data tooling, they have a passion for teaching data scientists and others how to use data and tools to do their work and inform their decisions. 🌐 GitHub\n🦋 BlueSky\n🔗 LinkedIn\n🐘 Fosstodon |"
  },
  {
    "objectID": "materials/slides/03-arrow.html#section-overview",
    "href": "materials/slides/03-arrow.html#section-overview",
    "title": "parquet, arrow, duckdb",
    "section": "Section Overview",
    "text": "Section Overview\n\nIntroduction to Column-Oriented Data Storage \nDeep Dive into Parquet \nWorking with Arrow in R \nQuerying Parquet with Different Engines \nArrow Datasets for Larger-than-Memory Operations \nPartitioning Strategies \nHands-on Workshop: Analysis with PUMS Data"
  },
  {
    "objectID": "materials/slides/03-arrow.html#why-should-i-care-about-data-storage",
    "href": "materials/slides/03-arrow.html#why-should-i-care-about-data-storage",
    "title": "parquet, arrow, duckdb",
    "section": "Why should I care about data storage?",
    "text": "Why should I care about data storage?\n\nData has to be represented somewhere, both during analysis and when storing.\n\n\nThe shape and characteristics of this representation has a huge impact on performance.\n\n\nWhat if you could speed up a key part of your analysis by 30x and reduce your storage by 10x?"
  },
  {
    "objectID": "materials/slides/03-arrow.html#row-vs.-column-oriented-storage",
    "href": "materials/slides/03-arrow.html#row-vs.-column-oriented-storage",
    "title": "parquet, arrow, duckdb",
    "section": "Row vs. Column-Oriented Storage",
    "text": "Row vs. Column-Oriented Storage\n\n\nRow-oriented\n|ID|Name |Age|City    |\n|--|-----|---|--------|\n|1 |Alice|25 |New York|\n|2 |Bob  |30 |Boston  |\n|3 |Carol|45 |Chicago |\n\n\nEfficient for single record access\nEfficient for appending\n\n\n\n\nColumn-oriented\nID:    [1, 2, 3]\nName:  [Alice, Bob, Carol]\nAge:   [25, 30, 45]\nCity:  [New York, Boston, Chicago]\n\n\nEfficient for analytics\nBetter compression\n\n\n\n\n\nRow oriented formats are super familiar: CSVs as well as many databases\nBut Column-orientation isn’t something that is new and cutting edge. In fact, every single one of you use a system that stores data this way: R data frames(!)"
  },
  {
    "objectID": "materials/slides/03-arrow.html#why-column-oriented-storage",
    "href": "materials/slides/03-arrow.html#why-column-oriented-storage",
    "title": "parquet, arrow, duckdb",
    "section": "Why Column-Oriented Storage?",
    "text": "Why Column-Oriented Storage?\n\nAnalytics typically access a subset of columns\n\n“What is the average age by city?”\nOnly needs [Age, City] columns\n\nBenefits:\n\nOnly read needed columns from disk\nSimilar data types stored together\nBetter compression ratios\n\n\n\nCompression: this is because like-types are stored with like, so you get more frequent patterns — the core of compression. But you also can use encodings like dictionary encodings very efficiently."
  },
  {
    "objectID": "materials/slides/03-arrow.html#column-oriented-data-is-great",
    "href": "materials/slides/03-arrow.html#column-oriented-data-is-great",
    "title": "parquet, arrow, duckdb",
    "section": "Column-Oriented Data is great",
    "text": "Column-Oriented Data is great\n\nAnd you use column-oriented dataframes already!\n\n\n… but still storing my data in a fundamentally row-oriented way.\n\n\nThis isn’t so bad if you’re only talking about a small amount of data, transposing a few columns for a few rows is no big deal. But as data gets larger, or if you have to do this frequently, this process of transposing (AKA serialization) hurts."
  },
  {
    "objectID": "materials/slides/03-arrow.html#the-serialization-problem",
    "href": "materials/slides/03-arrow.html#the-serialization-problem",
    "title": "parquet, arrow, duckdb",
    "section": "The serialization problem",
    "text": "The serialization problem\n\n\nMany of these were operating in essentially column-oriented ways — but to transfer data ended up writting into row-oriented data structures, then read them back in to something that was column-oriented.\nMoving data between representations is hard - Different formats, requirements, and limitations - Compatibility issues - Serialization is a huge bottleneck"
  },
  {
    "objectID": "materials/slides/03-arrow.html#the-serialization-problem-1",
    "href": "materials/slides/03-arrow.html#the-serialization-problem-1",
    "title": "parquet, arrow, duckdb",
    "section": "The serialization problem",
    "text": "The serialization problem"
  },
  {
    "objectID": "materials/slides/03-arrow.html#what-is-apache-arrow",
    "href": "materials/slides/03-arrow.html#what-is-apache-arrow",
    "title": "parquet, arrow, duckdb",
    "section": "What is Apache Arrow?",
    "text": "What is Apache Arrow?\n\n\nCross-language development platform for\nin-memory data\n\nConsistent in-memory columnar data format\nLanguage-independent\nZero-copy reads"
  },
  {
    "objectID": "materials/slides/03-arrow.html#what-is-apache-arrow-1",
    "href": "materials/slides/03-arrow.html#what-is-apache-arrow-1",
    "title": "parquet, arrow, duckdb",
    "section": "What is Apache Arrow?",
    "text": "What is Apache Arrow?\n\n\nBenefits:\n\nSeamless data interchange between systems\nFast analytical processing\nEfficient memory usage"
  },
  {
    "objectID": "materials/slides/03-arrow.html#what-is-apache-parquet",
    "href": "materials/slides/03-arrow.html#what-is-apache-parquet",
    "title": "parquet, arrow, duckdb",
    "section": "What is Apache Parquet?",
    "text": "What is Apache Parquet?\n\n\nOpen-source columnar storage format\n\nCreated by Twitter and Cloudera in 2013\nPart of the Apache Software Foundation"
  },
  {
    "objectID": "materials/slides/03-arrow.html#what-is-apache-parquet-1",
    "href": "materials/slides/03-arrow.html#what-is-apache-parquet-1",
    "title": "parquet, arrow, duckdb",
    "section": "What is Apache Parquet?",
    "text": "What is Apache Parquet?\n\n\nFeatures:\n\nColumnar storage\nExplicit schema\nStatistical metadata\nEfficient compression"
  },
  {
    "objectID": "materials/slides/03-arrow.html#reading-a-file",
    "href": "materials/slides/03-arrow.html#reading-a-file",
    "title": "parquet, arrow, duckdb",
    "section": "Reading a File",
    "text": "Reading a File\nAs a CSV file\n\nsystem.time({\n  df &lt;- read.csv(\"CA_person_2021.csv\")\n})\n\n\n   user  system elapsed \n 14.449   0.445  15.037 \n\n\nDescribe the CSV\nThis CSV is 708 MB, I’m reading this in on my MacBook Pro, your times will vary! We can use arrow or data.tables’s CSV reader and it’s faster (1.85 sec and 1.61 sec respectively). And if we read to an arrow table it’s even faster: 0.51 seconds"
  },
  {
    "objectID": "materials/slides/03-arrow.html#reading-a-file-1",
    "href": "materials/slides/03-arrow.html#reading-a-file-1",
    "title": "parquet, arrow, duckdb",
    "section": "Reading a File",
    "text": "Reading a File\nAs a Parquet file\n\nlibrary(arrow)\noptions(arrow.use_altrep = FALSE)\n\nsystem.time({\n  df &lt;- read_parquet(\"CA_person_2021.parquet\")\n})\n\n\n   user  system elapsed \n  1.017   0.207   0.568 \n\n\nThe parquet file is 62 MB\nIt’s even faster with altrep (0.186 s), but that’s cheating! Also, if we read into an arrow table rather than a dataframe: 0.1 second"
  },
  {
    "objectID": "materials/slides/03-arrow.html#exercise",
    "href": "materials/slides/03-arrow.html#exercise",
    "title": "parquet, arrow, duckdb",
    "section": "Exercise",
    "text": "Exercise\n\ndata &lt;- tibble::tibble(\n  integers = 1:10,\n  doubles = as.numeric(1:10),\n  strings = sprintf(\"%02d\", 1:10)\n)\n\nwrite.csv(data, \"numeric_base.csv\", row.names = FALSE)\nwrite_csv_arrow(data, \"numeric_arrow.csv\")\nwrite_parquet(data, \"numeric.parquet\")\n\ndf_csv &lt;- read.csv(\"numeric_base.csv\")\ndf_csv_arrow &lt;- read_csv_arrow(\"numeric_arrow.csv\")\ndf_parquet &lt;- read_parquet(\"numeric.parquet\")\n\n\nAre there any differences?"
  },
  {
    "objectID": "materials/slides/03-arrow.html#exercise-answer",
    "href": "materials/slides/03-arrow.html#exercise-answer",
    "title": "parquet, arrow, duckdb",
    "section": "Exercise (answer)",
    "text": "Exercise (answer)\n\n\n&gt; df_csv_arrow\n# A tibble: 10 × 3\n   integers doubles strings\n      &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n 1        1       1       1\n 2        2       2       2\n 3        3       3       3\n 4        4       4       4\n 5        5       5       5\n 6        6       6       6\n 7        7       7       7\n 8        8       8       8\n 9        9       9       9\n10       10      10      10\n\n&gt; df_parquet\n# A tibble: 10 × 3\n   integers doubles strings\n      &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1        1       1 01     \n 2        2       2 02     \n 3        3       3 03     \n 4        4       4 04     \n 5        5       5 05     \n 6        6       6 06     \n 7        7       7 07     \n 8        8       8 08     \n 9        9       9 09     \n10       10      10 10"
  },
  {
    "objectID": "materials/slides/03-arrow.html#exercise-answer-1",
    "href": "materials/slides/03-arrow.html#exercise-answer-1",
    "title": "parquet, arrow, duckdb",
    "section": "Exercise (answer)",
    "text": "Exercise (answer)\n\n\n&gt; df_csv_arrow\n# A tibble: 10 × 3\n   integers doubles strings\n      &lt;int&gt;   &lt;int&gt;   &lt;int&gt;\n 1        1       1       1\n 2        2       2       2\n 3        3       3       3\n 4        4       4       4\n 5        5       5       5\n 6        6       6       6\n 7        7       7       7\n 8        8       8       8\n 9        9       9       9\n10       10      10      10\n\n&gt; df_parquet\n# A tibble: 10 × 3\n   integers doubles strings\n      &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1        1       1 01     \n 2        2       2 02     \n 3        3       3 03     \n 4        4       4 04     \n 5        5       5 05     \n 6        6       6 06     \n 7        7       7 07     \n 8        8       8 08     \n 9        9       9 09     \n10       10      10 10"
  },
  {
    "objectID": "materials/slides/03-arrow.html#what-is-inside-a-parquet-file",
    "href": "materials/slides/03-arrow.html#what-is-inside-a-parquet-file",
    "title": "parquet, arrow, duckdb",
    "section": "What is inside a Parquet file?",
    "text": "What is inside a Parquet file?\n\nSchema metadata\n\nSelf-describing format\nPreserves column types\nType-safe data interchange\n\nThe data itself\n\nEncodings\nAdvanced compression\n\n\n\nEncodings: - Dictionary — Particularly effective for categorical data - Run-length encoding - Efficient storage of sequential repeated values\nAdvanced compression:\n\nColumn-specific compression algorithms\nBoth dictionary and value compression"
  },
  {
    "objectID": "materials/slides/03-arrow.html#structure-of-a-parquet-file",
    "href": "materials/slides/03-arrow.html#structure-of-a-parquet-file",
    "title": "parquet, arrow, duckdb",
    "section": "Structure of a Parquet File",
    "text": "Structure of a Parquet File\n\n\n\nRow groups: Horizontal partitions of data\nColumn chunks: Columnar data within a row group\nPages: Small units of column chunk data\nFooter: Contains file metadata and schema"
  },
  {
    "objectID": "materials/slides/03-arrow.html#benchmarks-parquet-vs-csv",
    "href": "materials/slides/03-arrow.html#benchmarks-parquet-vs-csv",
    "title": "parquet, arrow, duckdb",
    "section": "Benchmarks: Parquet vs CSV",
    "text": "Benchmarks: Parquet vs CSV"
  },
  {
    "objectID": "materials/slides/03-arrow.html#benchmarks-parquet-vs-csv-1",
    "href": "materials/slides/03-arrow.html#benchmarks-parquet-vs-csv-1",
    "title": "parquet, arrow, duckdb",
    "section": "Benchmarks: Parquet vs CSV",
    "text": "Benchmarks: Parquet vs CSV"
  },
  {
    "objectID": "materials/slides/03-arrow.html#reading-efficiency-selecting-columns",
    "href": "materials/slides/03-arrow.html#reading-efficiency-selecting-columns",
    "title": "parquet, arrow, duckdb",
    "section": "Reading Efficiency: Selecting Columns",
    "text": "Reading Efficiency: Selecting Columns\n\nWith CSV:\n\nMust read entire file, even if you only need a few columns\nNo efficient way to skip columns during read\n\nWith Parquet:\n\nRead only needed columns from disk\nSignificant performance benefit for wide tables"
  },
  {
    "objectID": "materials/slides/03-arrow.html#reading-efficiency-selecting-columns-1",
    "href": "materials/slides/03-arrow.html#reading-efficiency-selecting-columns-1",
    "title": "parquet, arrow, duckdb",
    "section": "Reading Efficiency: Selecting Columns",
    "text": "Reading Efficiency: Selecting Columns\n\n\nsystem.time({\n  df_subset &lt;- read_parquet(\n    \"CA_person_2021.parquet\", \n    col_select = c(\"PUMA\", \"COW\")\n  )\n})\n\n\n\n\n   user  system elapsed \n  0.027   0.003   0.031 \n\n   user  system elapsed \n  1.017   0.207   0.568"
  },
  {
    "objectID": "materials/slides/03-arrow.html#nanoparquet-vs.-arrow-reader",
    "href": "materials/slides/03-arrow.html#nanoparquet-vs.-arrow-reader",
    "title": "parquet, arrow, duckdb",
    "section": "nanoparquet vs. arrow Reader",
    "text": "nanoparquet vs. arrow Reader\n\nnanoparquet\n\nLightweight Parquet reader\nMinimal dependencies\nGood for embedding\n\narrow\n\nFull-featured reader\nSupport for datasets\nIntegration with Arrow ecosystem"
  },
  {
    "objectID": "materials/slides/03-arrow.html#nanoparquet-vs.-arrow-reader-1",
    "href": "materials/slides/03-arrow.html#nanoparquet-vs.-arrow-reader-1",
    "title": "parquet, arrow, duckdb",
    "section": "nanoparquet vs. arrow Reader",
    "text": "nanoparquet vs. arrow Reader\n\nlibrary(arrow)\noptions(arrow.use_altrep = FALSE)\n\nsystem.time({\n  df &lt;- read_parquet(\"CA_person_2021.parquet\")\n})\n\n   user  system elapsed \n  1.017   0.207   0.568 \n\n\n\n\n\nlibrary(nanoparquet)\n\nsystem.time({\n  df &lt;- read_parquet(\"CA_person_2021.parquet\")\n})\n\n   user  system elapsed \n  0.709   0.099   0.894"
  },
  {
    "objectID": "materials/slides/03-arrow.html#parquet-tooling-ecosystem",
    "href": "materials/slides/03-arrow.html#parquet-tooling-ecosystem",
    "title": "parquet, arrow, duckdb",
    "section": "Parquet Tooling Ecosystem",
    "text": "Parquet Tooling Ecosystem\nLanguages with native Parquet support:\n\nR (via arrow, nanoparquet)\nPython (via pyarrow, pandas)\nJava\nC++\nRust\nJavaScript\nGo"
  },
  {
    "objectID": "materials/slides/03-arrow.html#parquet-tooling-ecosystem-1",
    "href": "materials/slides/03-arrow.html#parquet-tooling-ecosystem-1",
    "title": "parquet, arrow, duckdb",
    "section": "Parquet Tooling Ecosystem",
    "text": "Parquet Tooling Ecosystem\nSystems with Parquet integration:\n\nDuckDB\nGoogle BigQuery\nSnowflake\nAmazon Athena\nApache Spark\nApache Hadoop"
  },
  {
    "objectID": "materials/slides/03-arrow.html#introduction-to-the-arrow-package",
    "href": "materials/slides/03-arrow.html#introduction-to-the-arrow-package",
    "title": "parquet, arrow, duckdb",
    "section": "Introduction to the arrow Package",
    "text": "Introduction to the arrow Package\n\n# Install and load the Arrow package\ninstall.packages(\"arrow\")\nlibrary(arrow)\n\n# Check Arrow version and capabilities\narrow_info()\n\n\nThe arrow package provides:\n\nNative R interface to Apache Arrow\nTools for working with large datasets\nIntegration with dplyr for data manipulation\nReading/writing various file formats"
  },
  {
    "objectID": "materials/slides/03-arrow.html#reading-and-writing-parquet-files-revisited",
    "href": "materials/slides/03-arrow.html#reading-and-writing-parquet-files-revisited",
    "title": "parquet, arrow, duckdb",
    "section": "Reading and Writing Parquet files, revisited",
    "text": "Reading and Writing Parquet files, revisited\n\n# Read a Parquet file into R\ndata &lt;- read_parquet(\"CA_person_2021.parquet\")\n\n# Write an R data frame to Parquet\nwrite_parquet(data, \"CA_person_2021_new.parquet\")\n\n# Reading a subset of columns\ndf_subset &lt;- read_parquet(\n  \"CA_person_2021.parquet\", \n  col_select = c(\"PUMA\", \"COW\", \"AGEP\")\n)\n\n# Reading with a row filter (predicate pushdown)\ndf_filtered &lt;- open_dataset(\"CA_person_2021.parquet\") |&gt; \n  filter(AGEP &gt; 40) |&gt;\n  collect()"
  },
  {
    "objectID": "materials/slides/03-arrow.html#demo-using-dplyr-with-arrow",
    "href": "materials/slides/03-arrow.html#demo-using-dplyr-with-arrow",
    "title": "parquet, arrow, duckdb",
    "section": "Demo: Using dplyr with arrow",
    "text": "Demo: Using dplyr with arrow\n\n# Create an Arrow Table\ntable &lt;- read_parquet(\"CA_person_2021.parquet\", as_data_frame = FALSE)\n\n# Use dplyr verbs with arrow tables\ntable |&gt;\n  filter(AGEP &gt;= 16) |&gt;\n  summarize(\n    mean_commute_time = sum(JWMNP * PWGTP, na.rm = TRUE) /\n      sum(PWGTP),\n    count = n()\n  ) |&gt;\n  collect()\n\n\nWithout as_data_frame = FALSE: the dataframe is backed by altrep, actually. But generally functions like any other dataframe."
  },
  {
    "objectID": "materials/slides/03-arrow.html#introduction-to-duckdb",
    "href": "materials/slides/03-arrow.html#introduction-to-duckdb",
    "title": "parquet, arrow, duckdb",
    "section": "Introduction to DuckDB",
    "text": "Introduction to DuckDB\n\n\nAnalytical SQL database system\n\nEmbedded database (like SQLite)\nColumn oriented\nIn-process query execution\n\nFeatures:\n\nDirect Parquet querying\nParallel processing\nZero-copy integration with arrow\n\n\n\nThe zero-copy integration with arrow is because DuckDB uses basically the same format for it’s own internal representation."
  },
  {
    "objectID": "materials/slides/03-arrow.html#duckdb",
    "href": "materials/slides/03-arrow.html#duckdb",
    "title": "parquet, arrow, duckdb",
    "section": "DuckDB",
    "text": "DuckDB\n\nlibrary(duckdb)\n\ncon &lt;- dbConnect(duckdb())\n\n# Register a Parquet file as a virtual table\ndbExecute(con, \"CREATE VIEW pums AS SELECT * \n                FROM read_parquet('CA_person_2021.parquet')\")\n\n# Run our query\ndbGetQuery(con, \"\n  SELECT SUM(JWMNP * PWGTP)/SUM(PWGTP) as avg_commute_time,\n         COUNT(*) as count\n  FROM pums\n  WHERE AGEP &gt;= 16\n\")\n\ndbDisconnect(con, shutdown = TRUE)"
  },
  {
    "objectID": "materials/slides/03-arrow.html#duckplyr",
    "href": "materials/slides/03-arrow.html#duckplyr",
    "title": "parquet, arrow, duckdb",
    "section": "duckplyr",
    "text": "duckplyr\n\nlibrary(duckplyr)\n\n# Read data with Arrow\npums_data &lt;- read_file_duckdb(\n  \"CA_person_2021.parquet\", \n  \"read_parquet\"\n)\n\n# Use duckplyr to optimize dplyr operations\npums_data |&gt;\n  filter(AGEP &gt;= 16) |&gt;\n  summarize(\n    mean_commute_time = sum(JWMNP * PWGTP, na.rm = TRUE) /\n      sum(PWGTP),\n    count = n()\n  ) |&gt;\n  collect()\n\n\nduckplyr is a drop-in replacement for dplyr, using duckdb as a backend"
  },
  {
    "objectID": "materials/slides/03-arrow.html#data.table",
    "href": "materials/slides/03-arrow.html#data.table",
    "title": "parquet, arrow, duckdb",
    "section": "data.table",
    "text": "data.table\n\nlibrary(arrow)\nlibrary(data.table)\n\n# Read Parquet file with Arrow\npums_data &lt;- read_parquet(\"CA_person_2021.parquet\")\n\n# Convert to data.table\npums_dt &lt;- as.data.table(pums_data)\n\n# data.table query\npums_dt[AGEP &gt;= 16,\n  .(avg_commute_time = sum(JWMNP * PWGTP, na.rm = TRUE) / sum(PWGTP), \n    count = .N)]"
  },
  {
    "objectID": "materials/slides/03-arrow.html#demo-seamless-integration-arrow-duckdb",
    "href": "materials/slides/03-arrow.html#demo-seamless-integration-arrow-duckdb",
    "title": "parquet, arrow, duckdb",
    "section": "Demo: Seamless Integration Arrow ↔︎ DuckDB",
    "text": "Demo: Seamless Integration Arrow ↔︎ DuckDB\n\ntable &lt;- read_parquet(\"CA_person_2021.parquet\", as_data_frame = FALSE)\n\n# Use dplyr verbs with arrow tables\ntable |&gt;\n  filter(AGEP &gt;= 16) |&gt;\n  to_duckdb() |&gt;\n  summarize(\n    mean_commute_time = sum(JWMNP * PWGTP, na.rm = TRUE) /\n      sum(PWGTP),\n    count = n()\n  )"
  },
  {
    "objectID": "materials/slides/03-arrow.html#understanding-arrow-datasets-vs.-tables",
    "href": "materials/slides/03-arrow.html#understanding-arrow-datasets-vs.-tables",
    "title": "parquet, arrow, duckdb",
    "section": "Understanding Arrow Datasets vs. Tables",
    "text": "Understanding Arrow Datasets vs. Tables\n\n\nArrow Table\n\nIn-memory data structure\nMust fit in RAM\nFast operations\nSimilar to base data frames\nGood for single file data\n\n\nArrow Dataset\n\nCollection of files\nLazily evaluated\nLarger-than-memory capable\nDistributed execution\nSupports partitioning"
  },
  {
    "objectID": "materials/slides/03-arrow.html#demo-querying-multi-file-datasets",
    "href": "materials/slides/03-arrow.html#demo-querying-multi-file-datasets",
    "title": "parquet, arrow, duckdb",
    "section": "Demo: Querying Multi-file Datasets",
    "text": "Demo: Querying Multi-file Datasets\n\npums_ds &lt;- open_dataset(\"data/person\")\n\n# Examine the dataset, list files\nprint(pums_ds)\nhead(pums_ds$files)\n\n# Query execution with lazy evaluation\npums_ds |&gt;\n  filter(AGEP &gt;= 16) |&gt;\n  group_by(year, ST) |&gt;\n  summarize(\n    mean_commute_time = sum(JWMNP * PWGTP, na.rm = TRUE) /\n      sum(PWGTP),\n    count = n()\n  ) |&gt;\n  collect()\n\n\nMention Acero engine in C++"
  },
  {
    "objectID": "materials/slides/03-arrow.html#lazy-evaluation-and-query-optimization",
    "href": "materials/slides/03-arrow.html#lazy-evaluation-and-query-optimization",
    "title": "parquet, arrow, duckdb",
    "section": "Lazy Evaluation and Query Optimization",
    "text": "Lazy Evaluation and Query Optimization\n\nLazy evaluation workflow:\n\nDefine operations (filter, group, summarize)\nOptimizes the plan (predicate pushdown, et c.)\nOnly reads necessary data from disk\nExecutes when collect() is called\n\nBenefits:\n\nMinimizes memory usage + reduces I/O\nLeverages Arrow’s native compute functions"
  },
  {
    "objectID": "materials/slides/03-arrow.html#working-with-datasets-on-s3",
    "href": "materials/slides/03-arrow.html#working-with-datasets-on-s3",
    "title": "parquet, arrow, duckdb",
    "section": "Working with Datasets on S3",
    "text": "Working with Datasets on S3\narrow can work with data and datasets in cloud storage. This can be a good option if you don’t have access to a formal DBMS.\n\nEasy to store\narrow efficiently uses metadata to read only what is necessary\n\n\nI know, I know — this workshop is about local files. But I couldn’t help myself"
  },
  {
    "objectID": "materials/slides/03-arrow.html#demo-working-with-datasets-on-s3",
    "href": "materials/slides/03-arrow.html#demo-working-with-datasets-on-s3",
    "title": "parquet, arrow, duckdb",
    "section": "Demo: Working with Datasets on S3",
    "text": "Demo: Working with Datasets on S3\n\npums_ds &lt;- open_dataset(\"s3://scaling-arrow-pums/person/\")\n\n# Query execution with lazy evaluation\npums_ds |&gt;\n  filter(year == 2021, location == \"ca\", AGEP &gt;= 16) |&gt;\n  group_by(year, ST) |&gt;\n  summarize(\n    mean_commute_time = sum(JWMNP * PWGTP, na.rm = TRUE) /\n      sum(PWGTP),\n    count = n()\n  ) |&gt;\n  collect()\n\n\nTalk about partitioning helping, etc"
  },
  {
    "objectID": "materials/slides/03-arrow.html#demo-sipping-data",
    "href": "materials/slides/03-arrow.html#demo-sipping-data",
    "title": "parquet, arrow, duckdb",
    "section": "Demo: Sipping data",
    "text": "Demo: Sipping data\n\npums_ds &lt;- open_dataset(\"s3://scaling-arrow-pums/person/\")\n\n# Query execution with lazy evaluation\npums_ds |&gt;\n  filter(AGEP &gt;= 97) |&gt;\n  collect()\n\n\nAround ~110MB\nSys.getpid() nettop -p X"
  },
  {
    "objectID": "materials/slides/03-arrow.html#what-is-partitioning",
    "href": "materials/slides/03-arrow.html#what-is-partitioning",
    "title": "parquet, arrow, duckdb",
    "section": "What is Partitioning?",
    "text": "What is Partitioning?\n\nDividing data into logical segments\n\nStored in separate files/directories\nBased on one or more column values\nEnables efficient filtering\n\nBenefits:\n\nFaster queries that filter on partition columns\nImproved parallel processing\nEasier management of large datasets"
  },
  {
    "objectID": "materials/slides/03-arrow.html#hive-vs.-non-hive-partitioning",
    "href": "materials/slides/03-arrow.html#hive-vs.-non-hive-partitioning",
    "title": "parquet, arrow, duckdb",
    "section": "Hive vs. Non-Hive Partitioning",
    "text": "Hive vs. Non-Hive Partitioning\n\n\nHive Partitioning\n\nDirectory format: column=value\nExample:\nperson/\n├── year=2018/\n│   ├── state=NY/\n│   │   └── data.parquet\n│   └── state=CA/\n│       └── data.parquet\n├── year=2019/\n│   ├── ...\nSelf-describing structure\nStandard in big data ecosystem\n\n\nNon-Hive Partitioning\n\nDirectory format: value\nExample:\nperson/\n├── 2018/\n│   ├── NY/\n│   │   └── data.parquet\n│   └── CA/\n│       └── data.parquet\n├── 2019/\n│   ├── ...\nRequires column naming\nLess verbose directory names"
  },
  {
    "objectID": "materials/slides/03-arrow.html#effective-partitioning-strategies",
    "href": "materials/slides/03-arrow.html#effective-partitioning-strategies",
    "title": "parquet, arrow, duckdb",
    "section": "Effective Partitioning Strategies",
    "text": "Effective Partitioning Strategies\n\nChoose partition columns wisely:\n\nCommonly used in filters\nLow to medium cardinality\n\nCommon partition dimensions:\n\nTime (year, month, day)\nGeography (country, state, region)\nCategory (product type, department)"
  },
  {
    "objectID": "materials/slides/03-arrow.html#partitioning-in-practice-writing-datasets",
    "href": "materials/slides/03-arrow.html#partitioning-in-practice-writing-datasets",
    "title": "parquet, arrow, duckdb",
    "section": "Partitioning in Practice: Writing Datasets",
    "text": "Partitioning in Practice: Writing Datasets\n\nca_pums_data &lt;- read_parquet(\"CA_person_2021.parquet\")\n\nca_pums_data |&gt;\n  mutate(\n    age_group = case_when(\n      AGEP &lt; 18 ~ \"under_18\",\n      AGEP &lt; 30 ~ \"18_29\",\n      AGEP &lt; 45 ~ \"30_44\",\n      AGEP &lt; 65 ~ \"45_64\",\n      TRUE ~ \"65_plus\"\n    )\n  ) |&gt;\n  group_by(ST, age_group) |&gt;\n  write_dataset(\n    path = \"ca_pums_by_age/\"\n  )"
  },
  {
    "objectID": "materials/slides/03-arrow.html#demo-repartitioning-the-whole-dataset",
    "href": "materials/slides/03-arrow.html#demo-repartitioning-the-whole-dataset",
    "title": "parquet, arrow, duckdb",
    "section": "Demo: Repartitioning the whole dataset",
    "text": "Demo: Repartitioning the whole dataset\n\npums_data &lt;- open_dataset(\"data/person\")\n\npums_data |&gt;\n  mutate(\n    age_group = case_when(\n      AGEP &lt; 18 ~ \"under_18\",\n      AGEP &lt; 30 ~ \"18_29\",\n      AGEP &lt; 45 ~ \"30_44\",\n      AGEP &lt; 65 ~ \"45_64\",\n      TRUE ~ \"65_plus\"\n    )\n  ) |&gt;\n  group_by(year, ST, age_group) |&gt;\n  write_dataset(\n    path = \"pums_by_age/\"\n  )\n\n\nuser system elapsed 386.530 65.862 115.496"
  },
  {
    "objectID": "materials/slides/03-arrow.html#best-practices-for-partition-design",
    "href": "materials/slides/03-arrow.html#best-practices-for-partition-design",
    "title": "parquet, arrow, duckdb",
    "section": "Best Practices for Partition Design",
    "text": "Best Practices for Partition Design\n\nAvoid over-partitioning:\n\nToo many small files = poor performance\nTarget file size: 20MB–2GB\nAvoid high-cardinality columns (e.g., user_id)\n\nConsider query patterns:\n\nPartition by commonly filtered columns\nBalance between read speed and write complexity"
  },
  {
    "objectID": "materials/slides/03-arrow.html#partitioning-performance-impact",
    "href": "materials/slides/03-arrow.html#partitioning-performance-impact",
    "title": "parquet, arrow, duckdb",
    "section": "Partitioning Performance Impact",
    "text": "Partitioning Performance Impact\n\n\nopen_dataset(\"&lt;path/to/data&gt;\") |&gt;\n  filter(year &gt;= 2018) |&gt;\n  summarise(\n    mean_commute = sum(JWMNP * PWGTP, na.rm = TRUE) / sum(PWGTP)\n  ) |&gt;\n  collect()"
  },
  {
    "objectID": "materials/slides/03-arrow.html#conclusion",
    "href": "materials/slides/03-arrow.html#conclusion",
    "title": "parquet, arrow, duckdb",
    "section": "Conclusion",
    "text": "Conclusion\n\nColumn-oriented storage formats like Parquet provide massive performance advantages for analytical workloads (30x speed, 10x smaller files)\nPartitioning strategies help manage large datasets effectively when working with data too big for memory"
  },
  {
    "objectID": "materials/slides/03-arrow.html#conclusion-1",
    "href": "materials/slides/03-arrow.html#conclusion-1",
    "title": "parquet, arrow, duckdb",
    "section": "Conclusion",
    "text": "Conclusion\n\nApache Arrow enables seamless data interchange between systems without costly serialization/deserialization\nMultiple query engines (arrow, DuckDB, data.table) offer flexibility depending on your analysis needs, all using modern formats like Parquet"
  },
  {
    "objectID": "materials/slides/03-arrow.html#conclusion-2",
    "href": "materials/slides/03-arrow.html#conclusion-2",
    "title": "parquet, arrow, duckdb",
    "section": "Conclusion",
    "text": "Conclusion\nResources:\n\nWorkshop materials: GitHub Repository\nArrow documentation: arrow.apache.org/docs/r\nParquet: parquet.apache.org\nDuckDB: duckdb.org\nBook: Scaling up with Arrow and R\n20% Discount on a physical book with code: 25AFLY2"
  },
  {
    "objectID": "materials/slides/04-workflow.html#parquet-workflow",
    "href": "materials/slides/04-workflow.html#parquet-workflow",
    "title": "Towards a Smooth Workflow",
    "section": "Parquet workflow",
    "text": "Parquet workflow\n\nIf you only have csvs, arrow can convert them to parquets.\n(Even if the csvs can’t be read into R!)\nThink about data partitions that make sense.\narrow syntax mimics dplyr for some table operations."
  },
  {
    "objectID": "materials/slides/04-workflow.html#duckdb-workflow",
    "href": "materials/slides/04-workflow.html#duckdb-workflow",
    "title": "Towards a Smooth Workflow",
    "section": "duckdb workflow",
    "text": "duckdb workflow\n\nUse duckdb to set up an “invisible” databalse.\nUse dbConnect(), dbExecute() etc. to send SQL queries to the database.\nOr, use duckplyr to write dplyr-like code that translates to SQL.\nBe strategic - run filters and summaries on the database, then collect() into R for more analysis."
  },
  {
    "objectID": "materials/slides/04-workflow.html#data.table-workflow",
    "href": "materials/slides/04-workflow.html#data.table-workflow",
    "title": "Towards a Smooth Workflow",
    "section": "data.table workflow",
    "text": "data.table workflow\n\nUse fread() for csvs, or arrow functions for parquets, or lazy_dt() to convert collected data frames.\nFull dataset is in R - no databases or partitioning here!\nUse dtplyr for dplyr-like code that translates to data.table.\nEspecially fast for:\n\nsplit-apply-combine on many groups\nrolling windows\npivoting"
  },
  {
    "objectID": "materials/activities/03-practice-arrow.html",
    "href": "materials/activities/03-practice-arrow.html",
    "title": "Hands-on practice: Using parquet, arrow, and duckdb",
    "section": "",
    "text": "ProblemsHintsSolution\n\n\n\nLoad the PUMS person data as an arrow dataset\nWhat are the dimensions of the dataset? Number of rows? Number of columns?\nExamine the dataset:\n\nWhat columns does the dataset have?\nWhat are the column types?\n\n\n\n\nYou can use arrow::open_dataset(...) to open a dataset. Treat the dataset like it’s a data frame, can you use the same functions that you are already familiar with?\n\n\n\nlibrary(arrow)\nlibrary(dplyr)\n\n# Open the PUMS dataset\npums_ds &lt;- open_dataset(\"~/PUMS/data/person\")\n\n# dimensions\nnrow(pums_ds)\nncol(pums_ds)\n\n# Examine the dataset\npums_ds\n\n# Examine schema\nschema(pums_ds)"
  },
  {
    "objectID": "materials/activities/03-practice-arrow.html#exercise-1-reading-partitioned-pums-data",
    "href": "materials/activities/03-practice-arrow.html#exercise-1-reading-partitioned-pums-data",
    "title": "Hands-on practice: Using parquet, arrow, and duckdb",
    "section": "",
    "text": "ProblemsHintsSolution\n\n\n\nLoad the PUMS person data as an arrow dataset\nWhat are the dimensions of the dataset? Number of rows? Number of columns?\nExamine the dataset:\n\nWhat columns does the dataset have?\nWhat are the column types?\n\n\n\n\nYou can use arrow::open_dataset(...) to open a dataset. Treat the dataset like it’s a data frame, can you use the same functions that you are already familiar with?\n\n\n\nlibrary(arrow)\nlibrary(dplyr)\n\n# Open the PUMS dataset\npums_ds &lt;- open_dataset(\"~/PUMS/data/person\")\n\n# dimensions\nnrow(pums_ds)\nncol(pums_ds)\n\n# Examine the dataset\npums_ds\n\n# Examine schema\nschema(pums_ds)"
  },
  {
    "objectID": "materials/activities/03-practice-arrow.html#exercise-2-basic-filtering-and-aggregation",
    "href": "materials/activities/03-practice-arrow.html#exercise-2-basic-filtering-and-aggregation",
    "title": "Hands-on practice: Using parquet, arrow, and duckdb",
    "section": "Exercise 2: Basic Filtering and Aggregation",
    "text": "Exercise 2: Basic Filtering and Aggregation\n\nProblemsHintSolution\n\n\n\nWhat was the population of Tennessee in 2018?\nWhat was the population of Tennessee over the last five years of available data?\n\n\n\nTry using familiar dplyr verbs: filter(), summarize(), et c.\n\n\n\nlibrary(arrow)\nlibrary(dplyr)\n\n# Open the PUMS dataset\npums_ds &lt;- open_dataset(\"~/PUMS/data/person\")\n\npums_ds |&gt;\n  filter(year == 2018, location == \"tn\") |&gt;\n  summarize(\n    n = n(),\n    population = sum(PWGTP)\n  ) |&gt;\n  collect()\n\npums_ds |&gt;\n  filter(location == \"tn\") |&gt;\n  group_by(year) |&gt;\n  summarize(\n    n = n(),\n    population = sum(PWGTP)\n  ) |&gt;\n  arrange(-year) |&gt;\n  slice_head(n = 5) |&gt;\n  collect()"
  },
  {
    "objectID": "materials/activities/03-practice-arrow.html#exercise-3-using-duckdb-with-pums-data",
    "href": "materials/activities/03-practice-arrow.html#exercise-3-using-duckdb-with-pums-data",
    "title": "Hands-on practice: Using parquet, arrow, and duckdb",
    "section": "Exercise 3: Using DuckDB with PUMS Data",
    "text": "Exercise 3: Using DuckDB with PUMS Data\n\nProblemsHintSolution\n\n\nFor each state, compute the minimum commute time and the maximum commute time. Return it in a long data frame (hint, you’ll need to use tidyr::pivot_longer here) with the columns: location, commute_metric (values: max_commute, min_commute), time.\nFor motivation: if you were trying to plot using ggplot2 and wanted both the minimums and the maximums to show up on the same plot.\n\n\nArrow’s query engine doesn’t support tidyr::pivot_longer. So you’ll need to use to_duckdb() and then use duckdb from there.\n\n\n\nlibrary(arrow)\nlibrary(duckdb)\nlibrary(tidyr)\n\n# Open the PUMS dataset\npums_ds &lt;- open_dataset(\"~/PUMS/data/person\")\n\npums_ds |&gt;\n  group_by(location) |&gt;\n  summarize(\n    max_commute = max(JWMNP, na.rm = TRUE),\n    min_commute = min(JWMNP, na.rm = TRUE)\n  ) |&gt;\n  to_duckdb() |&gt; \n  pivot_longer(!location, names_to = \"commute_metric\", values_to = \"time\") |&gt;\n  arrange(location) |&gt;\n  collect()"
  },
  {
    "objectID": "materials/activities/03-practice-arrow.html#challenge-formulate-your-own-analysis",
    "href": "materials/activities/03-practice-arrow.html#challenge-formulate-your-own-analysis",
    "title": "Hands-on practice: Using parquet, arrow, and duckdb",
    "section": "Challenge: Formulate Your Own Analysis",
    "text": "Challenge: Formulate Your Own Analysis\n\nChoose a research question:\n\nHow has commute time changed over the years?\nWhat’s the relationship between education and income?\nHow does housing cost burden vary by state?\nYour own question…\n\nImplement the analysis using:\n\nArrow Dataset operations\nDuckDB SQL queries\nData visualization\n\nCompare performance between approaches"
  },
  {
    "objectID": "materials/activities/03-practice-arrow.html#the-pums-dataset",
    "href": "materials/activities/03-practice-arrow.html#the-pums-dataset",
    "title": "Hands-on practice: Using parquet, arrow, and duckdb",
    "section": "The PUMS Dataset",
    "text": "The PUMS Dataset\ndetailed dataset description\n\nPublic Use Microdata Sample\n\nUS Census Bureau data\nIndividual person and household records\nAnonymized demographic information\nIncome, education, housing, commute, et c.\n\nDataset characteristics:\n\nMultiple years (2005-2022, sans 2020)\nAll US states and territories\n53 Million rows (person), 25 Million rows (household)\n200+ variables"
  },
  {
    "objectID": "materials/activities/02-practice-datatable.html#setup",
    "href": "materials/activities/02-practice-datatable.html#setup",
    "title": "data.table",
    "section": "Setup",
    "text": "Setup\nDownload zip file\n\nlibrary(data.table)\nlibrary(arrow)\nlibrary(dplyr)\n\n\n# Load PUMS data (same as in slides)\npums &lt;- open_dataset(here::here(\"data\", \"PUMS\", \"person\")) |&gt; collect()\nsetDT(pums)\n\n# Add age groups variable for exercises\npums[, age_groups := fcase(AGEP &lt; 18, \"Under 18\", AGEP &lt; 65, \"18-64\", default = \"65+\")]"
  },
  {
    "objectID": "materials/activities/02-practice-datatable.html#demo",
    "href": "materials/activities/02-practice-datatable.html#demo",
    "title": "data.table",
    "section": "Demo",
    "text": "Demo\n\n# Select columns (j)\npums[, .(AGEP, SEX, ST)]\n\n# Filter rows (i)\npums[year == 2021 & location == \"ak\"]\n\n# Summarize by groups (by)\npums[, .(total_pop = sum(PWGTP)), by = ST]\n\n# Add new columns with :=\npums[, total_pop := sum(PWGTP), by = ST]\npums[, age_decade := floor(AGEP / 10) * 10]\n\n# Chain operations\npums[year == 2021][, .(avg_age = mean(AGEP)), by = ST][order(-avg_age)]"
  },
  {
    "objectID": "materials/activities/02-practice-datatable.html#your-turn",
    "href": "materials/activities/02-practice-datatable.html#your-turn",
    "title": "data.table",
    "section": "Your Turn",
    "text": "Your Turn\nTry these exercises with the PUMS dataset:\n\nFind the unique values of the ST variable: use data.table syntax or dtplyr syntax to find the unique values of the ST variable.\n\n\n# Your code here"
  },
  {
    "objectID": "materials/activities/02-practice-datatable.html#your-turn-1",
    "href": "materials/activities/02-practice-datatable.html#your-turn-1",
    "title": "data.table",
    "section": "Your Turn",
    "text": "Your Turn\n\nBasic filtering and grouping: Calculate total population by age_groups for both Alaska and California across years.\n\n\n# Your code here"
  },
  {
    "objectID": "materials/activities/02-practice-datatable.html#your-turn-2",
    "href": "materials/activities/02-practice-datatable.html#your-turn-2",
    "title": "data.table",
    "section": "Your Turn",
    "text": "Your Turn\n\nPopulation comparison: Compare total population across all states for 2021\n\n\n# Your code here"
  },
  {
    "objectID": "materials/activities/02-practice-datatable.html#your-turn-3",
    "href": "materials/activities/02-practice-datatable.html#your-turn-3",
    "title": "data.table",
    "section": "Your Turn",
    "text": "Your Turn\n\nIncome analysis: Find the median personal income (PINCP) by age group across all years.\n\n\n# Your code here"
  },
  {
    "objectID": "materials/activities/02-practice-datatable.html#your-turn-4",
    "href": "materials/activities/02-practice-datatable.html#your-turn-4",
    "title": "data.table",
    "section": "Your Turn",
    "text": "Your Turn\n\nChaining operations: Find the state with the highest average age in 2022, sorted from oldest to youngest\n\n\n# Your code here"
  },
  {
    "objectID": "materials/activities/02-practice-datatable.html#your-turn-5",
    "href": "materials/activities/02-practice-datatable.html#your-turn-5",
    "title": "data.table",
    "section": "Your Turn",
    "text": "Your Turn\n\nCreating new variables: Add a variable for income brackets (PINCP) and calculate employment rates (ESR) by bracket\n\n\n# Hint: Use PINCP for income, ESR for employment status\n# Your code here"
  },
  {
    "objectID": "materials/activities/02-practice-datatable.html#your-turn-6",
    "href": "materials/activities/02-practice-datatable.html#your-turn-6",
    "title": "data.table",
    "section": "Your Turn",
    "text": "Your Turn\n\nRolling Joins (extra challenging): Using the variables produced in number 6, join with the following data using the roll parameter to create a new variable called col_adjustment.\n\n\ncol_adjustments &lt;- data.table(\n  state_code = c(1, 2, 3, 4, 5, 6, 7, 8, 9),  # WV, WI, AL, AZ, AR, WY, WA, CA, AK\n  state_name = c(\n    \"West Virginia\", \"Wisconsin\", \"Alabama\", \"Arizona\", \"Arkansas\", \n    \"Wyoming\", \"Washington\", \"California\", \"Alaska\"),\n  col_factor = c(0.82, 0.88, 0.85, 0.92, 0.83, 0.89, 1.08, 1.25, 1.15)\n)\nsetkey(col_adjustments, state_code)\n\n# Hint try both roll = -Inf and roll = +Inf and see which one makes sense for this scenario\n# Your code here"
  }
]