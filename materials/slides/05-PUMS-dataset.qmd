---
title: "Introduction to PUMS"
format: 
  revealjs:
    footer: "[JSM: Large Data](https://github.com/kbodwin/jsm-large-data)"
    theme: simple
    scrollable: true
    embed-resources: true
    include-in-header:
        - text: |
            <style>
            .v-center-container {
                display: flex;
                justify-content: center;
                align-items: center;
                height: 90%;
            }
            .v-spacier {
                margin-bottom: 2em; 
                margin-top: 2em;
            }
            </style>
editor: source
---

# The Public Access Microdata dataset

## About the data

:::{.incremental}
* Collected by the United States Census Bureau as part of the American Community Survey
* Disclosure protection ‚Äî introduces noise to make it impossible to identify specific people or households
* Covers: 2005--2022 using the 1-year estimates (sans 2020; COVID)
* Split into **person** and **household**
    * columns: person: 230, household: 188 
    * rows: person: 53M, household: 25M
:::

## A few example variables

:::{.incremental}
* Person
  * Language spoken at home (LANP)
  * Travel time to work (JWMNP) 
* Household
  * Access to internat (ACCESS)
  * Monthly rent (RNTP)
* Weights üòµ‚Äçüí´
  * PWGTP and WGTP for weights
:::

## Format of the data

:::{.incremental}
* Released and available as CSV files (~90GB)
* Uses survey-style coding 
::: 

. . .


For this workshop:

:::{.incremental}
* Recoded the dataset 
* Saved as parquet (~12GB) partitioned by year and state
:::

:::{.notes}
survey-style coding is where categorical variables will be given a number and there is a separate look up table for the values. Additionally, there are frequently sentinel values that mean missing or "99 and greater"

We have pulled the key into the actual data so you don't need to do the lookups and also converted numeric columns into integers, floats, et c. where appropriate.
:::

## Can I analyze all of PUMS?

::: {.fragment .v-spacier}
Most analysis of PUMS data starts with subsetting the data. Either by state (or even smaller) or year and often both.
:::


::: {.fragment .v-spacier}
But with the tools we learn about in this workshop, we actually can analyze the whole dataset.
:::


## What can I do? 

![](images/pums-data-manip-agg-plot-n_commuters-html-1.png){fig-align="center"}

## What can I do? 

![](images/pums-data-manip-agg-plot-commute_time-html-1.png){fig-align="center"}

## Caveat

::: {.v-center-container style="font-size: 1.25em;"}
Though we have not _purposefully_ altered this data, this data **should not be relied on** to be a perfect or even possibly accurate representation of the official PUMS dataset. 
:::
