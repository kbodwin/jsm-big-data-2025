---
title: "JSM 2025 Short Course"
---

## Large Local Data

by: Kelly Bodwin, Tyson Barrett & Jonathan Keane

# Welcome!

Welcome to this Short Course on **Storing, Importing, Managing, and Analyzing Large Data Locally with R**.  The goal for the course is to provide training in modern tools for working with large data that fits on-disk on a local machine.

This workshop is geared towards researchers and practitioners who regularly use R for their data preparation and/or analysis, but who may not be familiar with strategies and tools for speeding up processes, especially on larger datasets.

## Short Course Description

It is increasingly common in academic and professional settings to encounter datasets large enough to exceed the capabilities of standard data processing tools, yet small enough to be stored on local computers. Recent articles even claim that "the era of big data is over" and that data analysts and researchers should "think small, develop locally, ship joyfully"  Such "medium" dataests are instrumental in measuring, tracking, and recording a wide array of phenomena across disciplines such as human behavior, animal studies, geology, economics, and astronomy. In this workshop, we will present modern techniques for handling large local data in R using a tidy data pipeline, encompassing stages from data storage and importing to cleaning, analysis, and exporting data and analyses.  Specifically, we will teach a combination of tools from the data.table, arrow, and duckDB packages, with a focus on parquet data files for storage and transfer. By the end of the workshop, participants will understand how to integrate these tools to establish a legible, reproducible, efficient, and high-performance workflow.  


## Intended Audience and Level

We expect attendees to have R fluency at the level of a typical introductory course, such as the textbook [R for Data Science](https://r4ds.hadley.nz/) (Wickham, Ã‡etinkaya-Rundel, & Grolemund 2023); as well as familiarity with some data application that may motivate tools beyond the introductory level.

# PUMS dataset

We will be referencing [a dataset that uses the US Census Bureau's PUMS dataset](https://scaling-arrow-pums.s3.us-east-1.amazonaws.com/readme.html). It would be good to download one of these two options before the workshop so you can work on it locally during the workshop. There are a few ways to get the PUMS data before the workshop:

# Easiest, quickest option
Download a subset of the data: [https://github.com/arrowrbook/book/releases/download/PUMS_subset/PUMS.subset.zip](https://github.com/arrowrbook/book/releases/download/PUMS_subset/PUMS.subset.zip)

This subset only includes the person-level data for years 2005, 2018, 2021 and only for states Alaska, Alabama, Arkansas, Arizona, California, Washington, Wisconsin, West Virginia, and Wyoming.

Simply download it and unzip it into a directory called data in your working directory and you can run the examples in the workshop.

# Longer, but full dataset option
We also host a full version of the dataset in AWS S3.

Once you have setup your [AWS account and CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-quickstart.html), download the data into a data directory to use:

```
aws s3 cp --recursive s3://scaling-arrow-pums/ ./data/
```

This is the full dataset, but does require that you setup your AWS CLI and wait for the dataset to be downloaded. This might require `--request-payer requester` after the workshop where you will need to setup an AWS account and pay the small transfer fee.

# Schedule

| Time | Topic | Presenter |
|:----------------:|:------------------------------:|:--------------------:|
| 8:30 - 9:00 | [Introductions, Installs, Set-up](materials/slides/00-setup-intro.qmd) | all |
| 9:00 - 9:45 | [I. Identify slowdowns and solutions](materials/slides/01-slowdowns-solutions.qmd) | Kelly |
| 9:45 - 10:15 | [Activity 1](materials/activities/01-practice-data.qmd) | Kelly |
| 10:15 - 10:30 | Break |  |
| 10:30 - 11:30 | [II. data.table for fast wrangling](materials/slides/02-datatable.qmd) | Tyson |
| 11:30 - 12:00| [Activity 2](materials/activities/02-practice-datatable.qmd) | Tyson |
| 12:00 - 1:30 | Lunch Break |  |
| 1:30 - 2:30 | [III. parquet, arrow, duckdb](materials/slides/03-arrow.qmd) | Jonathan |
| 2:30 - 3:00 | [Activity 3](materials/activities/03-practice-arrow.qmd) | Jonathan  |
| 3:00 - 3:30 | Break |  |
| 3:30 - 4:30 | [IV. Workflow](materials/slides/04-workflow.qmd) | all |
| 4:30 - 5:00 | [Activity 4](materials/activities/04-practice-workflow.qmd) | all |

# Workshop Materials

Workshop materials can be found in the github repository [jsm-large-data](https://github.com/kbodwin/jsm-big-data-2025/tree/main/materials)!

------------------------------------------------------------------------

![](https://i.creativecommons.org/l/by/4.0/88x31.png) This work is licensed under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).
